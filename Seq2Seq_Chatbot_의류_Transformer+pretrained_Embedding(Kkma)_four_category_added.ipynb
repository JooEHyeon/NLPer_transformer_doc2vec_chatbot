{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Seq2Seq_Chatbot_의류_Transformer+pretrained Embedding(Kkma)_four_category_added.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9UA-8fQ2EDnp",
        "ioT3c4eLEKon",
        "lsf4tJl61Xi9"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ideablast/NLPer_chatbot/blob/toram/Seq2Seq_Chatbot_%EC%9D%98%EB%A5%98_Transformer%2Bpretrained_Embedding(Kkma)_four_category_added.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsiilWsMNHHL",
        "outputId": "be49eb28-66df-4a44-da0a-97b590bb36ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 59.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/96/1030895dea70855a2e1078e3fe0d6a63dcb7c212309e07dc9ee39d33af54/JPype1-1.1.2-cp36-cp36m-manylinux2010_x86_64.whl (450kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 56.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: tweepy, colorama, beautifulsoup4, JPype1, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.1.2 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UA-8fQ2EDnp"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DAFy5c7ydzC"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers, losses, metrics\n",
        "from keras import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from konlpy.tag import Okt, Hannanum, Kkma, Komoran"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioT3c4eLEKon"
      },
      "source": [
        "## Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9YUdE1OydzG"
      },
      "source": [
        "# 태그 단어\n",
        "PAD = \"<PADDING>\"   # 패딩\n",
        "STA = \"<START>\"     # 시작\n",
        "END = \"<END>\"       # 끝\n",
        "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
        "\n",
        "# 태그 인덱스\n",
        "PAD_INDEX = 0\n",
        "STA_INDEX = 1\n",
        "END_INDEX = 2\n",
        "OOV_INDEX = 3\n",
        "\n",
        "# 데이터 타입\n",
        "ENCODER_INPUT  = 0\n",
        "DECODER_INPUT  = 1\n",
        "DECODER_TARGET = 2\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 200 ##word embedding dim\n",
        "NUM_HEADS = 4 ## D_Model % NUM_HEADS == 0이 되야하므로... D_MODEL / NUM_HEADS = d_k : 한 헤드에서 Q,K,V의 shape (D_MODEL, d_k)\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "EPOCHS = 50\n",
        "# for data pipelining\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "VOCAB_SIZE = 0 # 후에 len(words) 로 바뀜.\n",
        "\n",
        "# 한 문장에서 단어 시퀀스의 최대 개수\n",
        "MAX_SEQ = 30\n",
        "\n",
        "# 정규 표현식 필터\n",
        "RE_FILTER = re.compile(\"[\\\"':;~()]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhVVnW_uEWT1"
      },
      "source": [
        "## Data Load & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80IauV0FpUv2",
        "outputId": "126bd2a9-d82e-4909-c051-b880cd8ec6d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEHDnPXNzZlM",
        "outputId": "8cf7003e-3ae4-48e8-b749-fabb06a34a18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wear_data = pd.read_csv(\"/content/drive/My Drive/wear.csv\")\n",
        "print(wear_data.shape)\n",
        "customer = wear_data[wear_data.SPEAKER == \"고객\"].SENTENCE\n",
        "store = wear_data[wear_data.SPEAKER == \"점원\"].SENTENCE\n",
        "print(customer.shape, store.shape) # 질문의 개수와 답의 개수가 일치하지 않는다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15826, 20)\n",
            "(8381,) (7445,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwMO4CneuD-p",
        "outputId": "8a7eed15-335c-4f20-a443-66fbe872abb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "main = wear_data['MAIN']\n",
        "main.shape\n",
        "category = wear_data['CATEGORY']\n",
        "category.shape\n",
        "all_stc = wear_data['SENTENCE']\n",
        "all_stc\n",
        "category"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          신발\n",
              "1          신발\n",
              "2          신발\n",
              "3          신발\n",
              "4          신발\n",
              "         ... \n",
              "15821    액세서리\n",
              "15822    액세서리\n",
              "15823    액세서리\n",
              "15824    액세서리\n",
              "15825    액세서리\n",
              "Name: CATEGORY, Length: 15826, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSUQOvy715fb",
        "outputId": "5947e948-b6e5-468f-c0ef-0164fe512e0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(main.shape, all_stc.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15826,) (15826,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLNSiqcHM4WY",
        "outputId": "0f2f66b7-6ce3-4e7d-eb35-f0b16dc18a78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 고객과 점원의 질,답 쌍으로 만들기\n",
        "prev = \"고객\"\n",
        "store_arr = []\n",
        "customer_arr = []\n",
        "store_stc = \"\"\n",
        "customer_stc = \"\"\n",
        "main_arr = []\n",
        "category_arr = []\n",
        "\n",
        "for i in range(wear_data.shape[0]):\n",
        "    if (prev == wear_data.iloc[i].SPEAKER):\n",
        "        if prev == \"점원\":\n",
        "             store_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "        else : \n",
        "             customer_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "            \n",
        "    elif prev == \"점원\":\n",
        "        store_arr.append(store_stc)\n",
        "        customer_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"고객\"\n",
        "        main_arr.append(main[i])\n",
        "    else :\n",
        "        customer_arr.append(customer_stc)\n",
        "        store_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"점원\"\n",
        "        category_arr.append(category[i])\n",
        "\n",
        "print(len(store_arr))\n",
        "print(len(customer_arr))\n",
        "print(store_arr[-1])\n",
        "print(customer_arr[-1]) # 자료 상에서 이후에는 계속 고객의 물음만 계속된다. 코드 레벨에서 이 부분은 빼게 구현했다. (stc는 만들어지지만 arr에 append 안하게 된다.)\n",
        "print(len(category_arr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7301\n",
            "7301\n",
            "요즘 파스텔 톤이 유행이에요\n",
            "요즘 유행하는 색깔이 뭐예요?\n",
            "7301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV1kGedgul5h",
        "outputId": "eed31e0b-4c96-498d-f1cf-a6a23079225e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(25):\n",
        "    print(customer_arr[i])\n",
        "    print(store_arr[i])\n",
        "    print(main_arr[i]) # MAIN 행으로 하기에는 너무 쌍이 안맞다,,,\n",
        "    print(category_arr[i])\n",
        "    print() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 신발은 여기 있는 게 다예요?\n",
            "네 성인이나 아동 다 있어요 발 사이즈 몇 신으세요?\n",
            "종류별신발제품문의요청\n",
            "신발\n",
            "\n",
            "230이요\n",
            "편하게 신을 수 있는 거 찾으세요?\n",
            "착화감\n",
            "신발\n",
            "\n",
            "네 봄이니까 편하게 신을 수 있는 거\n",
            "이런 건 어떠세요? 이런 거도 신발 무척 편하거든요\n",
            "굽높이문의\n",
            "신발\n",
            "\n",
            "굽 좀 높은 거 없나요?\n",
            "봄 상품은 아직 어른 제품이 많이 안나왔습니다\n",
            "재입고문의\n",
            "신발\n",
            "\n",
            "언제 들어와요?\n",
            "이번주 지나면 들어올 거예요\n",
            "소재문의\n",
            "신발\n",
            "\n",
            "이거는 가죽이에요?\n",
            "가죽 아니고 쎄무예요\n",
            "제품가격문의\n",
            "신발\n",
            "\n",
            "가죽은 얼마예요?\n",
            "2만 9천 원입니다\n",
            "사이즈재고문의\n",
            "신발\n",
            "\n",
            "털 달린 거 저거는 사이즈 있어요?\n",
            "230이 없어요  이거 한 번 신어보세요\n",
            "사이즈문의\n",
            "신발\n",
            "\n",
            "좀 크네 또 안 들어와요?\n",
            "네 이건 다 끝났어요\n",
            "종류별가방제품문의요청\n",
            "신발\n",
            "\n",
            "가방 매는 거 보고 있어요\n",
            "여기 있어요\n",
            "제품가격문의\n",
            "가방\n",
            "\n",
            "가격이 얼마예요?\n",
            "이 종류는 2만 원이고 이 종류는 3만 8천 원이에요\n",
            "소재를제시한제품문의\n",
            "가방\n",
            "\n",
            "가죽으로 된 거는 없어요?\n",
            "가죽은 없고 레자만 있어요\n",
            "제품가격문의\n",
            "가방\n",
            "\n",
            "레자는 얼마예요?\n",
            "5만 5천 원요\n",
            "가방소재문의\n",
            "가방\n",
            "\n",
            "이거는 천이죠?\n",
            "네 맞아요\n",
            "제품가격문의\n",
            "가방\n",
            "\n",
            "이건 얼마예요?\n",
            "그것도 5만 5천 원요\n",
            "제품구성문의\n",
            "가방\n",
            "\n",
            "이거 끈은 따로 없어요?\n",
            "안에 있어요\n",
            "공휴일영업문의\n",
            "가방\n",
            "\n",
            "내일은 문 열어요?\n",
            "휴무입니다\n",
            "공휴일영업문의\n",
            "가방\n",
            "\n",
            "며칠까지 휴무예요?\n",
            "설까지 쉬고 다음날 열 거 같아요\n",
            "제품가격문의\n",
            "가방\n",
            "\n",
            "여기 마스크는 얼마예요?\n",
            "5천 원요\n",
            "제품소재문의\n",
            "가방\n",
            "\n",
            "이거 나무예요? 다 돌인가요?\n",
            "나무도 있고 도자기도 있어요\n",
            "세트제품개별구매문의\n",
            "액세서리\n",
            "\n",
            "이런 건 세트로 팔아요?\n",
            "네 세트로만 팔아요\n",
            "제품소재문의\n",
            "액세서리\n",
            "\n",
            "이건 뭐예요?\n",
            "마블이라고 종이를 말아가지고 하는 거예요\n",
            "제품가격문의\n",
            "액세서리\n",
            "\n",
            "제일 큰 거는 얼마인데요?\n",
            "세트에 7만 원이요\n",
            "종류별액세서리제품문의요청\n",
            "액세서리\n",
            "\n",
            "스카프 좀 보려구요\n",
            "네 천천히 보세요\n",
            "계절상품문의\n",
            "액세서리\n",
            "\n",
            "실크스카프도 봄에 하나요?\n",
            "실크 봄 가을에 하죠\n",
            "제품문의\n",
            "액세서리\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbivSckMydzN"
      },
      "source": [
        "# 형태소분석 함수\n",
        "def pos_tag(sentences):\n",
        "    \n",
        "    # KoNLPy 형태소분석기 설정\n",
        "    tagger = Kkma()\n",
        "    \n",
        "    # 문장 품사 변수 초기화\n",
        "    sentences_pos = []\n",
        "    \n",
        "    # 모든 문장 반복\n",
        "    for sentence in sentences:\n",
        "        # [\\\"':;~()] 특수기호 제거\n",
        "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
        "        \n",
        "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
        "        sentence = \" \".join(tagger.morphs(sentence))\n",
        "        sentences_pos.append(sentence)\n",
        "        \n",
        "    return sentences_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seqSNWcydzP",
        "outputId": "98a8bab8-1efc-490b-dba1-d628899fada3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 형태소분석 수행\n",
        "question = pos_tag(customer_arr)\n",
        "answer = pos_tag(store_arr)\n",
        "\n",
        "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
        "for i in range(5):\n",
        "    print('Q : ' + question[i])\n",
        "    print('A : ' + answer[i])\n",
        "    print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q : 신발 은 여기 있 는 것 이 다예 이 요 ?\n",
            "A : 네 성인 이나 아동 다 있 어요 발 사이즈 몇 신 으세요 ?\n",
            "\n",
            "Q : 230 이요\n",
            "A : 편하 게 신 을 수 있 는 거 찾 으세요 ?\n",
            "\n",
            "Q : 네 봄 이 니까 편하 게 신 을 수 있 는 거\n",
            "A : 이런 건 어 어 떠세 이 요 ? 이런 거도 신발 무척 편하 거든요\n",
            "\n",
            "Q : 굽 좀 높 은 거 없 나요 ?\n",
            "A : 봄 상품 은 아직 어른 제품 이 많이 안 나오 았 습니다\n",
            "\n",
            "Q : 언제 들어오 아요 ?\n",
            "A : 이번 주 지나 면 들어오 ㄹ 거 이 에요\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrnct_nzydzR"
      },
      "source": [
        "# 질문과 대답 문장들을 하나로 합침\n",
        "sentences = []\n",
        "sentences.extend(question)\n",
        "sentences.extend(answer)\n",
        "\n",
        "words = []\n",
        "\n",
        "# 단어들의 배열 생성\n",
        "for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "        words.append(word)\n",
        "\n",
        "# 길이가 0인 단어는 삭제\n",
        "words = [word for word in words if len(word) > 0]\n",
        "\n",
        "# 중복된 단어 삭제\n",
        "words = list(set(words))\n",
        "\n",
        "#제일 앞에 태그 단어 삽입. 기존 단어들은 뒤로 밀림.\n",
        "words[:0] = [PAD, STA, END, OOV]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE9ZhJpEy_rT",
        "outputId": "a2ebc6c1-d942-4239-f922-9f6d9fb65f23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "VOCAB_SIZE = len(words)\n",
        "print(\"손님과 점원의 말에서 사용된 총 단어의 수 :\",len(words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "손님과 점원의 말에서 사용된 총 단어의 수 : 3508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkvyOnSvydzX"
      },
      "source": [
        "# 단어와 인덱스의 딕셔너리 생성\n",
        "word_to_index = {word: index for index, word in enumerate(words)}\n",
        "index_to_word = {index: word for index, word in enumerate(words)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfoTztrvydzc"
      },
      "source": [
        "# 문장을 인덱스로 변환(정수인코딩)\n",
        "def convert_text_to_index(sentences, vocabulary, type): \n",
        "    \n",
        "    sentences_index = []\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for sentence in sentences:\n",
        "        sentence_index = []\n",
        "        \n",
        "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
        "        if type == DECODER_INPUT:\n",
        "            sentence_index.extend([vocabulary[STA]])\n",
        "        \n",
        "        # 문장의 단어들을 띄어쓰기로 분리\n",
        "        for word in sentence.split():\n",
        "            if vocabulary.get(word) is not None:\n",
        "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[word]])\n",
        "            else:\n",
        "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "        # 최대 길이 검사\n",
        "        if type == DECODER_TARGET:\n",
        "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
        "            if len(sentence_index) >= MAX_SEQ:\n",
        "                sentence_index = sentence_index[:MAX_SEQ-1] + [vocabulary[END]]\n",
        "            else:\n",
        "                sentence_index += [vocabulary[END]]\n",
        "        else:\n",
        "            if len(sentence_index) > MAX_SEQ:\n",
        "                sentence_index = sentence_index[:MAX_SEQ]\n",
        "            \n",
        "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "        sentence_index += (MAX_SEQ - len(sentence_index)) * [vocabulary[PAD]]\n",
        "        \n",
        "        # 문장의 인덱스 배열을 추가\n",
        "        sentences_index.append(sentence_index)\n",
        "\n",
        "    return np.asarray(sentences_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zezFPTvcydzf",
        "outputId": "86a5f1ad-9e27-4d17-993f-e1405b0b9086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 인코더 입력 인덱스 변환\n",
        "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
        "\n",
        "# 첫 번째 인코더 입력 출력 (신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_encoder[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있 는 것 이 다예 이 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 441, 3317, 1647, 1556,   66, 1676, 2634, 3327, 2634,  915, 1870,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmql1Lf_ydzh",
        "outputId": "6c99c14c-d39e-4d62-b117-91fe97a22940",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 입력 인덱스 변환\n",
        "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (<START> 신발 은 여기 있는 게 다예 요)\n",
        "print(answer[0])\n",
        "x_decoder[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "네 성인 이나 아동 다 있 어요 발 사이즈 몇 신 으세요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,  597, 3107,  437, 2215, 3206, 1556, 3121,  728, 3440, 1250,\n",
              "       2341, 1865, 1870,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIhDbaLydzk",
        "outputId": "64bc058a-40eb-441a-f148-cbd82354412c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 목표 인덱스 변환\n",
        "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (신발 은 여기 있는 게 다예 요 <END>)\n",
        "print(answer[0])\n",
        "y_decoder[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "네 성인 이나 아동 다 있 어요 발 사이즈 몇 신 으세요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 597, 3107,  437, 2215, 3206, 1556, 3121,  728, 3440, 1250, 2341,\n",
              "       1865, 1870,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ixwhL1fY_d"
      },
      "source": [
        "## Load Pretrained Embedding model\n",
        " - from https://github.com/Kyubyong/wordvectors 's korean(w2v)\n",
        " - 200 dim\n",
        " - this model trained 330M corpus(tagged by Kkma)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPa7XT-TfYAk"
      },
      "source": [
        "emb_model = gensim.models.Word2Vec.load('/content/drive/My Drive/ko.bin')\n",
        "emb_model.save(\"base_word2vec_200d.model\") #기본 full 모델 백업, 더 Train할때 #type: gensim.models.word2vec.Word2Vec\n",
        "\n",
        "word_vectors = emb_model.wv\n",
        "word_vectors.save(\"base_word2vec_200d.wordvectors\") #기본 KeyedVecotros 모델 백업, 더 train안시킬때, 로드속도 및 메모리 손실 적음\n",
        "# Load back with memory-mapping = read-only, shared across processes.\n",
        "wv = KeyedVectors.load(\"base_word2vec_200d.wordvectors\", mmap='r') #type: gensim.models.keyedvectors.Word2VecKeyedVectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJbjANLxmTd-"
      },
      "source": [
        "#일단 추가 학습 없이 해보자.\n",
        "emb_layer = wv.get_keras_embedding(train_embeddings=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsf4tJl61Xi9"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsxmXWS41XVd"
      },
      "source": [
        "# decoder inputs use the previous target as input\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': x_encoder,\n",
        "        'dec_inputs': x_decoder\n",
        "    },\n",
        "    {\n",
        "        'outputs': y_decoder\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cstXcPJo4rKD",
        "outputId": "03f6b769-9d84-40a2-d97a-3229c1cb67a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ({inputs: (None, 30), dec_inputs: (None, 30)}, {outputs: (None, 30)}), types: ({inputs: tf.int64, dec_inputs: tf.int64}, {outputs: tf.int64})>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxXCQWvw2jwx"
      },
      "source": [
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH-k-kk_1_Vu"
      },
      "source": [
        "## scaled dot product Attention\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True) # QK^T\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth) #  QK^T / sqrt(d_k)\n",
        "\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9) # zero padding token softmax 결과가 0이 나오도록\n",
        "  \n",
        "  attention_weights = tf.nn.softmax(logits, axis = -1) # softmax(QK^T / sqrt(d_k))\n",
        "\n",
        "  output = tf.matmul(attention_weights, value) # softmax(QK^T / sqrt(d_k)) * V\n",
        "\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7orcKMr13xY8"
      },
      "source": [
        "## multi-head attention\n",
        "## each head need (scaled_dot_product_attention)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0 # 128,8\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "  \n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(inputs, shape=(batch_size,-1,self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3]) ##????\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    #linear\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    #split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    #scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    #concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "\n",
        "    #final linear\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmlW0oi89nEC"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37sh3f8P-JUB"
      },
      "source": [
        "#print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W7ld50z3vT2"
      },
      "source": [
        "# it handle mask future tokens in a sequence used decoder. and mask pad tokens\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W25teKwt_F80"
      },
      "source": [
        "#print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLhXEIJgASo3"
      },
      "source": [
        "Positional encoding\n",
        "\n",
        "since we don't use any rnn, cnn, positional encoding give model position information of words in sentence.\n",
        "\n",
        "positional encoding vector is added to embedding vector\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7s19-x3_Hpq"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "  \n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles #pos/10000^(2i/d_model)\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position = tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model = d_model)\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLiumNZZDZGY"
      },
      "source": [
        "### Encoder Layer\n",
        "1. Multi-head attention (with padding mask)\n",
        "2. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oarRWUMLDYnC"
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query':inputs,\n",
        "          'key':inputs,\n",
        "          'value':inputs,\n",
        "          'mask':padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3rO9IcDHGE5"
      },
      "source": [
        "### Encoder\n",
        "1. Input Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` encoder layers\n",
        "\n",
        "Embedding + positional encoding : input\n",
        "\n",
        "going encoder layers.\n",
        "\n",
        "output going decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOwoi2_jHvbA"
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = emb_layer(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)#??왜 vocab_size가 들어가지?\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, padding_mask], outputs = outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8XHH5dpJr-G"
      },
      "source": [
        "### Decoder Layer\n",
        "1. Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2. Multi-head attention (with padding mask). `value` and `key` is from encoder output. `query` is from Multi-head attention layer output\n",
        "3. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtAfKdk-JrxK"
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name=\"padding_mask\")\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query' : inputs,\n",
        "          'key' : inputs,\n",
        "          'value' : inputs,\n",
        "          'mask' : look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query' : attention1,\n",
        "          'key' : enc_outputs,\n",
        "          'value' : enc_outputs,\n",
        "          'mask' : padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnBSBcm1NAYv"
      },
      "source": [
        "### Decoder\n",
        "1. output Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` decoder layers\n",
        "\n",
        "Embedding + positional encoding : input (target)\n",
        "\n",
        "going decoder layers.\n",
        "\n",
        "output going final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnA-8FEAOT4F"
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"decoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name='padding_mask')\n",
        "\n",
        "  embeddings = emb_layer(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"decoder_layer_{}\".format(i),\n",
        "    )(inputs = [outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-vmtqKQjhf"
      },
      "source": [
        "### Transformer\n",
        "1. encoder\n",
        "2. decoder\n",
        "3. final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEMfL5SFQqr4"
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"enc_padding_mask\")(inputs)\n",
        "  \n",
        "  #mask future tokens for decoder inputs at 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1,None,None),\n",
        "      name=\"look_ahead_mask\")(dec_inputs)\n",
        "  \n",
        "  #mask encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"dec_padding_mask\")(inputs)\n",
        "  \n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pav-8Jd3ydzp"
      },
      "source": [
        "## 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8y-mjWtydzp"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBI__UKXsRLZ",
        "outputId": "da486378-ec41-415c-ed8e-4e83ceaacec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Functional)            (None, None, 200)    6771224     inputs[0][0]                     \n",
            "                                                                 enc_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Functional)            (None, None, 200)    7093624     dec_inputs[0][0]                 \n",
            "                                                                 encoder[0][0]                    \n",
            "                                                                 look_ahead_mask[0][0]            \n",
            "                                                                 dec_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "outputs (Dense)                 (None, None, 3508)   705108      decoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,532,956\n",
            "Trainable params: 2,495,956\n",
            "Non-trainable params: 6,037,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK3IwtA4TOnN"
      },
      "source": [
        "### Loss function\n",
        "since target sequences are padded, deal this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi7YnqpVTYn2"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_SEQ))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "  \n",
        "  mask = tf.cast(tf.not_equal(y_true,0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzHEmCzUVhTu"
      },
      "source": [
        "### Custom learning rate\n",
        "use Adam optimizer with custom learning rate\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkFm9m_LVt8c"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb8PGbKgWAbP"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vql4FYFUV_3_"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_SEQ))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTXbb1Z2I4IM"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl3V7BllWWFG",
        "outputId": "c1b9301b-cf01-4404-f101-e4824a444fbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "115/115 [==============================] - 3s 26ms/step - loss: 2.4591 - accuracy: 0.0189\n",
            "Epoch 2/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 2.1292 - accuracy: 0.0333\n",
            "Epoch 3/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 1.7872 - accuracy: 0.0420\n",
            "Epoch 4/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 1.5823 - accuracy: 0.0584\n",
            "Epoch 5/50\n",
            "115/115 [==============================] - 2s 22ms/step - loss: 1.4580 - accuracy: 0.0736\n",
            "Epoch 6/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 1.3514 - accuracy: 0.0874\n",
            "Epoch 7/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 1.2625 - accuracy: 0.0988\n",
            "Epoch 8/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 1.1919 - accuracy: 0.1065\n",
            "Epoch 9/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 1.1363 - accuracy: 0.1118\n",
            "Epoch 10/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 1.0883 - accuracy: 0.1164\n",
            "Epoch 11/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 1.0473 - accuracy: 0.1205\n",
            "Epoch 12/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 1.0098 - accuracy: 0.1238\n",
            "Epoch 13/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.9751 - accuracy: 0.1275\n",
            "Epoch 14/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.9422 - accuracy: 0.1302\n",
            "Epoch 15/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.9146 - accuracy: 0.1332\n",
            "Epoch 16/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.8833 - accuracy: 0.1370\n",
            "Epoch 17/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.8606 - accuracy: 0.1385\n",
            "Epoch 18/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.8322 - accuracy: 0.1412\n",
            "Epoch 19/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.8076 - accuracy: 0.1439\n",
            "Epoch 20/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.7830 - accuracy: 0.1461\n",
            "Epoch 21/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.7603 - accuracy: 0.1484\n",
            "Epoch 22/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.7372 - accuracy: 0.1510\n",
            "Epoch 23/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.7151 - accuracy: 0.1538\n",
            "Epoch 24/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6936 - accuracy: 0.1561\n",
            "Epoch 25/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6727 - accuracy: 0.1592\n",
            "Epoch 26/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6500 - accuracy: 0.1617\n",
            "Epoch 27/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6311 - accuracy: 0.1647\n",
            "Epoch 28/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.6105 - accuracy: 0.1680\n",
            "Epoch 29/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.5920 - accuracy: 0.1705\n",
            "Epoch 30/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.5743 - accuracy: 0.1728\n",
            "Epoch 31/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.5531 - accuracy: 0.1764\n",
            "Epoch 32/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.5376 - accuracy: 0.1783\n",
            "Epoch 33/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.5226 - accuracy: 0.1818\n",
            "Epoch 34/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.5113 - accuracy: 0.1825\n",
            "Epoch 35/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.4952 - accuracy: 0.1862\n",
            "Epoch 36/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.4757 - accuracy: 0.1896\n",
            "Epoch 37/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.4598 - accuracy: 0.1922\n",
            "Epoch 38/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.4383 - accuracy: 0.1966\n",
            "Epoch 39/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.4184 - accuracy: 0.2004\n",
            "Epoch 40/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.3985 - accuracy: 0.2043\n",
            "Epoch 41/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.3799 - accuracy: 0.2084\n",
            "Epoch 42/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.3617 - accuracy: 0.2120\n",
            "Epoch 43/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.3476 - accuracy: 0.2156\n",
            "Epoch 44/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.3303 - accuracy: 0.2190\n",
            "Epoch 45/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.3141 - accuracy: 0.2232\n",
            "Epoch 46/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.3034 - accuracy: 0.2257\n",
            "Epoch 47/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.2925 - accuracy: 0.2280\n",
            "Epoch 48/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.2749 - accuracy: 0.2324\n",
            "Epoch 49/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.2690 - accuracy: 0.2334\n",
            "Epoch 50/50\n",
            "115/115 [==============================] - 2s 21ms/step - loss: 0.2541 - accuracy: 0.2375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c60376b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7MzIlL5tZfY"
      },
      "source": [
        "## 카테고리 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR6GEuioAvZ3"
      },
      "source": [
        "category_info = pd.DataFrame({\"stc\":all_stc, \"cate\":main})\n",
        "rough_info = pd.DataFrame({\"stc\":all_stc, \"cate\":category})\n",
        "\n",
        "category_info.dropna(inplace = True)\n",
        "category_info.reset_index(drop=True, inplace = True)\n",
        "\n",
        "rough_info.dropna(inplace = True)\n",
        "rough_info.reset_index(drop=True, inplace = True)\n",
        "\n",
        "tagger = Okt()\n",
        "\n",
        "for i in range(category_info.shape[0]):\n",
        "    category_info['stc'][i] = tagger.morphs(category_info['stc'][i])\n",
        "\n",
        "for i in range(rough_info.shape[0]):\n",
        "    rough_info['stc'][i] = tagger.morphs(rough_info['stc'][i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN4iLrvzBO_g",
        "outputId": "0d0095b6-1e29-4c1a-f191-9f6bf6931dd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "category_info\n",
        "category_list = pd.factorize(category_info['cate'])[1]\n",
        "category_info['cate'] = pd.factorize(category_info['cate'])[0]\n",
        "category_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['종류별신발제품문의요청', '착화감', '굽높이문의', '재입고문의', '소재문의', '제품가격문의', '사이즈재고문의',\n",
              "       '사이즈문의', '종류별가방제품문의요청', '소재를제시한제품문의',\n",
              "       ...\n",
              "       '맞춤문의/요청', '스타일선택/요청', '고객변심에의한환불/반품/교환요청', '카카오페이/삼성페이결제',\n",
              "       '교환/환불가능기간문의', '환불/반품/교환요청/문의', 'A/S신청문의', '특수제질세무/가죽세탁문의',\n",
              "       '종류별신발제품문의/요청', '선물포장문의/요청'],\n",
              "      dtype='object', length=405)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpTWCUA6KmVk",
        "outputId": "7b7d659b-f0a3-4c6a-df73-5076e176906c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rough_category_list = pd.factorize(rough_info['cate'])[1]\n",
        "rough_info['cate'] = pd.factorize(rough_info['cate'])[0]\n",
        "rough_category_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['신발', '가방', '액세서리', '의류'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLvAk6HDVGas",
        "outputId": "b17d51d1-d48d-461e-e7b1-6d66a46941fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "rough_info"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stc</th>\n",
              "      <th>cate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[신발, 은, 여기, 있는, 게, 다예, 요, ?]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[네, 성인, 이나, 아동, 다, 있어요]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[발, 사이즈, 몇, 신으세요, ?]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[230, 이요]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[편하게, 신, 을, 수, 있는, 거, 찾으세요, ?]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15821</th>\n",
              "      <td>[이, 쿠폰, 에, 적립, 해주세요]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15822</th>\n",
              "      <td>[사은, 품, 받으려면, 쿠폰, 몇, 개, 모, 아야, 해, 요, ?]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15823</th>\n",
              "      <td>[쿠폰, 몇, 개, 모으면, 사은, 품, 받을, 수, 있어요, ?]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15824</th>\n",
              "      <td>[쿠폰, 몇, 장, 모, 아야, 사은, 품, 받을, 수, 있나요, ?]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15825</th>\n",
              "      <td>[사은, 품, 받으려면, 쿠폰, 몇, 장, 있어야, 돼요, ?]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15826 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           stc  cate\n",
              "0                 [신발, 은, 여기, 있는, 게, 다예, 요, ?]     0\n",
              "1                      [네, 성인, 이나, 아동, 다, 있어요]     0\n",
              "2                         [발, 사이즈, 몇, 신으세요, ?]     0\n",
              "3                                    [230, 이요]     0\n",
              "4               [편하게, 신, 을, 수, 있는, 거, 찾으세요, ?]     0\n",
              "...                                        ...   ...\n",
              "15821                     [이, 쿠폰, 에, 적립, 해주세요]     2\n",
              "15822  [사은, 품, 받으려면, 쿠폰, 몇, 개, 모, 아야, 해, 요, ?]     2\n",
              "15823    [쿠폰, 몇, 개, 모으면, 사은, 품, 받을, 수, 있어요, ?]     2\n",
              "15824  [쿠폰, 몇, 장, 모, 아야, 사은, 품, 받을, 수, 있나요, ?]     2\n",
              "15825      [사은, 품, 받으려면, 쿠폰, 몇, 장, 있어야, 돼요, ?]     2\n",
              "\n",
              "[15826 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RpJz7TpBrrr",
        "outputId": "d81ef158-e1cf-4e04-b30c-c28bdd5456d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# train, test로 데이터 분리하기\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    category_info['stc'], category_info['cate'], test_size = 0.2, shuffle = True, random_state = 11)\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "print(len(y_train[0]))\n",
        "print(len(y_test[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "405\n",
            "405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjdl4ufTLZeo",
        "outputId": "2ed411b0-07da-4437-8b1f-49a302ff1081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# train, test로 데이터 분리하기\n",
        "rX_train, rX_test, ry_train, ry_test = train_test_split(\n",
        "    rough_info['stc'], rough_info['cate'], test_size = 0.2, shuffle = True, random_state = 11)\n",
        "\n",
        "ry_train = to_categorical(ry_train)\n",
        "ry_test = to_categorical(ry_test)\n",
        "\n",
        "print(len(ry_train[0]))\n",
        "print(len(ry_test[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49xD3bbzB4IB"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# 헤드라인 정수 인코딩\n",
        "tokenizer = Tokenizer(5000) # Tokenizer 객체 생성 -> 아래 셀을 통해 3번 이상 나온 단어의 수가 약 25000개인 것을 알 수 있고, 상위 25000개만 쓰겠다는 뜻으로 인자를 넘긴다.\n",
        "tokenizer.fit_on_texts(X_train) # news_train에 있는 단어에 정수 인코딩\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train) # 실제로 정수 할당\n",
        "X_test = tokenizer.texts_to_sequences(X_test) # 실제로 정수 할당\n",
        "\n",
        "# 이제 headline들이 정수의 배열로 이뤄지게 된다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHhpsrGKLkNK"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# 헤드라인 정수 인코딩\n",
        "rtokenizer = Tokenizer(5000) # Tokenizer 객체 생성 -> 아래 셀을 통해 3번 이상 나온 단어의 수가 약 25000개인 것을 알 수 있고, 상위 25000개만 쓰겠다는 뜻으로 인자를 넘긴다.\n",
        "rtokenizer.fit_on_texts(rX_train) # news_train에 있는 단어에 정수 인코딩\n",
        "\n",
        "rX_train = tokenizer.texts_to_sequences(rX_train) # 실제로 정수 할당\n",
        "rX_test = tokenizer.texts_to_sequences(rX_test) # 실제로 정수 할당\n",
        "\n",
        "# 이제 headline들이 정수의 배열로 이뤄지게 된다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cKaNg07EaXA",
        "outputId": "d5ec3517-aa33-4b21-e3dc-b07dc98861d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(tokenizer.word_index))\n",
        "\n",
        "wc = 0\n",
        "for word, word_count in tokenizer.word_counts.items():\n",
        "    if word_count <= 2:\n",
        "        wc += 1\n",
        "\n",
        "print(wc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5903\n",
            "3642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI9xC0TTLoUx",
        "outputId": "e23a3139-ca17-49dd-ea71-5437175642bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(rtokenizer.word_index))\n",
        "\n",
        "wc = 0\n",
        "for word, word_count in rtokenizer.word_counts.items():\n",
        "    if word_count <= 2:\n",
        "        wc += 1\n",
        "\n",
        "print(wc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5923\n",
            "3671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfSo1zs9H6eg",
        "outputId": "118fcb0e-0fdc-4821-ed8f-04e4e51be848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "len_stc = []\n",
        "for data in X_train:\n",
        "    len_stc.append(len(data))\n",
        "\n",
        "y, x, _ = plt.hist(len_stc, bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlfn1PdGH9Kw"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # 패딩\n",
        "max_len = 15\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYbs1MJzMMa3"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # 패딩\n",
        "max_len = 15\n",
        "rX_train = pad_sequences(rX_train, maxlen=max_len)\n",
        "rX_test = pad_sequences(rX_test, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAhw97pnH_LA"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000, 128))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(405, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FUXrW5KIEo6",
        "outputId": "9e51eaff-7dc8-478e-d213-b6e22366977c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=30) # 128 64 32 실험"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "394/394 [==============================] - 4s 10ms/step - loss: 4.7782 - acc: 0.1243 - val_loss: 4.4085 - val_acc: 0.1603\n",
            "Epoch 2/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 4.1392 - acc: 0.1869 - val_loss: 3.8438 - val_acc: 0.2286\n",
            "Epoch 3/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 3.5103 - acc: 0.2804 - val_loss: 3.4783 - val_acc: 0.2919\n",
            "Epoch 4/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 3.0149 - acc: 0.3501 - val_loss: 3.2393 - val_acc: 0.3396\n",
            "Epoch 5/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 2.6062 - acc: 0.4187 - val_loss: 3.0877 - val_acc: 0.3660\n",
            "Epoch 6/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 2.2599 - acc: 0.4822 - val_loss: 3.0525 - val_acc: 0.3723\n",
            "Epoch 7/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 1.9659 - acc: 0.5449 - val_loss: 3.0089 - val_acc: 0.3835\n",
            "Epoch 8/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 1.7159 - acc: 0.5982 - val_loss: 3.0216 - val_acc: 0.3854\n",
            "Epoch 9/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 1.5059 - acc: 0.6429 - val_loss: 3.0495 - val_acc: 0.3921\n",
            "Epoch 10/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 1.3335 - acc: 0.6835 - val_loss: 3.0298 - val_acc: 0.3994\n",
            "Epoch 11/30\n",
            "394/394 [==============================] - 4s 9ms/step - loss: 1.1824 - acc: 0.7215 - val_loss: 3.0846 - val_acc: 0.3987\n",
            "Epoch 12/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 1.0620 - acc: 0.7498 - val_loss: 3.1254 - val_acc: 0.3997\n",
            "Epoch 13/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.9571 - acc: 0.7734 - val_loss: 3.1859 - val_acc: 0.3914\n",
            "Epoch 14/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.8667 - acc: 0.7949 - val_loss: 3.2605 - val_acc: 0.3994\n",
            "Epoch 15/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.7930 - acc: 0.8107 - val_loss: 3.3129 - val_acc: 0.3914\n",
            "Epoch 16/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.7266 - acc: 0.8259 - val_loss: 3.3753 - val_acc: 0.4003\n",
            "Epoch 17/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.6821 - acc: 0.8328 - val_loss: 3.4310 - val_acc: 0.3930\n",
            "Epoch 18/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.6238 - acc: 0.8488 - val_loss: 3.5045 - val_acc: 0.3943\n",
            "Epoch 19/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.5799 - acc: 0.8607 - val_loss: 3.5857 - val_acc: 0.3917\n",
            "Epoch 20/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.5397 - acc: 0.8652 - val_loss: 3.6381 - val_acc: 0.3955\n",
            "Epoch 21/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.5107 - acc: 0.8748 - val_loss: 3.6759 - val_acc: 0.3946\n",
            "Epoch 22/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.4844 - acc: 0.8808 - val_loss: 3.7648 - val_acc: 0.3844\n",
            "Epoch 23/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.4551 - acc: 0.8872 - val_loss: 3.8248 - val_acc: 0.3882\n",
            "Epoch 24/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.4273 - acc: 0.8943 - val_loss: 3.8958 - val_acc: 0.3857\n",
            "Epoch 25/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.4107 - acc: 0.8970 - val_loss: 3.9305 - val_acc: 0.3838\n",
            "Epoch 26/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.3890 - acc: 0.9025 - val_loss: 4.0539 - val_acc: 0.3851\n",
            "Epoch 27/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.3773 - acc: 0.9067 - val_loss: 4.0388 - val_acc: 0.3857\n",
            "Epoch 28/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.3598 - acc: 0.9075 - val_loss: 4.1782 - val_acc: 0.3822\n",
            "Epoch 29/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.3519 - acc: 0.9102 - val_loss: 4.2000 - val_acc: 0.3800\n",
            "Epoch 30/30\n",
            "394/394 [==============================] - 3s 9ms/step - loss: 0.3452 - acc: 0.9115 - val_loss: 4.2148 - val_acc: 0.3835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3ba3e14780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXs4ctdjMb4i"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "rmodel = Sequential()\n",
        "rmodel.add(Embedding(5000, 100))\n",
        "rmodel.add(LSTM(128))\n",
        "rmodel.add(Dense(4, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN5RpPyVMTpI",
        "outputId": "2012537c-36d3-420b-e25c-aa00f8441fc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "rmodel.fit(rX_train, ry_train, validation_data=(rX_test, ry_test), batch_size=10, epochs=10) # 128 64 32 실험"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1266/1266 [==============================] - 10s 8ms/step - loss: 1.0291 - acc: 0.5422 - val_loss: 0.9048 - val_acc: 0.5973\n",
            "Epoch 2/10\n",
            "1266/1266 [==============================] - 9s 7ms/step - loss: 0.7585 - acc: 0.6827 - val_loss: 0.9014 - val_acc: 0.6105\n",
            "Epoch 3/10\n",
            "1266/1266 [==============================] - 9s 7ms/step - loss: 0.6468 - acc: 0.7288 - val_loss: 0.9354 - val_acc: 0.6134\n",
            "Epoch 4/10\n",
            "1266/1266 [==============================] - 9s 7ms/step - loss: 0.5718 - acc: 0.7571 - val_loss: 0.9977 - val_acc: 0.6074\n",
            "Epoch 5/10\n",
            "1266/1266 [==============================] - 9s 7ms/step - loss: 0.5220 - acc: 0.7750 - val_loss: 1.0850 - val_acc: 0.5960\n",
            "Epoch 6/10\n",
            "1266/1266 [==============================] - 9s 7ms/step - loss: 0.4808 - acc: 0.7909 - val_loss: 1.1458 - val_acc: 0.6131\n",
            "Epoch 7/10\n",
            "1266/1266 [==============================] - 8s 7ms/step - loss: 0.4474 - acc: 0.8040 - val_loss: 1.2742 - val_acc: 0.6014\n",
            "Epoch 8/10\n",
            "1266/1266 [==============================] - 9s 7ms/step - loss: 0.4195 - acc: 0.8137 - val_loss: 1.3610 - val_acc: 0.6083\n",
            "Epoch 9/10\n",
            "1266/1266 [==============================] - 9s 7ms/step - loss: 0.3926 - acc: 0.8264 - val_loss: 1.4608 - val_acc: 0.6014\n",
            "Epoch 10/10\n",
            "1266/1266 [==============================] - 9s 7ms/step - loss: 0.3729 - acc: 0.8333 - val_loss: 1.4877 - val_acc: 0.6058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3b824d9ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iQ_bTr1JrT9",
        "outputId": "4a4ea424-edbf-455e-8393-799acd7cdfdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rmodel.evaluate(rX_test, ry_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99/99 [==============================] - 0s 3ms/step - loss: 2.7616 - acc: 0.5888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.7616019248962402, 0.5887555480003357]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb8zQs8mNueZ"
      },
      "source": [
        "def find_category(stc,tagger,tokenizer,model,category_list):\n",
        "    stc = tagger.morphs(stc)\n",
        "    encode_stc = tokenizer.texts_to_sequences([stc])\n",
        "    pad_stc = pad_sequences(encode_stc, maxlen=15)\n",
        "\n",
        "    score = model.predict(pad_stc)\n",
        "    return (category_list[score.argmax()], score[0, score.argmax()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny-XzbArK31A"
      },
      "source": [
        "위의 두 개 문장은 데이터셋에 없는 문장임에도 잘 분류해낸다. 약 20% 이상의 정확도만 보이면 써도 될 거 같다. 세 번째 문장은 데이터셋에 있는 문장인데 그래서 그런지 굉장히 높은 정확도를 보인다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmdMUjeaImd6",
        "outputId": "548ff559-262e-4370-c06c-2981ac7c34b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentence = \"이 코트에 어울리는 치마 있나요?\"\n",
        "print(find_category(sentence,tagger,tokenizer,model,category_list))\n",
        "sentence = \"같은 디자인으로 혹시 더 저렴한 상품 있나요?\"\n",
        "print(find_category(sentence,tagger,tokenizer,model,category_list))\n",
        "sentence = \"겨울이니까 좀 길게 입으셔야죠\"\n",
        "print(find_category(sentence,tagger,tokenizer,model,category_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b79164e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "('디자인문의', 0.2980443)\n",
            "('제품구매시할인문의', 0.30858043)\n",
            "('착용후어울리는지문의', 0.99896467)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFnPSr_VQSAl",
        "outputId": "0c53228c-4757-42f6-ffb9-9ffe248d2d9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentence = \"이 코트에 어울리는 치마 있나요?\"\n",
        "print(find_category(sentence,tagger,rtokenizer,rmodel,rough_category_list))\n",
        "sentence = \"굽 좀 높은 거 없나요?\"\n",
        "print(find_category(sentence,tagger,rtokenizer,rmodel,rough_category_list))\n",
        "sentence = \"겨울이니까 좀 길게 입으셔야죠\"\n",
        "print(find_category(sentence,tagger,rtokenizer,rmodel,rough_category_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ba4070ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "('가방', 0.96413314)\n",
            "('의류', 0.6966314)\n",
            "('가방', 0.9993899)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6EDnEOwI_G7"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxi2B-vjydzt"
      },
      "source": [
        "# 인덱스를 문장으로 변환\n",
        "def convert_index_to_text(indexs, vocabulary): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == END_INDEX:\n",
        "            # 종료 인덱스면 중지\n",
        "            break;\n",
        "        if vocabulary.get(index) is not None:\n",
        "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
        "            sentence += vocabulary[index]\n",
        "        else:\n",
        "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
        "            sentence.extend([vocabulary[OOV_INDEX]])\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E66RpbXydzy"
      },
      "source": [
        "# 예측을 위한 입력 생성\n",
        "def make_predict_input(sentence):\n",
        "\n",
        "    sentences = []\n",
        "    sentences.append(sentence)\n",
        "    sentences = pos_tag(sentences)\n",
        "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
        "    \n",
        "    return input_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umBNECObKCJj"
      },
      "source": [
        "def evaluate(input_seq):\n",
        "\n",
        "  input_seq = input_seq.squeeze()\n",
        "  sentence = tf.expand_dims(input_seq, axis=0)\n",
        "  output = tf.expand_dims([1], 0)\n",
        "\n",
        "  for i in range(MAX_SEQ):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, 2):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL1ux8vO0ZDZ",
        "outputId": "7c208822-5f5a-4841-843d-289a1a76cf53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(find_category('2만 9천 원 입니다'))\n",
        "print()\n",
        "\n",
        "print('봄옷은 다음주에 나오는데 다음주부터 가게 휴무에요')\n",
        "print(find_category('봄옷은 다음주에 나오는데 다음주부터 가게 휴무에요'))\n",
        "print()\n",
        "\n",
        "print(find_category('카드로 결제하면 부가세 별도에요?'))\n",
        "print(find_category('카드 로 결제 하시겠어요 ?'))\n",
        "print(find_category('그 옷 은 카드 로 구입 하 어 시 이 어 도 부가세 가 붙 지 않 아요'))\n",
        "print(find_category('그 옷 은 카드 로 구입 하 시 어도 부가세 가 붙 지 않 아요' ))\n",
        "print(find_category('네 카드 로 결제 하 시 나요 ? '))\n",
        "print(find_category('그 상품 은 길 이 조절 이 되 지 않 습니다 '))\n",
        "print(find_category('그 옷 은 카드 로 구입 하 시 어도 부가세 가 붙 지 않 아요 '))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('제품가격문의', 0.9999958)\n",
            "\n",
            "봄옷은 다음주에 나오는데 다음주부터 가게 휴무에요\n",
            "('계절상품문의', 0.4106924)\n",
            "\n",
            "('카드결제부가세여부문의', 0.9956285)\n",
            "('결제요청', 0.9995003)\n",
            "('현금할인여부문의', 0.5959313)\n",
            "('카드결제부가세여부문의', 0.5534975)\n",
            "('카드결제부가세여부문의', 0.29437932)\n",
            "('제품특징문의', 0.5574046)\n",
            "('카드결제부가세여부문의', 0.5534975)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_-WH6QHpyIw",
        "outputId": "263915f7-e1cf-4799-b94a-9e937d8c1e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "convert_index_to_text(evaluate(make_predict_input('와이프 선물로 뭐가 좋을까요?')).numpy()[1:],index_to_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-3ec42d988305>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvert_index_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_predict_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'와이프 선물로 뭐가 좋을까요?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_to_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-53b72659f813>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# select the last word from the seq_len dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpredicted_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1194\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10319\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10320\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10321\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10322\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Index out of range using input dim 2; input has only 2 dims [Op:StridedSlice] name: strided_slice/"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXm-SaLezG4b",
        "outputId": "d578bb9e-2fa2-4313-c019-6d0814f1bbbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(find_category('와이프 선물로 뭐가 좋을까요?'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('선물할대상에따른제품문의', 0.9997154)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBxzil_NWNLX",
        "outputId": "28a8ceea-0ce4-4928-9c5e-deddad43ce1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "convert_index_to_text(evaluate(make_predict_input('내일 뭐해요?')).numpy()[1:],index_to_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'내일 은 지금 이 라 , 오래되 과 밤색 었 어요 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUDsxhUxWaa9",
        "outputId": "30f37710-3a55-4f35-e7c4-46703da03f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "convert_index_to_text(evaluate(make_predict_input('이거 사이즈 큰거 있어요?')).numpy()[1:],index_to_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'그 사이즈 99 이상 짜 리 신발 찾 으세요 ? '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFym9Kw4Wkb9",
        "outputId": "50925d8c-9d11-477f-f9a5-620724ccd9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "convert_index_to_text(evaluate(make_predict_input('이거 사이즈 230 있어요?')).numpy()[1:],index_to_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'네 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPixonr7g-FT",
        "outputId": "1f227a94-ea37-4360-face-51f107a8905c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "convert_index_to_text(evaluate(make_predict_input('할인 되요?')).numpy()[1:],index_to_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'네 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3YqOZ-MEOVW",
        "outputId": "3046e8cb-5819-402e-cb0a-0f6ffbd9ee98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# for train data predict\n",
        "for seq_index in range(0,100):\n",
        "\n",
        "  print(\"고객 : \",question[seq_index])\n",
        "  print(find_category(question[seq_index]))\n",
        "  print(\"정답점원 :\",answer[seq_index])\n",
        "  print(find_category(answer[seq_index]))\n",
        "#   print(\"AI점원 :\",convert_index_to_text(evaluate(make_predict_input(question[seq_index])).numpy()[1:],index_to_word))\n",
        "#   print(find_category(convert_index_to_text(evaluate(make_predict_input(question[seq_index])).numpy()[1:],index_to_word)))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "고객 :  신발 은 여기 있 는 것 이 다예 이 요 ?\n",
            "('제품문의', 0.35067263)\n",
            "정답점원 : 네 성인 이나 아동 다 있 어요 발 사이즈 몇 신 으세요 ?\n",
            "('종류별신발제품문의요청', 0.4950419)\n",
            "\n",
            "\n",
            "고객 :  230 이요\n",
            "('종류별신발제품문의요청', 0.8758219)\n",
            "정답점원 : 편하 게 신 을 수 있 는 거 찾 으세요 ?\n",
            "('착화감', 0.646844)\n",
            "\n",
            "\n",
            "고객 :  네 봄 이 니까 편하 게 신 을 수 있 는 거\n",
            "('종류별신발제품문의요청', 0.40536597)\n",
            "정답점원 : 이런 건 어 어 떠세 이 요 ? 이런 거도 신발 무척 편하 거든요\n",
            "('종류별신발제품문의요청', 0.7603986)\n",
            "\n",
            "\n",
            "고객 :  굽 좀 높 은 거 없 나요 ?\n",
            "('굽높이문의', 0.8858914)\n",
            "정답점원 : 봄 상품 은 아직 어른 제품 이 많이 안 나오 았 습니다\n",
            "('종류별의류제품문의요청', 0.60463315)\n",
            "\n",
            "\n",
            "고객 :  언제 들어오 아요 ?\n",
            "('예약제품도착시간문의', 0.21958941)\n",
            "정답점원 : 이번 주 지나 면 들어오 ㄹ 거 이 에요\n",
            "('재입고문의', 0.9052052)\n",
            "\n",
            "\n",
            "고객 :  이거 는 가죽 이 에요 ?\n",
            "('가방소재문의', 0.51853323)\n",
            "정답점원 : 가죽 아니 고 쎄무예 요\n",
            "('가방소재문의', 0.8936109)\n",
            "\n",
            "\n",
            "고객 :  가죽 은 얼마 이 에요 ?\n",
            "('제품가격문의', 0.98395)\n",
            "정답점원 : 2 만 9 천 원 이 ㅂ니다\n",
            "('제품가격문의', 0.5300374)\n",
            "\n",
            "\n",
            "고객 :  털 달리 ㄴ 거 저거 는 사이즈 있 어요 ?\n",
            "('사이즈문의', 0.24792796)\n",
            "정답점원 : 230 이 없 어요 이거 한 번 신 어 보 세요\n",
            "('종류별신발제품문의요청', 0.93864715)\n",
            "\n",
            "\n",
            "고객 :  좀 크 네 또 안 들어오 아요 ?\n",
            "('귀뚫어주는지문의', 0.52474415)\n",
            "정답점원 : 네 이건 다 끝나 었 어요\n",
            "('제품소재문의', 0.51210743)\n",
            "\n",
            "\n",
            "고객 :  가방 매 는 거 보 고 있 어요\n",
            "('종류별신발제품문의요청', 0.64591014)\n",
            "정답점원 : 여기 있 어요\n",
            "('결제요청', 0.17815386)\n",
            "\n",
            "\n",
            "고객 :  가격 이 얼마 이 에요 ?\n",
            "('제품가격문의', 0.9939406)\n",
            "정답점원 : 이 종류 는 2 만 원 이 고 이 종류 는 3 만 8 천 원 이 에요\n",
            "('제품요청', 0.7810639)\n",
            "\n",
            "\n",
            "고객 :  가죽 으로 되 ㄴ 거 는 없 어요 ?\n",
            "('가방소재문의', 0.8145818)\n",
            "정답점원 : 가죽 은 없 고 레 자만 있 어요\n",
            "('가방소재문의', 0.75770634)\n",
            "\n",
            "\n",
            "고객 :  레 자 는 얼마 이 에요 ?\n",
            "('제품가격문의', 0.99877316)\n",
            "정답점원 : 5 만 5 천 원 이 요\n",
            "('제품가격문의', 0.47039402)\n",
            "\n",
            "\n",
            "고객 :  이거 는 천 이 죠 ?\n",
            "('가방소재문의', 0.99673223)\n",
            "정답점원 : 네 맞 아요\n",
            "('제품가격문의', 0.06903539)\n",
            "\n",
            "\n",
            "고객 :  이 건 얼마 이 에요 ?\n",
            "('제품가격문의', 0.99595803)\n",
            "정답점원 : 그것 도 5 만 5 천 원 이 요\n",
            "('다른계절상품문의', 0.56222236)\n",
            "\n",
            "\n",
            "고객 :  이거 끈 은 따로 없 어요 ?\n",
            "('제품구성문의', 0.7552352)\n",
            "정답점원 : 안 에 있 어요\n",
            "('제품정보문의', 0.32585058)\n",
            "\n",
            "\n",
            "고객 :  내일 은 문 열 어요 ?\n",
            "('사이즈문의', 0.7850879)\n",
            "정답점원 : 휴무 이 ㅂ니다\n",
            "('종류별가방제품문의요청', 0.35275117)\n",
            "\n",
            "\n",
            "고객 :  며칠 까지 휴무 이 에요 ?\n",
            "('공휴일영업문의', 0.99614304)\n",
            "정답점원 : 설 까지 쉬 고 다음날 열 ㄹ 거 같 아요\n",
            "('재입고문의', 0.3616068)\n",
            "\n",
            "\n",
            "고객 :  여기 마스크 는 얼마 이 에요 ?\n",
            "('제품가격문의', 0.80153215)\n",
            "정답점원 : 5 천 원 이 요\n",
            "('제품가격문의', 0.8139625)\n",
            "\n",
            "\n",
            "고객 :  이거 나무 이 에요 ? 다 돌 이 ㄴ가요 ?\n",
            "('제품소재문의', 0.7904119)\n",
            "정답점원 : 나무 도 있 고 도자기 도 있 어요\n",
            "('제품소재문의', 0.77981097)\n",
            "\n",
            "\n",
            "고객 :  이런 건 세트 로 팔 아요 ?\n",
            "('사이즈적합여부문의', 0.30696154)\n",
            "정답점원 : 네 세트 로 만 팔 아요\n",
            "('세트제품문의', 0.5806916)\n",
            "\n",
            "\n",
            "고객 :  이 건 뭐 이 에요 ?\n",
            "('가방소재문의', 0.8686081)\n",
            "정답점원 : 마블 이 라고 종이 를 말 아 가지 고 하 는 거 이 에요\n",
            "('제품소재문의', 0.2961735)\n",
            "\n",
            "\n",
            "고객 :  제일 크 ㄴ 거 는 얼마 이 ㄴ데요 ?\n",
            "('제품가격문의', 0.99995387)\n",
            "정답점원 : 세트 에 7 만 원 이요\n",
            "('제품가격문의', 0.9983352)\n",
            "\n",
            "\n",
            "고객 :  스카프 좀 보 려구요\n",
            "('종류별액세서리제품문의요청', 0.9435324)\n",
            "정답점원 : 네 천천히 보 세요\n",
            "('종류별액세서리제품문의요청', 0.79472)\n",
            "\n",
            "\n",
            "고객 :  실크 스카프 도 봄 에 하나 이 요 ?\n",
            "('계절상품문의', 0.98934233)\n",
            "정답점원 : 실크 봄 가을 에 하 죠\n",
            "('계절상품문의', 0.9918235)\n",
            "\n",
            "\n",
            "고객 :  이거 는 뭐 이 에요 ?\n",
            "('가방소재문의', 0.64092606)\n",
            "정답점원 : 토시 이 에요\n",
            "('제품문의', 0.98075986)\n",
            "\n",
            "\n",
            "고객 :  여기 가격 은 그대로 파시 는 거 이 에요 ?\n",
            "('제품가격문의', 0.9976826)\n",
            "정답점원 : 네 핸드 메이드 로 하 어 가지 고 그 가격 으로 팔 아요\n",
            "('색상문의', 0.25151935)\n",
            "\n",
            "\n",
            "고객 :  착용 하 어 보 ㄹ 수 있 어요 ?\n",
            "('매장에서착용문의', 0.6858918)\n",
            "정답점원 : 네 가능 하 세요\n",
            "('현금영수증요청', 0.4485946)\n",
            "\n",
            "\n",
            "고객 :  이거 는 요즘 들어오 ㄴ 거 이 에요 ?\n",
            "('돌제품문의', 0.33321851)\n",
            "정답점원 : 네 어제 들어오 았 어요\n",
            "('현금할인문의', 0.05565163)\n",
            "\n",
            "\n",
            "고객 :  세탁 은 물세탁 되 죠 ?\n",
            "('제품의세척방법문의', 0.6254029)\n",
            "정답점원 : 끝 부분 이 가죽 이 라서 조심 하 어야 하 어요\n",
            "('제품주문', 0.33284673)\n",
            "\n",
            "\n",
            "고객 :  지금 여기 있 는 것 이 다예 이 요 ?\n",
            "('제품문의', 0.98232585)\n",
            "정답점원 : 네 다예 요\n",
            "('제품문의', 0.8529316)\n",
            "\n",
            "\n",
            "고객 :  몇 시 에 문 닫 아요 ?\n",
            "('마감시간문의', 0.95101464)\n",
            "정답점원 : 8 시 까지 하 ㅂ니다\n",
            "('마감시간문의', 0.9920581)\n",
            "\n",
            "\n",
            "고객 :  일요일 도 하 세요 ?\n",
            "('공휴일영업문의', 0.982025)\n",
            "정답점원 : 알 뇨 닫 아요\n",
            "('제품정보문의', 0.15057185)\n",
            "\n",
            "\n",
            "고객 :  스카프 있 어요 ?\n",
            "('종류별액세서리제품문의요청', 0.842842)\n",
            "정답점원 : 네 여기 는 2 단 이거 는 3 단 제품 있 어요\n",
            "('착용후다른사이즈문의', 0.4830261)\n",
            "\n",
            "\n",
            "고객 :  이런 건 세탁 을 어떻 게 하 어요 ?\n",
            "('제품의세탁방법문의', 0.5004208)\n",
            "정답점원 : 울 ㄹ 샴푸 를 물 에 몇 방울 떨어뜨리 어서 조물 조물 하 면 되 ㅂ니다\n",
            "('제품의세척방법문의', 0.77643114)\n",
            "\n",
            "\n",
            "고객 :  원단 은 뭐 이 에요 ?\n",
            "('원단문의', 0.7088112)\n",
            "정답점원 : 원단 이 구김 안 가 고 참 괜찮 아요\n",
            "('다른계절상품문의', 0.23699492)\n",
            "\n",
            "\n",
            "고객 :  얼마 이 ㄴ데요 ?\n",
            "('제품가격문의', 0.99887246)\n",
            "정답점원 : 2 만 원 이 ㅂ니다\n",
            "('제품가격문의', 0.9534252)\n",
            "\n",
            "\n",
            "고객 :  브로치 같 은 것 은 어디 있 나요 ?\n",
            "('종류별액세서리제품문의요청', 0.99968743)\n",
            "정답점원 : 여기 있 는 거 밖에 없 어요\n",
            "('종류별액세서리제품문의요청', 0.8530277)\n",
            "\n",
            "\n",
            "고객 :  이런 거도 2 만 원 이 에요 ?\n",
            "('제품가격문의', 0.99896145)\n",
            "정답점원 : 헤 르 메스 이 ㄴ데 이것 도 괜찮 아요\n",
            "('제품가격문의', 0.20437413)\n",
            "\n",
            "\n",
            "고객 :  명품 이랑 똑같이 하 ㄴ 거 이 에요 ?\n",
            "('디자인문의', 0.8130322)\n",
            "정답점원 : 네 원단 만 다르 고 디자인 을 똑같이 만들 ㄴ 거 이 에요\n",
            "('종류별액세서리제품문의요청', 0.7491974)\n",
            "\n",
            "\n",
            "고객 :  온누리 상품권 도 되 죠 ?\n",
            "('상품권사용문의', 0.99886274)\n",
            "정답점원 : 네 되 ㅂ니다\n",
            "('방수제품문의', 0.42873433)\n",
            "\n",
            "\n",
            "고객 :  브로치 하 고 머리핀 하 고 보 려고요\n",
            "('종류별액세서리제품문의요청', 0.99951816)\n",
            "정답점원 : 머리핀 은 밖 에 있 고 브로치 는 안 에 있 습니다\n",
            "('종류별액세서리제품문의요청', 0.9997745)\n",
            "\n",
            "\n",
            "고객 :  도자기 같 은 거 말 고 구슬 이나 진주 같 은 거 는 없 어요 ?\n",
            "('소재를제시한제품문의', 0.9059617)\n",
            "정답점원 : 지금 옷 에 가볍 게 하 려면 진주 도 예쁘 지만 이것 도 깔끔 하 ㅂ니다 보석 은 싫 으세요 ?\n",
            "('할인여부문의', 0.7727321)\n",
            "\n",
            "\n",
            "고객 :  그 건 흥미 없 고 안 에 하면 안 떨어지 어요 ?\n",
            "('종류별액세서리제품문의요청', 0.9372456)\n",
            "정답점원 : 안 떨어지 어요\n",
            "('제품정보문의', 0.07145076)\n",
            "\n",
            "\n",
            "고객 :  얼마 이 에요 ?\n",
            "('제품가격문의', 0.9961727)\n",
            "정답점원 : 핀 꼽 는 거 는 좀 쌓 ㄴ 거 이 고 이거 는 3 만 원대 이 에요\n",
            "('제품소재문의', 0.9736468)\n",
            "\n",
            "\n",
            "고객 :  이 우산 은 얼마 이 ㄴ데요 ?\n",
            "('제품가격문의', 0.9960239)\n",
            "정답점원 : 4 만 2 천 원 이요\n",
            "('제품가격문의', 0.46946138)\n",
            "\n",
            "\n",
            "고객 :  무겁 지 않 아요 ?\n",
            "('제품종류문의', 0.17376089)\n",
            "정답점원 : 좋 은 재료 를 쓰 기 때문 에 무겁 지 않 아요\n",
            "('종류별액세서리제품문의요청', 0.5378958)\n",
            "\n",
            "\n",
            "고객 :  이렇 게 달 는 거 맞 아요 ?\n",
            "('굽문의', 0.26118168)\n",
            "정답점원 : 그렇 게 달 면 안되 고 이렇게 닫 아야 하 어요\n",
            "('종류별액세서리제품문의요청', 0.30617458)\n",
            "\n",
            "\n",
            "고객 :  자석 은 다 3 만 원 ?\n",
            "('제품가격문의', 0.5338046)\n",
            "정답점원 : 3 만 원 짜리 도 있 고 2 만 원 짜리 도 있 어요\n",
            "('할인여부문의', 0.7644035)\n",
            "\n",
            "\n",
            "고객 :  머리핀 종류 도 한 번 보여주 세요 곱창 은 요새 안 나오 아요 ?\n",
            "('종류별액세서리제품문의요청', 0.7542898)\n",
            "정답점원 : 곱창 밴드 는 안 나오 아요 촌스럽 어서 유행 다 지나 었 어요\n",
            "('종류별액세서리제품문의요청', 0.99688596)\n",
            "\n",
            "\n",
            "고객 :  브로치 종류 도 있 어요 ?\n",
            "('종류별액세서리제품문의요청', 0.99991775)\n",
            "정답점원 : 알 뇨 없 어요\n",
            "('제품정보문의', 0.15057185)\n",
            "\n",
            "\n",
            "고객 :  스카프 도 없 어요 ?\n",
            "('종류별액세서리제품문의요청', 0.97511274)\n",
            "정답점원 : 스카프 는 이쪽 에 종류 가 있 어요\n",
            "('종류별액세서리제품문의요청', 0.94836414)\n",
            "\n",
            "\n",
            "고객 :  이렇 ㄴ 거 실크 이 ㅂ니까 ?\n",
            "('가방소재문의', 0.8736183)\n",
            "정답점원 : 실크 아니 에요\n",
            "('가방소재문의', 0.73767823)\n",
            "\n",
            "\n",
            "고객 :  이렇 ㄴ 거 는 뭐 이 라 그리하 여요 ?\n",
            "('옷감문의', 0.9380218)\n",
            "정답점원 : 실캣 으로 만들 ㄴ 것 이 죠\n",
            "('제품하자발견시요구', 0.1851799)\n",
            "\n",
            "\n",
            "고객 :  이렇 ㄴ 거 는 얼마 이 에요 ?\n",
            "('제품가격문의', 0.9994844)\n",
            "정답점원 : 대충 2 만 원 내외 요\n",
            "('제품가격문의', 0.9877145)\n",
            "\n",
            "\n",
            "고객 :  이렇 ㄴ 거 는 물세탁 되 ㅂ니까 ?\n",
            "('제품의세척방법문의', 0.65953463)\n",
            "정답점원 : 물세탁 조금 하 어도 상관 은 없 으세요\n",
            "('제품의세탁방법문의', 0.39728928)\n",
            "\n",
            "\n",
            "고객 :  근데 이거 제가 한 거 아니 ㄴ데 약간 올 이 나가 었 네요\n",
            "('제품차이문의', 0.2020093)\n",
            "정답점원 : 이거 원하 시 면 주문 가능 하 세요\n",
            "('운영기간문의', 0.3553738)\n",
            "\n",
            "\n",
            "고객 :  또 언제 들어오 아요 ?\n",
            "('제품입고문의', 0.7062733)\n",
            "정답점원 : 스카프 는 많이 들어오 지 않 아서 주문 하 시 는 것 이 좋 아요\n",
            "('제조사문의', 0.33150312)\n",
            "\n",
            "\n",
            "고객 :  이거 는 목걸이 링 이 에요 ?\n",
            "('제품문의', 0.7835216)\n",
            "정답점원 : 알 뇨 반지 이 에요\n",
            "('제품가격문의', 0.26757607)\n",
            "\n",
            "\n",
            "고객 :  금 이 에요 ?\n",
            "('제품소재문의', 0.42841783)\n",
            "정답점원 : 액세서리 예 요 금 아니 에요\n",
            "('제품소재문의', 0.7521936)\n",
            "\n",
            "\n",
            "고객 :  이거 한 번 해보 아도 되 어요 ?\n",
            "('고객사이즈제시에따른제품선택문의', 0.48641393)\n",
            "정답점원 : 네 가능 하 ㅂ니다\n",
            "('현금영수증요청', 0.4485946)\n",
            "\n",
            "\n",
            "고객 :  신 상품 더 들어오 죠 ?\n",
            "('신상품문의', 0.88955694)\n",
            "정답점원 : 네 들어오 ㄹ 거 이 에요\n",
            "('제품소재문의', 0.7536145)\n",
            "\n",
            "\n",
            "고객 :  이 모양 으로 목걸이 팔찌 세트 구입 하 ㄹ까 하 는데\n",
            "('세트제품개별구매문의', 0.30367047)\n",
            "정답점원 : 똑같 은 모양 은 주문 을 넣 어야 하 ㄹ 거 같 은데요\n",
            "('사이즈문의', 0.4589179)\n",
            "\n",
            "\n",
            "고객 :  가격 은 어떻 게 되 어요 ?\n",
            "('제품가격문의', 0.9923624)\n",
            "정답점원 : 모양 을 보 고 견적 을 내보 아야 하 어요\n",
            "('선물할대상에따른제품문의', 0.96637315)\n",
            "\n",
            "\n",
            "고객 :  이 금 팔찌 는 무게 가 얼마 정도 이 ㄴ지 확인 하 ㄹ 수 있 어요 ?\n",
            "('세트제품개별구매문의', 0.35573345)\n",
            "정답점원 : 세 돈 이 조금 넘 네요\n",
            "('금함량문의', 0.84956014)\n",
            "\n",
            "\n",
            "고객 :  견본 이 ㄴ 팔찌 가 있 어요 ?\n",
            "('견본제품문의', 0.89372736)\n",
            "정답점원 : 여기 있 습니다\n",
            "('결제요청', 0.17815386)\n",
            "\n",
            "\n",
            "고객 :  여기 는 금 매입 도 하 어요 ?\n",
            "('금매입문의', 0.9752187)\n",
            "정답점원 : 네 하 어요\n",
            "('제품별색깔종류문의', 0.22858399)\n",
            "\n",
            "\n",
            "고객 :  이거 파 ㄴ다고 얼마 정도 받 을 수 있 어요 ?\n",
            "('제품가격문의', 0.8339654)\n",
            "정답점원 : 대충 39 만 3 천 원 정도 나오 네요\n",
            "('가격임의할인요구', 0.35695258)\n",
            "\n",
            "\n",
            "고객 :  팔찌 두 돈 짜리 도 한 번 보여주 시 고 다른 거 도 보여주 세요\n",
            "('수제품문의', 0.58366686)\n",
            "정답점원 : 유행 하 는 로즈 골드 하 시 어도 되 고 골드 하 시 어도 되 어요\n",
            "('종류별액세서리제품문의요청', 0.74996024)\n",
            "\n",
            "\n",
            "고객 :  가격 이 구입 하 려면 얼마 이 ㄴ데요 ?\n",
            "('제품가격문의', 0.5362021)\n",
            "정답점원 : 현금 가격 기준 으로 62 만 9 천 원 이요\n",
            "('제품가격문의', 0.9191564)\n",
            "\n",
            "\n",
            "고객 :  이거 18 케이 이 에요 ?\n",
            "('금함량문의', 0.998128)\n",
            "정답점원 : 네 18 케이 이 에요\n",
            "('금함량문의', 0.9964927)\n",
            "\n",
            "\n",
            "고객 :  시내 에 있 는 금 도매상 하 고 여기 랑 가격 차이 가 많이 나 아요 ?\n",
            "('주문제작문의', 0.31044587)\n",
            "정답점원 : 그쪽 은 유지비 가 많이 나가 니까 아무래도 여기 가 더 싸 죠\n",
            "('다른매장과가격비교문의', 0.4794614)\n",
            "\n",
            "\n",
            "고객 :  액세서리 세일 제품 이 있 나요 ?\n",
            "('세일품목문의', 0.9011348)\n",
            "정답점원 : 악세서리 어떤 거 찾 으세요 ?\n",
            "('종류별액세서리제품문의요청', 0.9992854)\n",
            "\n",
            "\n",
            "고객 :  스카프 같 은 거\n",
            "('종류별액세서리제품문의요청', 0.97939396)\n",
            "정답점원 : 이거 괜찮 아요\n",
            "('제품문의', 0.25969386)\n",
            "\n",
            "\n",
            "고객 :  이 건 소재 가 뭐 이 에요 ?\n",
            "('가방소재문의', 0.87513417)\n",
            "정답점원 : 폴리에스테르 라고 적히 어 있 네요\n",
            "('옷감문의', 0.7373175)\n",
            "\n",
            "\n",
            "고객 :  색상 은 이거 하나 뿐 이 고 ?\n",
            "('색상에대한문의', 0.9525022)\n",
            "정답점원 : 네 다 빠지 고 이거 하나 이 에요\n",
            "('색상에대한문의', 0.7922357)\n",
            "\n",
            "\n",
            "고객 :  빨 면 좀 그렇 지 않 을까 ?\n",
            "('구제품세탁여부문의', 0.56047887)\n",
            "정답점원 : 조심 하 어야 하 는데 면 이 아니 니까 집 에서 손 드라이 하 어도 되 어요\n",
            "('제품의세탁방법문의', 0.9694883)\n",
            "\n",
            "\n",
            "고객 :  이거 는 가격 이 얼마 이 에요 ?\n",
            "('제품가격문의', 0.99939775)\n",
            "정답점원 : 16000 원 이 ㄴ데 몇 천 원 빼드릴게 요\n",
            "('제품사용기간문의', 0.2733749)\n",
            "\n",
            "\n",
            "고객 :  이 건 얼마 이 에요 ?\n",
            "('제품가격문의', 0.99595803)\n",
            "정답점원 : 13000 원 이 ㅂ니다\n",
            "('제품가격문의', 0.8321538)\n",
            "\n",
            "\n",
            "고객 :  이 핑크색 모자 는 애기 들 꺼 이 에요 ?\n",
            "('종류별의류제품문의요청', 0.60306454)\n",
            "정답점원 : 애기 용 이 ㅂ니다\n",
            "('종류별액세서리제품문의요청', 0.9981263)\n",
            "\n",
            "\n",
            "고객 :  어른 들 꺼 는 없 어요 ?\n",
            "('사이즈재고문의', 0.3426818)\n",
            "정답점원 : 다 빠지 었 어요\n",
            "('제품정보문의', 0.20322315)\n",
            "\n",
            "\n",
            "고객 :  팔찌 제품 따로 있 나요 ?\n",
            "('제품문의', 0.68612444)\n",
            "정답점원 : 고객 님 이 하 시 ㄹ 거 이 에요 ?\n",
            "('종류별액세서리제품문의요청', 0.39685205)\n",
            "\n",
            "\n",
            "고객 :  네 지금 세일 기간 이 에요 ?\n",
            "('세일기간문의', 0.995044)\n",
            "정답점원 : 네 당 분간 은 하 ㄹ 거 같 아요\n",
            "('알레르기유무문의', 0.23739503)\n",
            "\n",
            "\n",
            "고객 :  하 ㄴ 몇 프로 하 는데요 ?\n",
            "('할인여부문의', 0.94442886)\n",
            "정답점원 : 정가 에서 한 40 프로 하 ㅂ니다\n",
            "('할인여부문의', 0.994323)\n",
            "\n",
            "\n",
            "고객 :  이거 는 가격대 가 얼마 이 에요 ?\n",
            "('제품가격문의', 0.7643565)\n",
            "정답점원 : 이거 샘플 이 14 케이 이 ㄴ데 무엇 을 로 보 아 드리 ㄹ까요 ?\n",
            "('소재를제시한제품문의', 0.8484883)\n",
            "\n",
            "\n",
            "고객 :  18 케이 로\n",
            "('종류별액세서리제품문의요청', 0.39590102)\n",
            "정답점원 : 18 케이 로 하 시 면 49 만 원 이요\n",
            "('종류별액세서리제품문의요청', 0.40538993)\n",
            "\n",
            "\n",
            "고객 :  팔찌 좀 핫 하 ㄴ 제품 뭐 가 있 어요 ?\n",
            "('베스트상품문의', 0.36836356)\n",
            "정답점원 : 깔끔 하 게 이렇 ㄴ 거 잘 나 가요\n",
            "('베스트상품문의', 0.4183917)\n",
            "\n",
            "\n",
            "고객 :  18 케이 이 에요 ?\n",
            "('금함량문의', 0.99022293)\n",
            "정답점원 : 네 맞 아요\n",
            "('제품가격문의', 0.06903539)\n",
            "\n",
            "\n",
            "고객 :  돈수 로 따지 면 몇 돈 이 에요 ?\n",
            "('금함량문의', 0.9839829)\n",
            "정답점원 : 두 돈 반 조금 안되 어요\n",
            "('종류별액세서리제품문의요청', 0.8846313)\n",
            "\n",
            "\n",
            "고객 :  얼마 이 에요 ?\n",
            "('제품가격문의', 0.9961727)\n",
            "정답점원 : 48 만 원 정도 요\n",
            "('제품가격문의', 0.9832736)\n",
            "\n",
            "\n",
            "고객 :  굵 은 것 이 이거 다예 이 요 ?\n",
            "('제품사용방법문의', 0.42127767)\n",
            "정답점원 : 5 돈 6 돈 짜리 도 있 어요 굵 은 거 찾 으시 면 이런 건 어 어 떠세 이 요 ?\n",
            "('입을수있는기간문의', 0.8056827)\n",
            "\n",
            "\n",
            "고객 :  너무 사치 스럽 ㄴ데 핸드폰 케이스 팔 는 거 이 에요 ?\n",
            "('소재문의', 0.37044054)\n",
            "정답점원 : 네 맞 습니다\n",
            "('제품가격문의', 0.06903539)\n",
            "\n",
            "\n",
            "고객 :  여기 는 가격 이 어떻 ㄴ 것 이 있 어요 ?\n",
            "('제품가격문의', 0.9774664)\n",
            "정답점원 : 기종 이 어떻 게 되 죠 ?\n",
            "('가방소재문의', 0.8373993)\n",
            "\n",
            "\n",
            "고객 :  엘 지이 ㄴ 데\n",
            "('제품문의', 0.119694375)\n",
            "정답점원 : 마 ㄴ 오천 원대 부터 시작하 어서 이만 오 천 원 까지 있 습니다\n",
            "('제품가격문의', 0.999918)\n",
            "\n",
            "\n",
            "고객 :  그 건 얼마 이 에요 ?\n",
            "('제품가격문의', 0.9808367)\n",
            "정답점원 : 3 만 원 정도 하 어요\n",
            "('제품별색깔종류문의', 0.4577264)\n",
            "\n",
            "\n",
            "고객 :  색상 은 이것 이 전부 이 에요 ?\n",
            "('제품별색깔종류문의', 0.6037152)\n",
            "정답점원 : 레드 색 이 ㄴ데 핑크 도 있 고 보랏빛 퍼플색 도 있 고 색상 종류 가 다양 하 어요\n",
            "('제품별색깔종류문의', 0.6456204)\n",
            "\n",
            "\n",
            "고객 :  엘 지 지 식스 케이스 로 좀 보여주 세요\n",
            "('결제요청', 0.66852623)\n",
            "정답점원 : 그 기종 은 여기 있 어요\n",
            "('제품특징문의', 0.30267084)\n",
            "\n",
            "\n",
            "고객 :  이 건 얼마 이 에요 ?\n",
            "('제품가격문의', 0.99595803)\n",
            "정답점원 : 3 만 5 천 원 이 ㅂ니다\n",
            "('제품소재문의', 0.47105137)\n",
            "\n",
            "\n",
            "고객 :  현금 으로 사면 할인 이 되 ㄴ다 거나 그렇 ㄴ 것 이 있 나요 ?\n",
            "('제품가격문의', 0.99797815)\n",
            "정답점원 : 현금 으로 하면 좀 디 씨 하 어 드리 어요\n",
            "('가격제한시선택문의', 0.4181607)\n",
            "\n",
            "\n",
            "고객 :  반지 이거 세 척 가능 하 어요 ?\n",
            "('현금영수증요청', 0.9351101)\n",
            "정답점원 : 월요일 에 하 어야 하 어요\n",
            "('계절상품문의', 0.17150715)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYv7EewQhIAd"
      },
      "source": [
        "## Test data prediction\n",
        " - 문장중 14900행부터의 문장 100개에 대한 예측."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uZiQH0Ziu_h"
      },
      "source": [
        "test_question_arr = []\n",
        "test_question = \"\"\n",
        "\n",
        "for i in range(14900,wear_data.shape[0]):\n",
        "        test_question = wear_data.iloc[i].SENTENCE\n",
        "        test_question_arr.append(test_question)\n",
        "\n",
        "# test_question_arr = pos_tag(test_question_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RroUo2wthdA-",
        "outputId": "f3c00a37-c8a6-472a-8b64-2c7368ac005f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# for train data predict\n",
        "for seq_index in range(0,100):\n",
        "\n",
        "  print(\"고객 : \",test_question_arr[seq_index])\n",
        "  print(\"AI점원 :\",convert_index_to_text(evaluate(make_predict_input(test_question_arr[seq_index])).numpy()[1:],index_to_word))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "고객 :  구제는 뭐예요?\n",
            "AI점원 : 그 깃털 소재 는 밍크 이 에요 \n",
            "\n",
            "\n",
            "고객 :  구제 옷도 있네요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  구제품은 다 세탁해서 나온 거예요?\n",
            "AI점원 : 네 , 세탁기 로 나오 는 제품 이 에요 \n",
            "\n",
            "\n",
            "고객 :  이건 다 세탁이 된 거죠?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  구제품은 세탁해서 파시는 건가요?\n",
            "AI점원 : 네 그렇 습니다 \n",
            "\n",
            "\n",
            "고객 :  구제품은 다 세탁해서 나오는 거겠죠?\n",
            "AI점원 : 네 , 다 다르 ㄴ 거 있 어요 \n",
            "\n",
            "\n",
            "고객 :  카드로 결제하면 부가세 별도에요?\n",
            "AI점원 : 그 옆 에 가격 같 은 경우 에 오시 면 되 ㅂ니다 \n",
            "\n",
            "\n",
            "고객 :  카드는 부가세 별도로 붙나요?\n",
            "AI점원 : 그 제품 은 카드 로 구입 하 시 어도 부가세 가 똑같 아요 \n",
            "\n",
            "\n",
            "고객 :  카드 결제하면 부가세 추가되나요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  카드로 하면 부가세 붙어요?\n",
            "AI점원 : 흰색 은 카드 로 하 시 면 이 더 붙 어요 \n",
            "\n",
            "\n",
            "고객 :  포인트 적립되는 거 뭐 있어요?\n",
            "AI점원 : 내일 모레 까지 이 에요 \n",
            "\n",
            "\n",
            "고객 :  이거 적립되죠?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  몸에 딱 붙는 옷인가요?\n",
            "AI점원 : 그 옷 은 프리 에 요 \n",
            "\n",
            "\n",
            "고객 :  몸에 딱 붙는 티셔츠 있어요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  원피스 중에 몸에 딱 붙는 건 없어요?\n",
            "AI점원 : 다 나가 었 어요 \n",
            "\n",
            "\n",
            "고객 :  할인 코너는 어디에요?\n",
            "AI점원 : 여기 하고 바깥쪽 에 있 는 할인 아니 에요 \n",
            "\n",
            "\n",
            "고객 :  할인 코너는 어디에 있어요?\n",
            "AI점원 : 여기 는 30 프로 에 있 어요 \n",
            "\n",
            "\n",
            "고객 :  할인 코너는 따로 없어요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  할인 코너는 어느 쪽에 있나요?\n",
            "AI점원 : 네 통신사 카드 로 부터 할인 되 어 있 어요 \n",
            "\n",
            "\n",
            "고객 :  영업은 매일 하시나요?\n",
            "AI점원 : 네 , 오늘 은 여덟 은 여덟 은 여덟 은 없 어요 \n",
            "\n",
            "\n",
            "고객 :  내일도 영업해요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  매일 영업하시는 건가요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  내일도 영업하시죠?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  카드가로 얼마예요?\n",
            "AI점원 : 카드 결제 로 하 면 6 만 원 까지 하 어 드리 어요 \n",
            "\n",
            "\n",
            "고객 :  카드로 결제하면 얼만데요?\n",
            "AI점원 : 그 상품 은 카드 결제 하 시 었 어요 \n",
            "\n",
            "\n",
            "고객 :  카드로 하면 얼마예요?\n",
            "AI점원 : 카드 결제 하 시 면 6 만 원 까지 하 어 드리 어요 \n",
            "\n",
            "\n",
            "고객 :  이 티셔츠는 엉덩이까지 내려오나요?\n",
            "AI점원 : 무지 티셔츠 도 스몰 사이즈 로 만들 었 어요 \n",
            "\n",
            "\n",
            "고객 :  바지 길이가 좀 짧아 보이는데요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이 원피스는 무릎까지 내려올까요?\n",
            "AI점원 : 그 제품 은 현재 품절 이 에요 \n",
            "\n",
            "\n",
            "고객 :  요새 입을 만한 옷으로 뭐가 좋을까요?\n",
            "AI점원 : 저 옷 은 저 랑 지금 모자 랑 사이즈 중 에 블루 가 있 는 거 에 블루 가 없 어요 \n",
            "\n",
            "\n",
            "고객 :  원피스 중에 잘 나가는 걸로 몇 개 추천해주실래요?\n",
            "AI점원 : 제일 잘 나가 ㅂ니다 . \n",
            "\n",
            "\n",
            "고객 :  이거 국산이에요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  중국에서 만든 거예요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이거보다 저렴한 거로 보여주세요\n",
            "AI점원 : 그럼 이 건 어 떠세 이 요 ? \n",
            "\n",
            "\n",
            "고객 :  5만 원 이하로는 없어요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  20만 원 정도 하는 건 없나요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이거보다 한 사이즈 더 큰 걸로 주세요\n",
            "AI점원 : 네 더 필요 하 시 ㄴ 건 없 으시 ㄴ가요 ? \n",
            "\n",
            "\n",
            "고객 :  여기 말고 근처에 다른 옷 가게 또 있어요?\n",
            "AI점원 : 그러 ㄴ 거 없이 다 보이 어 드리 ㄹ게요 \n",
            "\n",
            "\n",
            "고객 :  근처에 신발 가게 있나요?\n",
            "AI점원 : 지금 은 품절 이 ㅂ니다 . \n",
            "\n",
            "\n",
            "고객 :  주변에 편의점 혹시 있나요?\n",
            "AI점원 : 베이지 블랙 컬러 로 보이 어 드리 고 있 습니다 \n",
            "\n",
            "\n",
            "고객 :  이거는 왜 할인하는 거예요?\n",
            "AI점원 : 그 건 이월 상품 이 ㄴ데 , 할인 하 어서 할인 하 고 사이즈 가 많 아요 \n",
            "\n",
            "\n",
            "고객 :  이월 상품이라 할인하는 건가요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  신상품인 거 같은데 왜 할인해요?\n",
            "AI점원 : 신 상품 은 할인 하 고 있 어요 \n",
            "\n",
            "\n",
            "고객 :  이거는 왜 싸게 파시는 거예요?\n",
            "AI점원 : 원래 는 27 만 원 이 에요 \n",
            "\n",
            "\n",
            "고객 :  오픈한 지 얼마나 되셨어요?\n",
            "AI점원 : 그 게 팔 아요 \n",
            "\n",
            "\n",
            "고객 :  오픈한 지 오래되셨나요?\n",
            "AI점원 : 카드 결제 시 었 나요 ? \n",
            "\n",
            "\n",
            "고객 :  영업은 몇 시부터 몇 시까지 하시나요?\n",
            "AI점원 : 아홉 시 까지 영업 하 어요 \n",
            "\n",
            "\n",
            "고객 :  이거는 어떻게 입는 건가요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  주름 있는 쪽이 앞인가요?\n",
            "AI점원 : 네 , 이쪽 에 있 습니다 . \n",
            "\n",
            "\n",
            "고객 :  지퍼가 뒤쪽으로 가게 입는 거 맞죠?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  티셔츠처럼 위쪽으로 입으면 되나요?\n",
            "AI점원 : 그러 면 뭐 자켓 안 에 가시 면 되 ㅂ니다 \n",
            "\n",
            "\n",
            "고객 :  거울은 어디에 있어요?\n",
            "AI점원 : 왼쪽 라인 은 이쪽 에 있 어요 \n",
            "\n",
            "\n",
            "고객 :  거울에 좀 비춰보고 싶은데요\n",
            "AI점원 : 네 특별히 찾 으시 는 색상 있 으시 ㄴ가요 ? \n",
            "\n",
            "\n",
            "고객 :  거울 좀 비춰 주세요\n",
            "AI점원 : 네 이건 49000 원 이 에요 \n",
            "\n",
            "\n",
            "고객 :  키가 좀 큰 사람들은 어떻게 입나요?\n",
            "AI점원 : 이런 랑 가 크 ㄴ 것 으로 찾 으시 는 것 이 ㄴ가요 ? \n",
            "\n",
            "\n",
            "고객 :  남학생들도 많이 입나요?\n",
            "AI점원 : 대학생 들 은 주로 로 입 고 , 많이 입 을 수 있 습니다 . \n",
            "\n",
            "\n",
            "고객 :  여자들이 좋아하나요?\n",
            "AI점원 : 네 어떤 거 찾 으세요 ? \n",
            "\n",
            "\n",
            "고객 :  남자들이 좋아하나요?\n",
            "AI점원 : 남자 들 은 검은색 밖에 없 어요 \n",
            "\n",
            "\n",
            "고객 :  남자들이 많이 찾는 바지는 어떤거예요?\n",
            "AI점원 : 남자 바지 는 이것 이 더 굵 은 것 이 에요 \n",
            "\n",
            "\n",
            "고객 :  현금 결제만 되나요?\n",
            "AI점원 : 현금 결제 하 시 면 DC 하 시 면 DC 하 시 면 DC 하 시 면 DC 하 시 면 DC 하 시 면 DC 되 ㅂ니다 . \n",
            "\n",
            "\n",
            "고객 :  계좌 이체도 가능한가요?\n",
            "AI점원 : 네 , 가능 하 ㅂ니다 . \n",
            "\n",
            "\n",
            "고객 :  아동복 매장 맞지요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  땀 흡수 잘 되고 시원한 옷 있나요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  손으로 직접 만드시는 거예요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  여기에다 직접 수 놓으신 거예요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  다 손으로 하신 거예요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  수입품이죠?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이게 수입 제품 인가 봐요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  수입품 맞아요?\n",
            "AI점원 : 표시 는 안 나 고 손질 \n",
            "\n",
            "\n",
            "고객 :  수입품은 어디에 있어요?\n",
            "AI점원 : 여기 에 있 습니다 \n",
            "\n",
            "\n",
            "고객 :  이 바지도 수입품인가요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이 원피스도 수입이에요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  수입품으로 보여주세요\n",
            "AI점원 : 네 여기 있 습니다 \n",
            "\n",
            "\n",
            "고객 :  얼마 못 입을 것 같은데요?\n",
            "AI점원 : 2 만 원 이 ㅂ니다 \n",
            "\n",
            "\n",
            "고객 :  잘 관리하면 오래 입을 수 있나요?\n",
            "AI점원 : 네 가능 하 ㅂ니다 \n",
            "\n",
            "\n",
            "고객 :  유행이 지나면 못 입겠죠?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  몇 년 동안 입을 수도 있나요?\n",
            "AI점원 : 정가 에서 한 벌 에 한 벌 까지 가능 하 ㅂ니다 \n",
            "\n",
            "\n",
            "고객 :  저기 진열된 거 판매하시는 거예요?\n",
            "AI점원 : 네 , 그럼 요 \n",
            "\n",
            "\n",
            "고객 :  밖에 진열돼있는 옷 보고 싶은데요\n",
            "AI점원 : 네 , 어떤 스타일 로 찾 으세요 ? \n",
            "\n",
            "\n",
            "고객 :  사이즈가 66 맞아요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  사이즈 55 맞나요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  사이즈 77 이네요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  사이즈 S 네요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이월 상품으로 보여주세요\n",
            "AI점원 : 네 잠시 만 기다리 어 주 세요 \n",
            "\n",
            "\n",
            "고객 :  이월 상품으로 볼 수 있을까요?\n",
            "AI점원 : 잠시 만 기다리 어 주 세요 . \n",
            "\n",
            "\n",
            "고객 :  어깨가 너무 좁아 보이지 않는 옷으로 보여주세요\n",
            "AI점원 : 이 건 어 떠세 이 요 ? \n",
            "\n",
            "\n",
            "고객 :  다리가 날씬해 보이는 옷 좀 보여주실래요?\n",
            "AI점원 : 그 옷 은 현재 재 이 고 현금 이 에요 \n",
            "\n",
            "\n",
            "고객 :  뚱뚱해 보이지 않는 옷 좀 보려고요\n",
            "AI점원 : 고객 님 이 입 으시 는 스타일 로 이렇 ㄴ 옷 은 어떻 게 보이 어 보 세요 ? \n",
            "\n",
            "\n",
            "고객 :  입고 온 옷은 싸주실 수 있나요?\n",
            "AI점원 : 예 , 그러 ㄴ 옷 은 지금 저 면 지금 40 프로 할인 중 이 에요 \n",
            "\n",
            "\n",
            "고객 :  입고 온 옷은 담아 주시겠어요?\n",
            "AI점원 : 이 옷 은 일자 남방 이 라 밖 에 없 어요 \n",
            "\n",
            "\n",
            "고객 :  이거 입고 갈게요 제 옷은 담아주세요\n",
            "AI점원 : 그 옷 작 은 사이즈 는 거 괜찮 으시 ㄴ가요 ? \n",
            "\n",
            "\n",
            "고객 :  새 옷으로 입고 가게 제 옷은 넣어주세요\n",
            "AI점원 : 그 옷 은 55 사이즈 밖 에 괜찮 아요 \n",
            "\n",
            "\n",
            "고객 :  화장실은 어디에 있을까요?\n",
            "AI점원 : 여기 있 습니다 \n",
            "\n",
            "\n",
            "고객 :  화장실은 어느 쪽에 있어요?\n",
            "AI점원 : 맨투맨 은 이쪽 이 ㅂ니다 \n",
            "\n",
            "\n",
            "고객 :  화장실 밖에 있나요?\n",
            "AI점원 : 네 , 이 건 어떠신가 요 ? \n",
            "\n",
            "\n",
            "고객 :  여기 화장실은 없나요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  환불할 때 영수증 있어야 하죠?\n",
            "AI점원 : 환불 은 안 되 ㅂ니다 . \n",
            "\n",
            "\n",
            "고객 :  반품할 때 영수증 있어야 가능하죠?\n",
            "AI점원 : 네 . 가능 하 ㅂ니다 . \n",
            "\n",
            "\n",
            "고객 :  영수증 있어야 교환이나 반품되죠?\n",
            "AI점원 : 일주일 이내 에 오시 면 되 ㅂ니다 \n",
            "\n",
            "\n",
            "고객 :  티셔츠만 1+1이에요?\n",
            "AI점원 : 네 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}