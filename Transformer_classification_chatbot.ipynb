{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Transformer_classification_chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ioT3c4eLEKon",
        "jx-jxXncYmlp",
        "e6EDnEOwI_G7"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ideablast/NLPer_chatbot/blob/kdg/Transformer_classification_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsiilWsMNHHL",
        "outputId": "6ed4d82a-68ad-4593-9c1a-d02756093397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install konlpy\n",
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 74.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/96/1030895dea70855a2e1078e3fe0d6a63dcb7c212309e07dc9ee39d33af54/JPype1-1.1.2-cp36-cp36m-manylinux2010_x86_64.whl (450kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 59.5MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, tweepy, beautifulsoup4, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.1.2 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n",
            "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
            "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-58ewcrob\n",
            "  Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-58ewcrob\n",
            "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.3.0)\n",
            "Requirement already satisfied: keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.4.3)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.10.0)\n",
            "Collecting argparse>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.33.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (3.3.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.18.5)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.35.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.12.1)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.4.3->pykospacing==0.3) (3.13)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.17.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (4.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.4.8)\n",
            "Building wheels for collected packages: pykospacing\n",
            "  Building wheel for pykospacing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykospacing: filename=pykospacing-0.3-cp36-none-any.whl size=2255638 sha256=8919f3772dcd6bbb2acd577c399afa4b8bcd87124ca0ce7ebd3214c74cb07aac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t0o_1p9m/wheels/4d/45/58/e26cb2b7f6a063d234158c6fd1e5700f6e15b99d67154340ba\n",
            "Successfully built pykospacing\n",
            "Installing collected packages: argparse, pykospacing\n",
            "Successfully installed argparse-1.4.0 pykospacing-0.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ssut/py-hanspell.git\n",
            "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-dijt3fy2\n",
            "  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-dijt3fy2\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from py-hanspell==1.1) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (2020.6.20)\n",
            "Building wheels for collected packages: py-hanspell\n",
            "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-hanspell: filename=py_hanspell-1.1-cp36-none-any.whl size=4854 sha256=f6ac4f76d83bccd8924988e6121606aec7a78fdfdba363b82d08eefae5e30f0e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d5syj4ic/wheels/0a/25/d1/e5e96476dbb1c318cc26c992dd493394fe42b0c204b3e65588\n",
            "Successfully built py-hanspell\n",
            "Installing collected packages: py-hanspell\n",
            "Successfully installed py-hanspell-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UA-8fQ2EDnp"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DAFy5c7ydzC"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers, losses, metrics\n",
        "from keras import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from hanspell import spell_checker\n",
        "from pykospacing import spacing\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioT3c4eLEKon"
      },
      "source": [
        "## Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9YUdE1OydzG"
      },
      "source": [
        "# 태그 단어\n",
        "PAD = \"<PADDING>\"   # 패딩\n",
        "STA = \"<START>\"     # 시작\n",
        "END = \"<END>\"       # 끝\n",
        "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
        "\n",
        "# 태그 인덱스\n",
        "PAD_INDEX = 0\n",
        "STA_INDEX = 1\n",
        "END_INDEX = 2\n",
        "OOV_INDEX = 3\n",
        "\n",
        "# 데이터 타입\n",
        "ENCODER_INPUT  = 0\n",
        "DECODER_INPUT  = 1\n",
        "DECODER_TARGET = 2\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256 ##word embedding dim\n",
        "NUM_HEADS = 8 ## D_Model % NUM_HEADS == 0이 되야하므로...\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "EPOCHS = 50\n",
        "# for data pipelining\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "VOCAB_SIZE = 0 # 후에 len(words) 로 바뀜.\n",
        "\n",
        "# 한 문장에서 단어 시퀀스의 최대 개수\n",
        "max_sequences = 30\n",
        "\n",
        "# 정규 표현식 필터\n",
        "RE_FILTER = re.compile(\"[\\\"':;~()]\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhVVnW_uEWT1"
      },
      "source": [
        "## Data Load & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80IauV0FpUv2",
        "outputId": "9f74e7d2-35df-4bff-ef14-b6023470f4bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEHDnPXNzZlM",
        "outputId": "3f15a3d9-83a0-4f8f-b9ef-0ed2a4376863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wear_data = pd.read_csv(\"/content/drive/My Drive/wear_MAIN_edited.csv\")\n",
        "print(wear_data.shape)\n",
        "customer = wear_data[wear_data.SPEAKER == \"고객\"].SENTENCE\n",
        "store = wear_data[wear_data.SPEAKER == \"점원\"].SENTENCE\n",
        "print(customer.shape, store.shape) # 질문의 개수와 답의 개수가 일치하지 않는다."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15826, 20)\n",
            "(8381,) (7445,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLNSiqcHM4WY"
      },
      "source": [
        "prev = \"고객\"\n",
        "store_arr = []\n",
        "customer_arr = []\n",
        "store_stc = \"\"\n",
        "customer_stc = \"\"\n",
        "customer_C = \"\" #고객의 마지막 문장의 CATEGORY\n",
        "customer_M = \"\" #고객의 마지막 문장의 의도\n",
        "\n",
        "c_m = []\n",
        "for i in range(wear_data.shape[0]):\n",
        "    customer_C = wear_data.iloc[i].CATEGORY\n",
        "    customer_M = wear_data.iloc[i].MAIN\n",
        "    if (prev == wear_data.iloc[i].SPEAKER):\n",
        "        if prev == \"점원\":\n",
        "             store_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "        else : \n",
        "             customer_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "            \n",
        "    elif prev == \"점원\": # 점원 -> 고객\n",
        "        store_arr.append(store_stc)\n",
        "        customer_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"고객\"\n",
        "    else : # 고객 -> 점원\n",
        "        customer_arr.append(customer_stc)\n",
        "        c_m.append([customer_C,customer_M])\n",
        "        store_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"점원\"\n",
        "\n",
        "# print(len(store_arr))\n",
        "# print(len(customer_arr))\n",
        "# print(store_arr[-1])\n",
        "# print(customer_arr[-1]) # 자료 상에서 이후에는 계속 고객의 물음만 계속된다. 코드 레벨에서 이 부분은 빼게 구현했다. (stc는 만들어지지만 arr에 append 안하게 된다.)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByO6b_S10b6m"
      },
      "source": [
        "faqs = []\n",
        "for i in range(len(store_arr)):\n",
        "    faqs_tmp =[]\n",
        "    faqs_tmp.append(str(i+1))\n",
        "    faqs_tmp.append(customer_arr[i])\n",
        "    faqs_tmp.append(store_arr[i])\n",
        "\n",
        "    faqs.append(faqs_tmp)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSC-cPrN7Sen"
      },
      "source": [
        "for i in range(len(faqs)):\n",
        "  faqs[i].extend(c_m[i])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUOvBciM4G2g"
      },
      "source": [
        "category_arr = []\n",
        "main_arr = []\n",
        "for i in faqs:\n",
        "  category_arr.append(i[3])\n",
        "  main_arr.append(i[4])\n",
        "\n",
        "category_set = set(category_arr)\n",
        "main_set = set(main_arr)\n",
        "\n",
        "category_to_index = {word: index for index, word in enumerate(category_set)}\n",
        "main_to_index = {word: index for index, word in enumerate(main_set)} #질문의 의도만 가져오다보니 405개에서 387개로 줄어들음\n",
        "\n",
        "index_to_category = {index: word for index, word in enumerate(category_set)}\n",
        "index_to_main = {index: word for index, word in enumerate(main_set)}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IBBlpka5yNP"
      },
      "source": [
        "for i,item in enumerate(faqs):\n",
        "  faqs[i][3] = category_to_index[item[3]]\n",
        "  faqs[i][4] = main_to_index[item[4]]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNvig2FMzjXj",
        "outputId": "2a2d31f7-010f-467f-be0b-43ec45f82d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "question = []\n",
        "answer = []\n",
        "\n",
        "for Q in customer_arr:\n",
        "    question.append(Q.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "for A in store_arr:\n",
        "    answer.append(A.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "len(question), len(answer)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7301, 7301)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbivSckMydzN"
      },
      "source": [
        "# 형태소분석 함수\n",
        "def pos_tag(sentences):\n",
        "    \n",
        "    # KoNLPy 형태소분석기 설정\n",
        "    tagger = Okt()\n",
        "    \n",
        "    # 문장 품사 변수 초기화\n",
        "    sentences_pos = []\n",
        "    \n",
        "    # 모든 문장 반복\n",
        "    for sentence in sentences:\n",
        "        # [\\\"':;~()] 특수기호 제거\n",
        "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
        "        \n",
        "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
        "        sentence = \" \".join(tagger.morphs(sentence))\n",
        "        sentences_pos.append(sentence)\n",
        "        \n",
        "    return sentences_pos"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seqSNWcydzP",
        "outputId": "9a6c530b-8051-4d04-9f76-b08141bcf7ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 형태소분석 수행\n",
        "question = pos_tag(question)\n",
        "answer = pos_tag(answer)\n",
        "\n",
        "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
        "for i in range(5):\n",
        "    print('Q : ' + question[i])\n",
        "    print('A : ' + answer[i])\n",
        "    print()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q : 신발 은 여기 있는 게 다예 요 ?\n",
            "A : 네 성인 이나 아동 다 있어요 발 사이즈 몇 신으세요 ?\n",
            "\n",
            "Q : 230 이요\n",
            "A : 편하게 신 을 수 있는 거 찾으세요 ?\n",
            "\n",
            "Q : 네 봄 이니까 편하게 신 을 수 있는 거\n",
            "A : 이런 건 어떠세요 ? 이런 거도 신발 무척 편하거든요\n",
            "\n",
            "Q : 굽 좀 높은 거 없나요 ?\n",
            "A : 봄 상품 은 아직 어른 제품 이 많이 안 나왔습니다\n",
            "\n",
            "Q : 언제 들어와요 ?\n",
            "A : 이번 주 지나면 들어올 거 예요\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrnct_nzydzR"
      },
      "source": [
        "# 질문과 대답 문장들을 하나로 합침\n",
        "sentences = []\n",
        "sentences.extend(question)\n",
        "sentences.extend(answer)\n",
        "\n",
        "words = []\n",
        "\n",
        "# 단어들의 배열 생성\n",
        "for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "        words.append(word)\n",
        "\n",
        "# 길이가 0인 단어는 삭제\n",
        "words = [word for word in words if len(word) > 0]\n",
        "\n",
        "# 중복된 단어 삭제\n",
        "words = list(set(words))\n",
        "\n",
        "# 제일 앞에 태그 단어 삽입\n",
        "words[:0] = [PAD, STA, END, OOV]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE9ZhJpEy_rT",
        "outputId": "c1fcb148-9e0a-46d4-d5d8-8562f9a40a13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "VOCAB_SIZE = len(words)\n",
        "print(\"손님과 점원의 말에서 사용된 총 단어의 수 :\",len(words))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "손님과 점원의 말에서 사용된 총 단어의 수 : 6409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN-hToCq2QL3",
        "outputId": "7866c252-0a8a-4640-c1ca-1f928e93bf06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "words[:10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<PADDING>',\n",
              " '<START>',\n",
              " '<END>',\n",
              " '<OOV>',\n",
              " '밸런스',\n",
              " '지워요',\n",
              " '된다',\n",
              " '9200원',\n",
              " '뒷',\n",
              " '가디건']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkvyOnSvydzX"
      },
      "source": [
        "# 단어와 인덱스의 딕셔너리 생성\n",
        "word_to_index = {word: index for index, word in enumerate(words)}\n",
        "index_to_word = {index: word for index, word in enumerate(words)}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfoTztrvydzc"
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "def convert_text_to_index(sentences, vocabulary, type): \n",
        "    \n",
        "    sentences_index = []\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for sentence in sentences:\n",
        "        sentence_index = []\n",
        "        \n",
        "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
        "        if type == DECODER_INPUT:\n",
        "            sentence_index.extend([vocabulary[STA]])\n",
        "        \n",
        "        # 문장의 단어들을 띄어쓰기로 분리\n",
        "        for word in sentence.split():\n",
        "            if vocabulary.get(word) is not None:\n",
        "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[word]])\n",
        "            else:\n",
        "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "        # 최대 길이 검사\n",
        "        if type == DECODER_TARGET:\n",
        "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
        "            if len(sentence_index) >= max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
        "            else:\n",
        "                sentence_index += [vocabulary[END]]\n",
        "        else:\n",
        "            if len(sentence_index) > max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences]\n",
        "            \n",
        "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "        \n",
        "        # 문장의 인덱스 배열을 추가\n",
        "        sentences_index.append(sentence_index)\n",
        "\n",
        "    return np.asarray(sentences_index)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zezFPTvcydzf",
        "outputId": "af93291e-a6ee-4d48-e644-b68d9173cfa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 인코더 입력 인덱스 변환\n",
        "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
        "\n",
        "# 첫 번째 인코더 입력 출력 (신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_encoder[0]\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4280, 1256, 5062, 3237, 1873, 1993, 5346, 3220,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmql1Lf_ydzh",
        "outputId": "e4687418-8d90-42c1-b248-033f35831021",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 입력 인덱스 변환\n",
        "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (<START> 신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_decoder[0]\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1, 3128, 1435, 2031, 5501, 4270,  246, 1092,  551, 4643, 4224,\n",
              "       3220,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIhDbaLydzk",
        "outputId": "ff321f9d-c4d3-49b7-8a2a-748d02926b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 목표 인덱스 변환\n",
        "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (신발 은 여기 있는 게 다예 요 <END>)\n",
        "print(question[0])\n",
        "y_decoder[0]\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3128, 1435, 2031, 5501, 4270,  246, 1092,  551, 4643, 4224, 3220,\n",
              "          2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsf4tJl61Xi9"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsxmXWS41XVd"
      },
      "source": [
        "# decoder inputs use the previous target as input\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': x_encoder,\n",
        "        'dec_inputs': x_decoder\n",
        "    },\n",
        "    {\n",
        "        'outputs': y_decoder\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxXCQWvw2jwx"
      },
      "source": [
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH-k-kk_1_Vu"
      },
      "source": [
        "## scaled dot product Attention\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True) # QK^T\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth) #  QK^T / sqrt(d_k)\n",
        "\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9) # zero padding token softmax 결과가 0이 나오도록\n",
        "  \n",
        "  attention_weights = tf.nn.softmax(logits, axis = -1) # softmax(QK^T / sqrt(d_k))\n",
        "\n",
        "  output = tf.matmul(attention_weights, value) # softmax(QK^T / sqrt(d_k)) * V\n",
        "\n",
        "  return output"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7orcKMr13xY8"
      },
      "source": [
        "## multi-head attention\n",
        "## each head need (scaled_dot_product_attention)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0 # 128,8\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "  \n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(inputs, shape=(batch_size,-1,self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3]) ##????\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    #linear\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    #split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    #scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    #concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "\n",
        "    #final linear\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmlW0oi89nEC"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37sh3f8P-JUB",
        "outputId": "7eb736af-23a0-4d88-f11b-39bdf14feed8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W7ld50z3vT2"
      },
      "source": [
        "# it handle mask future tokens in a sequence used decoder. and mask pad tokens\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W25teKwt_F80",
        "outputId": "f62376f9-0bdc-474a-ec29-34f96635fd1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLhXEIJgASo3"
      },
      "source": [
        "Positional encoding\n",
        "\n",
        "since we don't use any rnn, cnn, positional encoding give model position information of words in sentence.\n",
        "\n",
        "positional encoding vector is added to embedding vector\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7s19-x3_Hpq"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "  \n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles #pos/10000^(2i/d_model)\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position = tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model = d_model)\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLiumNZZDZGY"
      },
      "source": [
        "### Encoder Layer\n",
        "1. Multi-head attention (with padding mask)\n",
        "2. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oarRWUMLDYnC"
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query':inputs,\n",
        "          'key':inputs,\n",
        "          'value':inputs,\n",
        "          'mask':padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3rO9IcDHGE5"
      },
      "source": [
        "### Encoder\n",
        "1. Input Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` encoder layers\n",
        "\n",
        "Embedding + positional encoding : input\n",
        "\n",
        "going encoder layers.\n",
        "\n",
        "output going decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOwoi2_jHvbA"
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)#??왜 vocab_size가 들어가지?\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, padding_mask], outputs = outputs, name=name)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8XHH5dpJr-G"
      },
      "source": [
        "### Decoder Layer\n",
        "1. Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2. Multi-head attention (with padding mask). `value` and `key` is from encoder output. `query` is from Multi-head attention layer output\n",
        "3. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtAfKdk-JrxK"
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name=\"padding_mask\")\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query' : inputs,\n",
        "          'key' : inputs,\n",
        "          'value' : inputs,\n",
        "          'mask' : look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query' : attention1,\n",
        "          'key' : enc_outputs,\n",
        "          'value' : enc_outputs,\n",
        "          'mask' : padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnBSBcm1NAYv"
      },
      "source": [
        "### Decoder\n",
        "1. output Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` decoder layers\n",
        "\n",
        "Embedding + positional encoding : input (target)\n",
        "\n",
        "going decoder layers.\n",
        "\n",
        "output going final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnA-8FEAOT4F"
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"decoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name='padding_mask')\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"decoder_layer_{}\".format(i),\n",
        "    )(inputs = [outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-vmtqKQjhf"
      },
      "source": [
        "### Transformer\n",
        "1. encoder\n",
        "2. decoder\n",
        "3. final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEMfL5SFQqr4"
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"enc_padding_mask\")(inputs)\n",
        "  \n",
        "  #mask future tokens for decoder inputs at 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1,None,None),\n",
        "      name=\"look_ahead_mask\")(dec_inputs)\n",
        "  \n",
        "  #mask encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"dec_padding_mask\")(inputs)\n",
        "  \n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pav-8Jd3ydzp"
      },
      "source": [
        "## 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8y-mjWtydzp"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK3IwtA4TOnN"
      },
      "source": [
        "### Loss function\n",
        "since target sequences are padded, deal this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi7YnqpVTYn2"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "  \n",
        "  mask = tf.cast(tf.not_equal(y_true,0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzHEmCzUVhTu"
      },
      "source": [
        "### Custom learning rate\n",
        "use Adam optimizer with custom learning rate\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkFm9m_LVt8c"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb8PGbKgWAbP"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vql4FYFUV_3_"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTXbb1Z2I4IM"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl3V7BllWWFG",
        "outputId": "c4486f9b-39ab-4bbc-a143-8f0c42b349b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.9745 - accuracy: 0.0212\n",
            "Epoch 2/50\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.7337 - accuracy: 0.0333\n",
            "Epoch 3/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.4780 - accuracy: 0.0421\n",
            "Epoch 4/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.3197 - accuracy: 0.0458\n",
            "Epoch 5/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.2290 - accuracy: 0.0561\n",
            "Epoch 6/50\n",
            "115/115 [==============================] - 6s 57ms/step - loss: 1.1427 - accuracy: 0.0669\n",
            "Epoch 7/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 1.0619 - accuracy: 0.0749\n",
            "Epoch 8/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.9901 - accuracy: 0.0812\n",
            "Epoch 9/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.9265 - accuracy: 0.0865\n",
            "Epoch 10/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.8684 - accuracy: 0.0916\n",
            "Epoch 11/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.8145 - accuracy: 0.0964\n",
            "Epoch 12/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.7614 - accuracy: 0.1010\n",
            "Epoch 13/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.7114 - accuracy: 0.1056\n",
            "Epoch 14/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.6626 - accuracy: 0.1111\n",
            "Epoch 15/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.6111 - accuracy: 0.1175\n",
            "Epoch 16/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.5616 - accuracy: 0.1236\n",
            "Epoch 17/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.5127 - accuracy: 0.1302\n",
            "Epoch 18/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.4641 - accuracy: 0.1377\n",
            "Epoch 19/50\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4141 - accuracy: 0.1464\n",
            "Epoch 20/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.3699 - accuracy: 0.1541\n",
            "Epoch 21/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.3243 - accuracy: 0.1625\n",
            "Epoch 22/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.2804 - accuracy: 0.1720\n",
            "Epoch 23/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.2446 - accuracy: 0.1786\n",
            "Epoch 24/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.2120 - accuracy: 0.1850\n",
            "Epoch 25/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1853 - accuracy: 0.1909\n",
            "Epoch 26/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1654 - accuracy: 0.1948\n",
            "Epoch 27/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1472 - accuracy: 0.1982\n",
            "Epoch 28/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1370 - accuracy: 0.1998\n",
            "Epoch 29/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1279 - accuracy: 0.2015\n",
            "Epoch 30/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1167 - accuracy: 0.2041\n",
            "Epoch 31/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1119 - accuracy: 0.2052\n",
            "Epoch 32/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.1082 - accuracy: 0.2057\n",
            "Epoch 33/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1045 - accuracy: 0.2067\n",
            "Epoch 34/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1004 - accuracy: 0.2074\n",
            "Epoch 35/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0997 - accuracy: 0.2078\n",
            "Epoch 36/50\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 0.0928 - accuracy: 0.2092\n",
            "Epoch 37/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0908 - accuracy: 0.2099\n",
            "Epoch 38/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0832 - accuracy: 0.2120\n",
            "Epoch 39/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0788 - accuracy: 0.2133\n",
            "Epoch 40/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0733 - accuracy: 0.2148\n",
            "Epoch 41/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0689 - accuracy: 0.2158\n",
            "Epoch 42/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0662 - accuracy: 0.2163\n",
            "Epoch 43/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0630 - accuracy: 0.2175\n",
            "Epoch 44/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0610 - accuracy: 0.2180\n",
            "Epoch 45/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0573 - accuracy: 0.2191\n",
            "Epoch 46/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0539 - accuracy: 0.2200\n",
            "Epoch 47/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.0522 - accuracy: 0.2205\n",
            "Epoch 48/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.0507 - accuracy: 0.2210\n",
            "Epoch 49/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0486 - accuracy: 0.2217\n",
            "Epoch 50/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0487 - accuracy: 0.2215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbf34ac27f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx-jxXncYmlp"
      },
      "source": [
        "## Category Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8n8WAyTbYu1",
        "outputId": "ab89039d-44d2-4490-aa37-a996567284ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "faqs[:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['1', ' 신발은 여기 있는 게 다예요?', '네 성인이나 아동 다 있어요 발 사이즈 몇 신으세요?', 3, 197],\n",
              " ['2', '230이요', '편하게 신을 수 있는 거 찾으세요?', 3, 67],\n",
              " ['3', '네 봄이니까 편하게 신을 수 있는 거', '이런 건 어떠세요? 이런 거도 신발 무척 편하거든요', 3, 67],\n",
              " ['4', '굽 좀 높은 거 없나요?', '봄 상품은 아직 어른 제품이 많이 안나왔습니다', 3, 333],\n",
              " ['5', '언제 들어와요?', '이번주 지나면 들어올 거예요', 3, 242],\n",
              " ['6', '이거는 가죽이에요?', '가죽 아니고 쎄무예요', 3, 338],\n",
              " ['7', '가죽은 얼마예요?', '2만 9천 원입니다', 3, 347],\n",
              " ['8', '털 달린 거 저거는 사이즈 있어요?', '230이 없어요  이거 한 번 신어보세요', 3, 53],\n",
              " ['9', '좀 크네 또 안 들어와요?', '네 이건 다 끝났어요', 3, 242],\n",
              " ['10', '가방 매는 거 보고 있어요', '여기 있어요', 0, 219]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABLPQcW99mjB"
      },
      "source": [
        "category_y = []\n",
        "main_y = []\n",
        "for i in faqs:\n",
        "  category_y.append(i[3])\n",
        "  main_y.append(i[4])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAyr-ECE-tH-"
      },
      "source": [
        "def convert_text_to_index_for_classification(sentences, vocabulary): \n",
        "    \n",
        "    sentences_index = []\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for sentence in sentences:\n",
        "        sentence_index = []\n",
        "        \n",
        "        # 문장의 단어들을 띄어쓰기로 분리\n",
        "        for word in sentence.split():\n",
        "            if vocabulary.get(word) is not None:\n",
        "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[word]])\n",
        "            else:\n",
        "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "        if len(sentence_index) > max_sequences:\n",
        "            sentence_index = sentence_index[:max_sequences]\n",
        "            \n",
        "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "        \n",
        "        # 문장의 인덱스 배열을 추가\n",
        "        sentences_index.append(sentence_index)\n",
        "\n",
        "    return sentences_index"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ioc_akA_aZw",
        "outputId": "b4eb0ea5-3b69-443c-8342-69369cd6d2aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 분류모델에 들어갈 x 만들기\n",
        "question_index_for_cl = []\n",
        "answer_index_for_cl = []\n",
        "question_index_for_cl = convert_text_to_index_for_classification(question, word_to_index) #질문 문장에 정수인코딩,패딩\n",
        "answer_index_for_cl = convert_text_to_index_for_classification(answer, word_to_index)\n",
        "\n",
        "question_index_for_cl.extend(answer_index_for_cl) # 이렇게 합쳐줌으로써 question_index_for_cl 이 결국 분류모델의 x로 들어가게 될 예정\n",
        "len(question_index_for_cl)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEkfYKqa8a9c"
      },
      "source": [
        "# 분류모델에 들어갈 y만들기\n",
        "category_y = []\n",
        "main_y = []\n",
        "for i in faqs:\n",
        "  category_y.append(i[3])\n",
        "  main_y.append(i[4])\n",
        "\n",
        "category_y.extend(category_y) # 자기것을 그대로 뒤에 갓다붙임. 그래도 되는게, x의 0번 인덱스의 문장(고객의 질문)과 7301번 인덱스의 문장(점원의 답변)이 카테고리,의도가 같음.\n",
        "main_y.extend(main_y)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYhb9996D8Mq",
        "outputId": "10756733-fd05-401b-bf3c-db0d1caa0c90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(category_y), len(main_y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14602, 14602)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHhczfJBkGtb",
        "outputId": "df6b06df-6dfd-4c7d-d55b-caab74dbf427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.asarray(question_index_for_cl).shape"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14602, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB-wHnf9JCQZ",
        "outputId": "d29291cd-c30d-40ff-d645-d0181873080e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.asarray(main_y).shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14602,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL5Wld5gkLDM",
        "outputId": "ffc3443d-b233-4891-af54-892057ef0198",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.asarray(category_y).shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14602,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olSqa8TsNQm0"
      },
      "source": [
        "### Transformer classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW-r-YFCfVgv"
      },
      "source": [
        "class MultiHeadSelfAttention_classification(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super(MultiHeadSelfAttention_classification, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF-STW24OD-g"
      },
      "source": [
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention_classification(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential([layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),])\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diqd0EEBOOQZ"
      },
      "source": [
        "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCykTZScOT-x"
      },
      "source": [
        "import keras\n",
        "inputs = layers.Input(shape=(max_sequences,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_sequences, VOCAB_SIZE, D_MODEL)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(D_MODEL, NUM_HEADS, UNITS)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(40, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "\n",
        "cmodel = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4yZ-Mi-SeCF"
      },
      "source": [
        "inputs = layers.Input(shape=(max_sequences,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_sequences, VOCAB_SIZE, D_MODEL)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(D_MODEL, NUM_HEADS, UNITS)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(4000, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(387, activation=\"softmax\")(x)\n",
        "\n",
        "mmodel = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqRliLNpS5hs"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZdbSD3jOXZx"
      },
      "source": [
        "cmodel.compile(loss =\"sparse_categorical_crossentropy\", optimizer='adam', metrics=[\"acc\"])\n",
        "history_c = cmodel.fit(\n",
        "    np.asarray(question_index_for_cl), np.asarray(category_y), validation_split=0.1, batch_size=32, epochs=30\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SlrE3fAMIGo",
        "outputId": "e1517847-a9d8-4820-dd5c-49a94e03c6bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(history_c.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(history_c.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(history_c.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(history_c.history['val_acc'], 'g', label='val acc')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHQoXs8wfkYk",
        "outputId": "b4b93471-8324-4a26-d9df-f91154ce56fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "history_m = mmodel.fit(np.asarray(question_index_for_cl), np.asarray(main_y), validation_split=0.1, batch_size=32, epochs=30)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "411/411 [==============================] - 7s 17ms/step - loss: 4.3036 - acc: 0.1738 - val_loss: 4.2836 - val_acc: 0.1116\n",
            "Epoch 2/30\n",
            "411/411 [==============================] - 7s 16ms/step - loss: 3.2511 - acc: 0.3166 - val_loss: 4.0473 - val_acc: 0.2019\n",
            "Epoch 3/30\n",
            "411/411 [==============================] - 7s 16ms/step - loss: 2.6014 - acc: 0.4140 - val_loss: 4.0134 - val_acc: 0.2553\n",
            "Epoch 4/30\n",
            "411/411 [==============================] - 7s 16ms/step - loss: 2.1631 - acc: 0.4861 - val_loss: 4.1254 - val_acc: 0.2765\n",
            "Epoch 5/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 1.8094 - acc: 0.5544 - val_loss: 4.5975 - val_acc: 0.2861\n",
            "Epoch 6/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 1.5438 - acc: 0.6066 - val_loss: 4.7525 - val_acc: 0.2772\n",
            "Epoch 7/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 1.3346 - acc: 0.6453 - val_loss: 4.9984 - val_acc: 0.2574\n",
            "Epoch 8/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 1.1742 - acc: 0.6840 - val_loss: 5.5464 - val_acc: 0.2772\n",
            "Epoch 9/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 1.0573 - acc: 0.7035 - val_loss: 5.3895 - val_acc: 0.2594\n",
            "Epoch 10/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.9579 - acc: 0.7296 - val_loss: 5.9124 - val_acc: 0.2450\n",
            "Epoch 11/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.8802 - acc: 0.7451 - val_loss: 6.2621 - val_acc: 0.2861\n",
            "Epoch 12/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.8278 - acc: 0.7620 - val_loss: 6.3759 - val_acc: 0.2498\n",
            "Epoch 13/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.7805 - acc: 0.7700 - val_loss: 6.4781 - val_acc: 0.2553\n",
            "Epoch 14/30\n",
            "411/411 [==============================] - 7s 16ms/step - loss: 0.7283 - acc: 0.7898 - val_loss: 6.8812 - val_acc: 0.2533\n",
            "Epoch 15/30\n",
            "411/411 [==============================] - 7s 16ms/step - loss: 0.7016 - acc: 0.7952 - val_loss: 8.2384 - val_acc: 0.2553\n",
            "Epoch 16/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.6561 - acc: 0.8037 - val_loss: 7.9460 - val_acc: 0.2594\n",
            "Epoch 17/30\n",
            "411/411 [==============================] - 7s 16ms/step - loss: 0.6236 - acc: 0.8130 - val_loss: 7.7639 - val_acc: 0.2402\n",
            "Epoch 18/30\n",
            "411/411 [==============================] - 7s 17ms/step - loss: 0.5915 - acc: 0.8242 - val_loss: 8.4722 - val_acc: 0.2539\n",
            "Epoch 19/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.5600 - acc: 0.8321 - val_loss: 8.6892 - val_acc: 0.2430\n",
            "Epoch 20/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.5425 - acc: 0.8374 - val_loss: 8.4795 - val_acc: 0.2416\n",
            "Epoch 21/30\n",
            "411/411 [==============================] - 6s 15ms/step - loss: 0.5039 - acc: 0.8508 - val_loss: 8.8448 - val_acc: 0.2567\n",
            "Epoch 22/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.4947 - acc: 0.8515 - val_loss: 8.7775 - val_acc: 0.2676\n",
            "Epoch 23/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.4964 - acc: 0.8537 - val_loss: 9.3805 - val_acc: 0.2355\n",
            "Epoch 24/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.4799 - acc: 0.8518 - val_loss: 8.9504 - val_acc: 0.2471\n",
            "Epoch 25/30\n",
            "411/411 [==============================] - 6s 15ms/step - loss: 0.4580 - acc: 0.8610 - val_loss: 9.1003 - val_acc: 0.2615\n",
            "Epoch 26/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.4352 - acc: 0.8677 - val_loss: 9.8303 - val_acc: 0.2560\n",
            "Epoch 27/30\n",
            "411/411 [==============================] - 6s 15ms/step - loss: 0.4239 - acc: 0.8709 - val_loss: 10.1248 - val_acc: 0.2389\n",
            "Epoch 28/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.4171 - acc: 0.8730 - val_loss: 9.2565 - val_acc: 0.2553\n",
            "Epoch 29/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.4080 - acc: 0.8782 - val_loss: 11.2943 - val_acc: 0.2553\n",
            "Epoch 30/30\n",
            "411/411 [==============================] - 6s 16ms/step - loss: 0.4060 - acc: 0.8775 - val_loss: 10.0323 - val_acc: 0.2635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bX-vKIaS3MF"
      },
      "source": [
        "mmodel.save('main_bilstm_cl.h5')"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGQ3iSMkThaN"
      },
      "source": [
        "load_m_model = models.load_model('main_lstm_cl.h5')"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlLD_Nv6GMYz",
        "outputId": "041c4124-9c26-44a4-e743-e540a90724ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(history_m.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(history_m.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(history_m.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(history_m.history['val_acc'], 'g', label='val acc')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYqy-6NEfrXJ",
        "outputId": "821fa01f-f2df-4a9d-96a8-68b4927a6272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "history_c = cmodel.fit(np.asarray(question_index_for_cl), np.asarray(category_y), validation_split=0.1, batch_size=32, epochs=30) # 128 64 32 실험"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "411/411 [==============================] - 8s 19ms/step - loss: 1.0851 - acc: 0.5161 - val_loss: 0.6656 - val_acc: 0.7632\n",
            "Epoch 2/30\n",
            "411/411 [==============================] - 6s 14ms/step - loss: 0.7553 - acc: 0.6901 - val_loss: 0.6915 - val_acc: 0.6831\n",
            "Epoch 3/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.6267 - acc: 0.7458 - val_loss: 0.7421 - val_acc: 0.6715\n",
            "Epoch 4/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.5550 - acc: 0.7701 - val_loss: 0.7555 - val_acc: 0.6749\n",
            "Epoch 5/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.5042 - acc: 0.7885 - val_loss: 0.8558 - val_acc: 0.6632\n",
            "Epoch 6/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.4768 - acc: 0.7993 - val_loss: 0.8407 - val_acc: 0.6646\n",
            "Epoch 7/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.4462 - acc: 0.8085 - val_loss: 0.8447 - val_acc: 0.6797\n",
            "Epoch 8/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.4169 - acc: 0.8225 - val_loss: 0.9646 - val_acc: 0.6680\n",
            "Epoch 9/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.4008 - acc: 0.8270 - val_loss: 1.0289 - val_acc: 0.6674\n",
            "Epoch 10/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3904 - acc: 0.8313 - val_loss: 0.9929 - val_acc: 0.7488\n",
            "Epoch 11/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3735 - acc: 0.8387 - val_loss: 1.1055 - val_acc: 0.6530\n",
            "Epoch 12/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3543 - acc: 0.8494 - val_loss: 1.1124 - val_acc: 0.6639\n",
            "Epoch 13/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3436 - acc: 0.8520 - val_loss: 1.2516 - val_acc: 0.6523\n",
            "Epoch 14/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3313 - acc: 0.8573 - val_loss: 1.2098 - val_acc: 0.6482\n",
            "Epoch 15/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3252 - acc: 0.8586 - val_loss: 1.2979 - val_acc: 0.6454\n",
            "Epoch 16/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3176 - acc: 0.8610 - val_loss: 1.3926 - val_acc: 0.6366\n",
            "Epoch 17/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3061 - acc: 0.8658 - val_loss: 1.3123 - val_acc: 0.6694\n",
            "Epoch 18/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2947 - acc: 0.8710 - val_loss: 1.5765 - val_acc: 0.6393\n",
            "Epoch 19/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2904 - acc: 0.8730 - val_loss: 1.5425 - val_acc: 0.6372\n",
            "Epoch 20/30\n",
            "411/411 [==============================] - 6s 14ms/step - loss: 0.2805 - acc: 0.8773 - val_loss: 1.5780 - val_acc: 0.6331\n",
            "Epoch 21/30\n",
            "411/411 [==============================] - 6s 14ms/step - loss: 0.2691 - acc: 0.8824 - val_loss: 1.6811 - val_acc: 0.6352\n",
            "Epoch 22/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2633 - acc: 0.8856 - val_loss: 1.7184 - val_acc: 0.6461\n",
            "Epoch 23/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2613 - acc: 0.8865 - val_loss: 1.5853 - val_acc: 0.6502\n",
            "Epoch 24/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2519 - acc: 0.8908 - val_loss: 1.6437 - val_acc: 0.6605\n",
            "Epoch 25/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2442 - acc: 0.8946 - val_loss: 1.5970 - val_acc: 0.6509\n",
            "Epoch 26/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2443 - acc: 0.8935 - val_loss: 1.7792 - val_acc: 0.6338\n",
            "Epoch 27/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2276 - acc: 0.9015 - val_loss: 1.8550 - val_acc: 0.6331\n",
            "Epoch 28/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.2211 - acc: 0.9047 - val_loss: 1.9245 - val_acc: 0.6324\n",
            "Epoch 29/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2136 - acc: 0.9078 - val_loss: 1.9414 - val_acc: 0.6256\n",
            "Epoch 30/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2089 - acc: 0.9080 - val_loss: 1.9955 - val_acc: 0.6393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiLiJVHRUgVr"
      },
      "source": [
        "cmodel.save('category_bilstm_cl.h5')"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6SLbwbHObjs",
        "outputId": "84a45230-4249-4963-b525-f0527e6bf2de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "index_to_category"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '신발', 1: '가방', 2: '의류', 3: '액세서리'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zdmR5oZHWsq"
      },
      "source": [
        "def predict_cm(question_index_for_cl, category_y, main_y): #형태소 분리된 문장들의 list가 입력으로 가야함.\n",
        "  # stc_x = convert_text_to_index_for_classification(questions, word_to_index)\n",
        "  j = 0\n",
        "  c = 0\n",
        "  m = 0\n",
        "  for i in question_index_for_cl:\n",
        "    if np.argmax(cmodel.predict(np.asarray(i).reshape(1,30))) != category_y[j]:\n",
        "      c += 1\n",
        "    if np.argmax(mmodel.predict(np.asarray(i).reshape(1,30))) != main_y[j]:\n",
        "      m += 1\n",
        "    j+=1\n",
        "  print(c, \"개의 문장의 카테고리가 맞지 않음\")\n",
        "  print(m, \"개의 문장의 의도가 맞지 않음\")"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXA9XMEZy7x4",
        "outputId": "1899d6f4-5402-4598-e657-81bf8f978bc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_cm(question_index_for_cl, category_y, main_y)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2241 개의 문장의 카테고리가 맞지 않음\n",
            "2381 개의 문장의 의도가 맞지 않음\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXJLCyt0w95Y",
        "outputId": "1fd0fbcd-4593-4efc-bdce-6016c488f7eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.asarray(question_index_for_cl)[:10]"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4280, 1256, 5062, 3237, 1873, 1993, 5346, 3220,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [4629, 6058,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [3128, 1177, 6337, 5115, 4253, 3077, 2754, 3237, 5680,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [4856, 4457, 4357, 5680, 1509, 3220,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [4481, 1389, 3220,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [3336, 5680, 1602, 3261, 1329, 3220,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [3261, 1256, 3923, 5683, 3220,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [2968,  401, 5680, 1500, 5680, 1602,  551,  246, 3220,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [4457, 6274, 6300, 6158, 1389, 3220,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [5041, 2166, 5680, 3384,  246,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk46KWSNjTOl"
      },
      "source": [
        "predict_cm(question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXEMQH_jf5jl"
      },
      "source": [
        "def find_category(stc,tokenizer,model,category_list):\n",
        "    tagger = Okt()\n",
        "    stc = tagger.morphs(stc)\n",
        "    encode_stc = tokenizer.texts_to_sequences([stc])\n",
        "    pad_stc = pad_sequences(encode_stc, maxlen=15)\n",
        "    score = model.predict(pad_stc)\n",
        "    return (category_list[score.argmax()], score[0, score.argmax()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6EDnEOwI_G7"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxi2B-vjydzt"
      },
      "source": [
        "# 인덱스를 문장으로 변환\n",
        "def convert_index_to_text(indexs, vocabulary): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == END_INDEX:\n",
        "            # 종료 인덱스면 중지\n",
        "            break;\n",
        "        if vocabulary.get(index) is not None:\n",
        "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
        "            sentence += vocabulary[index]\n",
        "        else:\n",
        "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
        "            sentence.extend([vocabulary[OOV_INDEX]])\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E66RpbXydzy"
      },
      "source": [
        "# 예측을 위한 입력 생성\n",
        "def make_predict_input(sentence):\n",
        "\n",
        "    sentences = []\n",
        "    sentences.append(sentence)\n",
        "    sentences = pos_tag(sentences)\n",
        "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
        "    \n",
        "    return input_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umBNECObKCJj"
      },
      "source": [
        "def evaluate(input_seq):\n",
        "\n",
        "  input_seq = input_seq.squeeze()\n",
        "  sentence = tf.expand_dims(input_seq, axis=0)\n",
        "  output = tf.expand_dims([1], 0)\n",
        "\n",
        "  for i in range(max_sequences):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, 2):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjLQI4czaTs1"
      },
      "source": [
        "##doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAs_p0bLhlPy"
      },
      "source": [
        "import os\n",
        "from gensim.models import doc2vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import pandas as pd\n",
        "import jpype\n",
        "from konlpy.tag import Kkma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYLVCfVfaB88"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exGo1HnHR5Dg"
      },
      "source": [
        "kkma = Kkma()\n",
        "filter_kkma = ['NNG', 'NNP','OL','VA','VV','VXV']\n",
        "\n",
        "def tokenizer_kkma(doc):\n",
        "    # 꼬꼬마 형태소 분석기가 자바 기반이어서 파이썬에서 자바함수들을 실행할 수 있는 명령어 (jpype) 를 써줘야한다.\n",
        "    jpype.attachThreadToJVM()       \n",
        "    token_doc = [\"/\".join(word) for word in kkma.pos(doc)]\n",
        "    return token_doc\n",
        "\n",
        "def tokenize_kkma_noun_verb(doc):\n",
        "    jpype.attachThreadToJVM()\n",
        "    token_doc = [\"/\".join(word) for word in kkma.pos(doc) if word[1] in filter_kkma]\n",
        "    return token_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzqye7pxR8kD"
      },
      "source": [
        "token_faqs = [(tokenizer_kkma(row[1]), row[0]) for row in faqs]\n",
        "tagged_faqs = [TaggedDocument(d,[c]) for d,c in token_faqs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_DB1CbDSNQj",
        "outputId": "5360a19d-a53c-4000-e46f-4b65430a4f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 모델 만들기\n",
        "# cpu 몇 개 쓸 건지\n",
        "import multiprocessing\n",
        "# 내 컴에 있는 cpu 갯수 cores 에 저장\n",
        "cores = multiprocessing.cpu_count()\n",
        "# vector_size : 임베딩할 벡터 차원\n",
        "# negaive : negative sampling\n",
        "d2v_faqs = doc2vec.Doc2Vec(\n",
        "    vector_size = 100,\n",
        "    alpha = 0.025,\n",
        "    min_alpha = 0.025,\n",
        "    hs = 1,\n",
        "    negative = 0,\n",
        "    dm = 0,\n",
        "    dbow_words = 1,\n",
        "    min_count = 1,\n",
        "    workers = cores,\n",
        "    seed = 0\n",
        ")\n",
        "\n",
        "# 단어 사전 만들기\n",
        "d2v_faqs.build_vocab(tagged_faqs)\n",
        "for epoch in range(4):\n",
        "  # 모델 학습\n",
        "  print(epoch)\n",
        "  d2v_faqs.train(tagged_faqs,\n",
        "                 total_examples = d2v_faqs.corpus_count,\n",
        "                 epochs = d2v_faqs.epochs)\n",
        "  d2v_faqs.alpha -=0.0025\n",
        "  d2v_faqs.min_alpha = d2v_faqs.min_alpha"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPuuoO9WUwfT"
      },
      "source": [
        "# spell check and spacing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvEHNJR5X7Xh"
      },
      "source": [
        "def grammar_checker(sentence):\n",
        "\n",
        "  spacing_sentence = spacing(sentence.replace(' ',''))\n",
        "  spelled_sentence = spell_checker.check(spacing_sentence)\n",
        "  checked_sentence = spelled_sentence.checked\n",
        "\n",
        "  return checked_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjxPAkUcRXNQ"
      },
      "source": [
        "##합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "audGWlqWURLT"
      },
      "source": [
        "def give_cate(input_question): #카테고리추출하는 함수\n",
        "  big_cate=find_category(input_question,ctokenizer,cmodel,category_list)\n",
        "  samll_cate=find_category(input_question,rtokenizer,rmodel,rough_category_list)\n",
        "  return big_cate,samll_cate #리턴값으로 큰카테고리(이름,유사도),작은 카테고리(이름,유사도)\n",
        "\n",
        "def give_answer(input_question): #질문입력시 transfomer로 답변함\n",
        "  return convert_index_to_text(evaluate(make_predict_input(input_question)).numpy()[1:],index_to_word)\n",
        "\n",
        "def doc2_answer(input_question): #질문 입력시 doc2으로 답변함\n",
        "  token_test = tokenizer_kkma(input_question)\n",
        "  predict_vector = d2v_faqs.infer_vector(token_test)\n",
        "  result = d2v_faqs.docvecs.most_similar([predict_vector],topn=1)\n",
        "  return faqs[int(result[0][0])-1][2]\n",
        "\n",
        "def score_calcul(left_cate,right_cate):#카테고리를 두개를 입력하면 유사도를 계산함\n",
        "  result = 0\n",
        "  if left_cate[0]==right_cate[0]:\n",
        "    result += abs(left_cate[1]-right_cate[1])\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oOsaFW9RpBK",
        "outputId": "a2029d76-5358-4ca2-e3c3-26a87cc6c8db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_question = input()\n",
        "\n",
        "q_big_cate,q_samll_cate=give_cate(input_question)\n",
        "\n",
        "print(f\"{q_big_cate},{q_samll_cate}\")\n",
        "\n",
        "dm=doc2_answer(input_question)\n",
        "dm_big_cate,dm_small_cate=give_cate(dm)\n",
        "cm=give_answer(input_question)\n",
        "cm_big_cate,cm_small_cate=give_cate(cm)\n",
        "\n",
        "doc2_score=0\n",
        "tran_score=0\n",
        "\n",
        "doc2_score += score_calcul(q_big_cate,dm_big_cate)\n",
        "doc2_score += score_calcul(q_big_cate,dm_small_cate)\n",
        "tran_score += score_calcul(q_big_cate,cm_big_cate)\n",
        "tran_score += score_calcul(q_big_cate,dm_small_cate)\n",
        "\n",
        "if doc2_score>=tran_score:\n",
        "  print(f\"***doc2: {grammar_checker(dm)}\")\n",
        "else:\n",
        "  print(f\"***tran: {grammar_checker(cm)}\")\n",
        "\n",
        "print(\"==================================\")\n",
        "print(f\"doc2: {dm_big_cate},{dm_small_cate}\")\n",
        "print(grammar_checker(dm))\n",
        "if doc2_score!=0:\n",
        "  print(doc2_score)\n",
        "else:\n",
        "  print(\"평가불가\")\n",
        "print(\"\")\n",
        "print(f\"tran: {cm_big_cate},{cm_small_cate}\")\n",
        "print(grammar_checker(cm))\n",
        "if tran_score!=0:\n",
        "  print(tran_score)\n",
        "else:\n",
        "  print(\"평가불가\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "카운터에 있는 점원이 입고 있는 옷 맘에 드는데 어떤 제품인가요?\n",
            "('유사제품추천문의', 0.6587085),('신발', 0.9972078)\n",
            "***doc2: 네 피팅룸은 이쪽입니다\n",
            "==================================\n",
            "doc2: ('제품요청', 0.50416297),('의류', 0.999944)\n",
            "네 피팅룸은 이쪽입니다\n",
            "평가불가\n",
            "\n",
            "tran: ('제품별추천문의', 0.67691714),('의류', 0.88469416)\n",
            "고객 님 이 제품 은 어떠 신지 요 ? \n",
            "평가불가\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}