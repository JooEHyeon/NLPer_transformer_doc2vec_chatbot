{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Seq2Seq_Chatbot_의류_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9UA-8fQ2EDnp",
        "ioT3c4eLEKon",
        "lsf4tJl61Xi9"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ideablast/NLPer_chatbot/blob/kdg/Seq2Seq_Chatbot_%EC%9D%98%EB%A5%98_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsiilWsMNHHL",
        "outputId": "168b30d2-6a61-46ef-9d10-3ca4c75194aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.1MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/96/1030895dea70855a2e1078e3fe0d6a63dcb7c212309e07dc9ee39d33af54/JPype1-1.1.2-cp36-cp36m-manylinux2010_x86_64.whl (450kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 57.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: beautifulsoup4, tweepy, colorama, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.1.2 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UA-8fQ2EDnp"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DAFy5c7ydzC"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers, losses, metrics\n",
        "from keras import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioT3c4eLEKon"
      },
      "source": [
        "## Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9YUdE1OydzG"
      },
      "source": [
        "# 태그 단어\n",
        "PAD = \"<PADDING>\"   # 패딩\n",
        "STA = \"<START>\"     # 시작\n",
        "END = \"<END>\"       # 끝\n",
        "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
        "\n",
        "# 태그 인덱스\n",
        "PAD_INDEX = 0\n",
        "STA_INDEX = 1\n",
        "END_INDEX = 2\n",
        "OOV_INDEX = 3\n",
        "\n",
        "# 데이터 타입\n",
        "ENCODER_INPUT  = 0\n",
        "DECODER_INPUT  = 1\n",
        "DECODER_TARGET = 2\n",
        "\n",
        "# 한 문장에서 단어 시퀀스의 최대 개수\n",
        "max_sequences = 30\n",
        "\n",
        "# 임베딩 벡터 차원\n",
        "embedding_dim = 100\n",
        "\n",
        "# LSTM 히든레이어 차원 : 100 이 좋단다.\n",
        "lstm_hidden_dim = 100\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "# 정규 표현식 필터\n",
        "RE_FILTER = re.compile(\"[\\\"':;~()]\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhVVnW_uEWT1"
      },
      "source": [
        "## Data Load & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80IauV0FpUv2",
        "outputId": "053cda97-7dde-46b0-80be-66be120da5be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEHDnPXNzZlM",
        "outputId": "12c28284-28a1-4a4f-dcaf-b3fbdf93c7f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wear_data = pd.read_csv(\"/content/drive/My Drive/wear.csv\")\n",
        "print(wear_data.shape)\n",
        "customer = wear_data[wear_data.SPEAKER == \"고객\"].SENTENCE\n",
        "store = wear_data[wear_data.SPEAKER == \"점원\"].SENTENCE\n",
        "print(customer.shape, store.shape) # 질문의 개수와 답의 개수가 일치하지 않는다."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15826, 20)\n",
            "(8381,) (7445,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLNSiqcHM4WY",
        "outputId": "ab100a6e-690e-429a-e89d-f1c9127fe80e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "prev = \"고객\"\n",
        "store_arr = []\n",
        "customer_arr = []\n",
        "store_stc = \"\"\n",
        "customer_stc = \"\"\n",
        "\n",
        "for i in range(wear_data.shape[0]):\n",
        "    if (prev == wear_data.iloc[i].SPEAKER):\n",
        "        if prev == \"점원\":\n",
        "             store_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "        else : \n",
        "             customer_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "            \n",
        "    elif prev == \"점원\":\n",
        "        store_arr.append(store_stc)\n",
        "        customer_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"고객\"\n",
        "    else :\n",
        "        customer_arr.append(customer_stc)\n",
        "        store_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"점원\"\n",
        "\n",
        "print(len(store_arr))\n",
        "print(len(customer_arr))\n",
        "print(store_arr[-1])\n",
        "print(customer_arr[-1]) # 자료 상에서 이후에는 계속 고객의 물음만 계속된다. 코드 레벨에서 이 부분은 빼게 구현했다. (stc는 만들어지지만 arr에 append 안하게 된다.)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7301\n",
            "7301\n",
            "요즘 파스텔 톤이 유행이에요\n",
            "요즘 유행하는 색깔이 뭐예요?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNvig2FMzjXj",
        "outputId": "d2f74154-59bc-4f44-b06e-719286a99ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "question = []\n",
        "answer = []\n",
        "\n",
        "for Q in customer_arr:\n",
        "    question.append(Q.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "for A in store_arr:\n",
        "    answer.append(A.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "len(question), len(answer)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7301, 7301)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbivSckMydzN"
      },
      "source": [
        "# 형태소분석 함수\n",
        "def pos_tag(sentences):\n",
        "    \n",
        "    # KoNLPy 형태소분석기 설정\n",
        "    tagger = Okt()\n",
        "    \n",
        "    # 문장 품사 변수 초기화\n",
        "    sentences_pos = []\n",
        "    \n",
        "    # 모든 문장 반복\n",
        "    for sentence in sentences:\n",
        "        # [\\\"':;~()] 특수기호 제거\n",
        "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
        "        \n",
        "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
        "        sentence = \" \".join(tagger.morphs(sentence))\n",
        "        sentences_pos.append(sentence)\n",
        "        \n",
        "    return sentences_pos"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seqSNWcydzP",
        "outputId": "4de8f3f0-e2ed-4004-d39f-64a9284c4e66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 형태소분석 수행\n",
        "question = pos_tag(question)\n",
        "answer = pos_tag(answer)\n",
        "\n",
        "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
        "for i in range(5):\n",
        "    print('Q : ' + question[i])\n",
        "    print('A : ' + answer[i])\n",
        "    print()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q : 신발 은 여기 있는 게 다예 요 ?\n",
            "A : 네 성인 이나 아동 다 있어요 발 사이즈 몇 신으세요 ?\n",
            "\n",
            "Q : 230 이요\n",
            "A : 편하게 신 을 수 있는 거 찾으세요 ?\n",
            "\n",
            "Q : 네 봄 이니까 편하게 신 을 수 있는 거\n",
            "A : 이런 건 어떠세요 ? 이런 거도 신발 무척 편하거든요\n",
            "\n",
            "Q : 굽 좀 높은 거 없나요 ?\n",
            "A : 봄 상품 은 아직 어른 제품 이 많이 안 나왔습니다\n",
            "\n",
            "Q : 언제 들어와요 ?\n",
            "A : 이번 주 지나면 들어올 거 예요\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrnct_nzydzR"
      },
      "source": [
        "# 질문과 대답 문장들을 하나로 합침\n",
        "sentences = []\n",
        "sentences.extend(question)\n",
        "sentences.extend(answer)\n",
        "\n",
        "words = []\n",
        "\n",
        "# 단어들의 배열 생성\n",
        "for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "        words.append(word)\n",
        "\n",
        "# 길이가 0인 단어는 삭제\n",
        "words = [word for word in words if len(word) > 0]\n",
        "\n",
        "# 중복된 단어 삭제\n",
        "words = list(set(words))\n",
        "\n",
        "# 제일 앞에 태그 단어 삽입\n",
        "words[:0] = [PAD, STA, END, OOV]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE9ZhJpEy_rT",
        "outputId": "a2f6d23a-6cfd-4a48-a673-8d33b5e40685",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"손님과 점원의 말에서 사용된 총 단어의 수 :\",len(words))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "손님과 점원의 말에서 사용된 총 단어의 수 : 6409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkvyOnSvydzX"
      },
      "source": [
        "# 단어와 인덱스의 딕셔너리 생성\n",
        "word_to_index = {word: index for index, word in enumerate(words)}\n",
        "index_to_word = {index: word for index, word in enumerate(words)}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfoTztrvydzc"
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "def convert_text_to_index(sentences, vocabulary, type): \n",
        "    \n",
        "    sentences_index = []\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for sentence in sentences:\n",
        "        sentence_index = []\n",
        "        \n",
        "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
        "        if type == DECODER_INPUT:\n",
        "            sentence_index.extend([vocabulary[STA]])\n",
        "        \n",
        "        # 문장의 단어들을 띄어쓰기로 분리\n",
        "        for word in sentence.split():\n",
        "            if vocabulary.get(word) is not None:\n",
        "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[word]])\n",
        "            else:\n",
        "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "        # 최대 길이 검사\n",
        "        if type == DECODER_TARGET:\n",
        "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
        "            if len(sentence_index) >= max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
        "            else:\n",
        "                sentence_index += [vocabulary[END]]\n",
        "        else:\n",
        "            if len(sentence_index) > max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences]\n",
        "            \n",
        "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "        \n",
        "        # 문장의 인덱스 배열을 추가\n",
        "        sentences_index.append(sentence_index)\n",
        "\n",
        "    return np.asarray(sentences_index)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zezFPTvcydzf",
        "outputId": "9827a294-0c8d-4a6e-ccd2-8961701f56ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 인코더 입력 인덱스 변환\n",
        "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
        "\n",
        "# 첫 번째 인코더 입력 출력 (신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_encoder[0]\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2042, 3770, 2996, 6243, 4357, 4952, 2430, 4595,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmql1Lf_ydzh",
        "outputId": "085966bb-7b17-4078-a40c-adfad63ec95c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 입력 인덱스 변환\n",
        "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (<START> 신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_decoder[0]\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1, 1648, 5859, 3185, 1442, 3250,  725, 5208, 2919, 4861, 5622,\n",
              "       4595,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIhDbaLydzk",
        "outputId": "8df1607d-34f4-4096-8019-a5806cbe70d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 목표 인덱스 변환\n",
        "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (신발 은 여기 있는 게 다예 요 <END>)\n",
        "print(question[0])\n",
        "y_decoder[0]\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1648, 5859, 3185, 1442, 3250,  725, 5208, 2919, 4861, 5622, 4595,\n",
              "          2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsf4tJl61Xi9"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsxmXWS41XVd"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "# decoder inputs use the previous target as input\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': x_encoder,\n",
        "        'dec_inputs': x_decoder\n",
        "    },\n",
        "    {\n",
        "        'outputs': y_decoder\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cstXcPJo4rKD",
        "outputId": "96d45fab-7c56-47a8-fbd6-3706b1657296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ({inputs: (None, 30), dec_inputs: (None, 30)}, {outputs: (None, 30)}), types: ({inputs: tf.int64, dec_inputs: tf.int64}, {outputs: tf.int64})>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxXCQWvw2jwx"
      },
      "source": [
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH-k-kk_1_Vu"
      },
      "source": [
        "## scaled dot product Attention\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True) # QK^T\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth) #  QK^T / sqrt(d_k)\n",
        "\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9) # zero padding token softmax 결과가 0이 나오도록\n",
        "  \n",
        "  attention_weights = tf.nn.softmax(logits, axis = -1) # softmax(QK^T / sqrt(d_k))\n",
        "\n",
        "  output = tf.matmul(attention_weights, value) # softmax(QK^T / sqrt(d_k)) * V\n",
        "\n",
        "  return output"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7orcKMr13xY8"
      },
      "source": [
        "## multi-head attention\n",
        "## each head need (scaled_dot_product_attention)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0 # 128,8\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "  \n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(inputs, shape=(batch_size,-1,self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3]) ##????\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    #linear\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    #split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    #scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    #concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "\n",
        "    #final linear\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmlW0oi89nEC"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37sh3f8P-JUB",
        "outputId": "0d42d691-7719-4deb-9147-86962b9a8ef4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W7ld50z3vT2"
      },
      "source": [
        "# it handle mask future tokens in a sequence used decoder. and mask pad tokens\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W25teKwt_F80",
        "outputId": "a22dbefe-1d74-44a5-a50a-74471fa6d5f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLhXEIJgASo3"
      },
      "source": [
        "Positional encoding\n",
        "\n",
        "since we don't use any rnn, cnn, positional encoding give model position information of words in sentence.\n",
        "\n",
        "positional encoding vector is added to embedding vector\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7s19-x3_Hpq"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "  \n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles #pos/10000^(2i/d_model)\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position = tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model = d_model)\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLiumNZZDZGY"
      },
      "source": [
        "### Encoder Layer\n",
        "1. Multi-head attention (with padding mask)\n",
        "2. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oarRWUMLDYnC"
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query':inputs,\n",
        "          'key':inputs,\n",
        "          'value':inputs,\n",
        "          'mask':padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3rO9IcDHGE5"
      },
      "source": [
        "### Encoder\n",
        "1. Input Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` encoder layers\n",
        "\n",
        "Embedding + positional encoding : input\n",
        "\n",
        "going encoder layers.\n",
        "\n",
        "output going decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOwoi2_jHvbA"
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)#??왜 vocab_size가 들어가지?\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, padding_mask], outputs = outputs, name=name)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8XHH5dpJr-G"
      },
      "source": [
        "### Decoder Layer\n",
        "1. Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2. Multi-head attention (with padding mask). `value` and `key` is from encoder output. `query` is from Multi-head attention layer output\n",
        "3. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtAfKdk-JrxK"
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name=\"padding_mask\")\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query' : inputs,\n",
        "          'key' : inputs,\n",
        "          'value' : inputs,\n",
        "          'mask' : look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query' : attention1,\n",
        "          'key' : enc_outputs,\n",
        "          'value' : enc_outputs,\n",
        "          'mask' : padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnBSBcm1NAYv"
      },
      "source": [
        "### Decoder\n",
        "1. output Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` decoder layers\n",
        "\n",
        "Embedding + positional encoding : input (target)\n",
        "\n",
        "going decoder layers.\n",
        "\n",
        "output going final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnA-8FEAOT4F"
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"decoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name='padding_mask')\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"decoder_layer_{}\".format(i),\n",
        "    )(inputs = [outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-vmtqKQjhf"
      },
      "source": [
        "### Transformer\n",
        "1. encoder\n",
        "2. decoder\n",
        "3. final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEMfL5SFQqr4"
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"enc_padding_mask\")(inputs)\n",
        "  \n",
        "  #mask future tokens for decoder inputs at 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1,None,None),\n",
        "      name=\"look_ahead_mask\")(dec_inputs)\n",
        "  \n",
        "  #mask encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"dec_padding_mask\")(inputs)\n",
        "  \n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pav-8Jd3ydzp"
      },
      "source": [
        "## 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8y-mjWtydzp"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256 ##word embedding dim\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "VOCAB_SIZE = len(words)\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK3IwtA4TOnN"
      },
      "source": [
        "### Loss function\n",
        "since target sequences are padded, deal this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi7YnqpVTYn2"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "  \n",
        "  mask = tf.cast(tf.not_equal(y_true,0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzHEmCzUVhTu"
      },
      "source": [
        "### Custom learning rate\n",
        "use Adam optimizer with custom learning rate\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkFm9m_LVt8c"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb8PGbKgWAbP"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vql4FYFUV_3_"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTXbb1Z2I4IM"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl3V7BllWWFG",
        "outputId": "9ffc37ed-e995-47e1-aeff-c3fa8c89c9f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "115/115 [==============================] - 5s 46ms/step - loss: 1.9760 - accuracy: 0.0198\n",
            "Epoch 2/20\n",
            "115/115 [==============================] - 6s 48ms/step - loss: 1.7268 - accuracy: 0.0333\n",
            "Epoch 3/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 1.4725 - accuracy: 0.0409\n",
            "Epoch 4/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 1.3239 - accuracy: 0.0458\n",
            "Epoch 5/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 1.2318 - accuracy: 0.0558\n",
            "Epoch 6/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 1.1458 - accuracy: 0.0661\n",
            "Epoch 7/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 1.0649 - accuracy: 0.0747\n",
            "Epoch 8/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.9910 - accuracy: 0.0816\n",
            "Epoch 9/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.9262 - accuracy: 0.0872\n",
            "Epoch 10/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.8665 - accuracy: 0.0924\n",
            "Epoch 11/20\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 0.8115 - accuracy: 0.0967\n",
            "Epoch 12/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.7602 - accuracy: 0.1014\n",
            "Epoch 13/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.7101 - accuracy: 0.1059\n",
            "Epoch 14/20\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 0.6599 - accuracy: 0.1117\n",
            "Epoch 15/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.6103 - accuracy: 0.1170\n",
            "Epoch 16/20\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 0.5625 - accuracy: 0.1236\n",
            "Epoch 17/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.5116 - accuracy: 0.1302\n",
            "Epoch 18/20\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 0.4630 - accuracy: 0.1380\n",
            "Epoch 19/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.4122 - accuracy: 0.1464\n",
            "Epoch 20/20\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.3674 - accuracy: 0.1546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d2830bf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6EDnEOwI_G7"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxi2B-vjydzt"
      },
      "source": [
        "# 인덱스를 문장으로 변환\n",
        "def convert_index_to_text(indexs, vocabulary): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == END_INDEX:\n",
        "            # 종료 인덱스면 중지\n",
        "            break;\n",
        "        if vocabulary.get(index) is not None:\n",
        "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
        "            sentence += vocabulary[index]\n",
        "        else:\n",
        "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
        "            sentence.extend([vocabulary[OOV_INDEX]])\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E66RpbXydzy"
      },
      "source": [
        "# 예측을 위한 입력 생성\n",
        "def make_predict_input(sentence):\n",
        "\n",
        "    sentences = []\n",
        "    sentences.append(sentence)\n",
        "    sentences = pos_tag(sentences)\n",
        "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
        "    \n",
        "    return input_seq"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUV-fKE0ydz0"
      },
      "source": [
        "# 텍스트 생성\n",
        "def generate_text(input_seq):\n",
        "    \n",
        "    \n",
        "    # 입력을 인코더에 넣어 마지막 상태 구함\n",
        "    states = encoder_model.predict(input_seq)\n",
        "\n",
        "    # 목표 시퀀스 초기화\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    \n",
        "    # 목표 시퀀스의 첫 번째에 <START> 태그 추가\n",
        "    target_seq[0, 0] = STA_INDEX\n",
        "    \n",
        "    # 인덱스 초기화\n",
        "    indexs = []\n",
        "    \n",
        "    # 디코더 타임 스텝 반복\n",
        "    while 1:\n",
        "        # 디코더로 현재 타임 스텝 출력 구함\n",
        "        # 처음에는 인코더 상태를, 다음부터 이전 디코더 상태로 초기화\n",
        "        decoder_outputs, state_h, state_c = decoder_model.predict(\n",
        "                                                [target_seq] + states)\n",
        "\n",
        "        # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
        "        index = np.argmax(decoder_outputs[0, 0, :])\n",
        "        indexs.append(index)\n",
        "        \n",
        "        # 종료 검사\n",
        "        if index == END_INDEX or len(indexs) >= max_sequences:\n",
        "            break\n",
        "\n",
        "        # 목표 시퀀스를 바로 이전의 출력으로 설정\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = index\n",
        "        \n",
        "        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n",
        "        states = [state_h, state_c]\n",
        "\n",
        "    # 인덱스를 문장으로 변환\n",
        "    sentence = convert_index_to_text(indexs, index_to_word)\n",
        "        \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umBNECObKCJj"
      },
      "source": [
        "def evaluate(input_seq):\n",
        "\n",
        "  input_seq = input_seq.squeeze()\n",
        "  sentence = tf.expand_dims(input_seq, axis=0)\n",
        "  output = tf.expand_dims([1], 0)\n",
        "\n",
        "  for i in range(max_sequences):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, 2):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBxzil_NWNLX",
        "outputId": "56c33526-16b7-42a7-fb8e-11092d69deb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "convert_index_to_text(evaluate(make_predict_input('이 가방 얼마에요?')).numpy()[1:],index_to_word)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'그 가방 은 오만 구천 원 이에요 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUDsxhUxWaa9",
        "outputId": "0fabb4bb-4a66-4747-be59-88786eda5cef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "convert_index_to_text(evaluate(make_predict_input('이 지갑 얼마에요?')).numpy()[1:],index_to_word)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'현금 가로 사만원 이에요 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFym9Kw4Wkb9",
        "outputId": "3d9ca535-8ef9-4b70-998a-058b538722df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "convert_index_to_text(evaluate(make_predict_input('이거 사이즈 230 있어요?')).numpy()[1:],index_to_word)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'네 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3YqOZ-MEOVW",
        "outputId": "69a24a51-def2-478c-8ab7-7d5e7c7f4dd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# for train data predict\n",
        "for seq_index in range(0,100):\n",
        "\n",
        "  print(\"고객 : \",question[seq_index])\n",
        "  print(\"정답점원 :\",answer[seq_index])\n",
        "  print(\"AI점원 :\",convert_index_to_text(evaluate(make_predict_input(question[seq_index])).numpy()[1:],index_to_word))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "고객 :  신발 은 여기 있는 게 다예 요 ?\n",
            "정답점원 : 네 성인 이나 아동 다 있어요 발 사이즈 몇 신으세요 ?\n",
            "AI점원 : 네 , 이런 신발 은 다 잘 나가요 \n",
            "\n",
            "\n",
            "고객 :  230 이요\n",
            "정답점원 : 편하게 신 을 수 있는 거 찾으세요 ?\n",
            "AI점원 : 신발 신어 보세요 \n",
            "\n",
            "\n",
            "고객 :  네 봄 이니까 편하게 신 을 수 있는 거\n",
            "정답점원 : 이런 건 어떠세요 ? 이런 거도 신발 무척 편하거든요\n",
            "AI점원 : 이런 신발 은 이런 거 어떠세요 ? \n",
            "\n",
            "\n",
            "고객 :  굽 좀 높은 거 없나요 ?\n",
            "정답점원 : 봄 상품 은 아직 어른 제품 이 많이 안 나왔습니다\n",
            "AI점원 : 제품 이 제품 은 아직 다 나갔어요 \n",
            "\n",
            "\n",
            "고객 :  언제 들어와요 ?\n",
            "정답점원 : 이번 주 지나면 들어올 거 예요\n",
            "AI점원 : 다음 주 에 입고 될 거 예요 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 가죽 이에요 ?\n",
            "정답점원 : 가죽 아니고 쎄 무예 요\n",
            "AI점원 : 가죽 이에요 \n",
            "\n",
            "\n",
            "고객 :  가죽 은 얼마 예요 ?\n",
            "정답점원 : 2만 9천 원 입니다\n",
            "AI점원 : 이 거 는 삼만 이천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  털 달린 거 저 거 는 사이즈 있어요 ?\n",
            "정답점원 : 230 이 없어요 이 거 한 번 신어 보세요\n",
            "AI점원 : 저 패딩 은 한 번 신어 보세요 \n",
            "\n",
            "\n",
            "고객 :  좀 크네 또 안 들어와요 ?\n",
            "정답점원 : 네 이건 다 끝났어요\n",
            "AI점원 : 네 , 이건 다 슬리퍼 를 찾으세요 ? \n",
            "\n",
            "\n",
            "고객 :  가방 매는 거 보고 있어요\n",
            "정답점원 : 여기 있어요\n",
            "AI점원 : 저 제품 은 없어요 \n",
            "\n",
            "\n",
            "고객 :  가격 이 얼마 예요 ?\n",
            "정답점원 : 이 종류 는 2만 원 이고 이 종류 는 3만 8천 원 이에요\n",
            "AI점원 : 이 제품 은 오만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  가죽 으로 된 거 는 없어요 ?\n",
            "정답점원 : 가죽 은 없고 레자 만 있어요\n",
            "AI점원 : 가죽 은 없어요 \n",
            "\n",
            "\n",
            "고객 :  레자 는 얼마 예요 ?\n",
            "정답점원 : 5만 5천 원요\n",
            "AI점원 : 이건 가죽 인데 , 현금 결제 하시면 십 오만 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 천이 죠 ?\n",
            "정답점원 : 네 맞아요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이건 얼마 예요 ?\n",
            "정답점원 : 그것 도 5만 5천 원요\n",
            "AI점원 : 이 티 는 오만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  이 거 끈 은 따로 없어요 ?\n",
            "정답점원 : 안 에 있어요\n",
            "AI점원 : 끈 은 없어요 \n",
            "\n",
            "\n",
            "고객 :  내일 은 문 열어요 ?\n",
            "정답점원 : 휴무 입니다\n",
            "AI점원 : 일요일 은 문 닫아요 \n",
            "\n",
            "\n",
            "고객 :  며칠 까지 휴무 예요 ?\n",
            "정답점원 : 설 까지 쉬 고 다음 날 열 거 같아요\n",
            "AI점원 : 설 까지 영업 해요 \n",
            "\n",
            "\n",
            "고객 :  여기 마스크 는 얼마 예요 ?\n",
            "정답점원 : 5천 원요\n",
            "AI점원 : 5000원 이에요 \n",
            "\n",
            "\n",
            "고객 :  이 거 나무 예요 ? 다 돌 인가요 ?\n",
            "정답점원 : 나무 도 있고 도자기 도 있어요\n",
            "AI점원 : 예 , 점퍼 로 된 거 는 다 따뜻해요 \n",
            "\n",
            "\n",
            "고객 :  이런 건 세트 로 팔아요 ?\n",
            "정답점원 : 네 세트 로만 팔아요\n",
            "AI점원 : 네 세트 로 된 게 전부 에요 \n",
            "\n",
            "\n",
            "고객 :  이건 뭐 예요 ?\n",
            "정답점원 : 마블 이라고 종이 를 말아가지고 하는 거 예요\n",
            "AI점원 : 밑 에 칸 분들 한테 는 이만원 이에요 \n",
            "\n",
            "\n",
            "고객 :  제일 큰 거 는 얼마 인데 요 ?\n",
            "정답점원 : 세트 에 7만 원 이요\n",
            "AI점원 : 그 제품 은 삼만 구천 원 인데 , 현금 결제 하시면 삼만 이천 원 까지 할인 해 드려요 \n",
            "\n",
            "\n",
            "고객 :  스카프 좀 보려구요\n",
            "정답점원 : 네 천천히 보세요\n",
            "AI점원 : 네 그럼 요즘 뜨는 칼라 가 있으니 보여 드릴게요 \n",
            "\n",
            "\n",
            "고객 :  실크 스카프 도 봄 에 하나요 ?\n",
            "정답점원 : 실크 봄 가을 에 하죠\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 뭐 예요 ?\n",
            "정답점원 : 토시 예요\n",
            "AI점원 : 그거 는 크로스 백 이에요 \n",
            "\n",
            "\n",
            "고객 :  여기 가격 은 그대로 파시 는 거 예요 ?\n",
            "정답점원 : 네 핸드 메이드 로 해가지고 그 가격 으로 팔아요\n",
            "AI점원 : 네 , 구정 지나야 들어와요 \n",
            "\n",
            "\n",
            "고객 :  착용 해볼 수 있어요 ?\n",
            "정답점원 : 네 가능하세요\n",
            "AI점원 : 네 착용 은 안되고 착용 해보셔도 됩니다 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 요즘 들어온 거 예요 ?\n",
            "정답점원 : 네 어제 들어왔어요\n",
            "AI점원 : 네 어제 들어왔어요 \n",
            "\n",
            "\n",
            "고객 :  세탁 은 물 세탁 되죠 ?\n",
            "정답점원 : 끝 부분 이 가죽 이라서 조심해야 해 요\n",
            "AI점원 : 네 , 세탁기 로 물 세탁 하시면 돼요 \n",
            "\n",
            "\n",
            "고객 :  지금 여기 있는 게 다예 요 ?\n",
            "정답점원 : 네 다예 요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  몇 시 에 문 닫아요 ?\n",
            "정답점원 : 8시 까지 합니다\n",
            "AI점원 : 8시 까지 영업 해요 \n",
            "\n",
            "\n",
            "고객 :  일요일 도 하세요 ?\n",
            "정답점원 : 아뇨 닫아요\n",
            "AI점원 : 일요일 은 문 닫아요 \n",
            "\n",
            "\n",
            "고객 :  스카프 있어요 ?\n",
            "정답점원 : 네 여기는 2 단 이 거 는 3 단 제품 있어요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이런 건 세탁 을 어떻게 해 요 ?\n",
            "정답점원 : 울 샴푸 를 물 에 몇 방울 떨어뜨려서 조물조물 하면 됩니다\n",
            "AI점원 : 울 샴푸 로 손 빨래 하셔야 돼요 \n",
            "\n",
            "\n",
            "고객 :  원단 은 뭐 예요 ?\n",
            "정답점원 : 원단 이 구김 안 가고 참 괜찮아요\n",
            "AI점원 : 원단 은 원단 에 적혀 있어요 \n",
            "\n",
            "\n",
            "고객 :  얼마 인데 요 ?\n",
            "정답점원 : 2만 원 입니다\n",
            "AI점원 : 그 티 는 오만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  브로치 같은 건 어디 있나요 ?\n",
            "정답점원 : 여기 있는 거 밖에 없어요\n",
            "AI점원 : 여기 있습니다 \n",
            "\n",
            "\n",
            "고객 :  이런 거도 2만 원 이예 요 ?\n",
            "정답점원 : 헤르메스 인데 이 것 도 괜찮아요\n",
            "AI점원 : 이 옷 은 가죽 이라 그래요 \n",
            "\n",
            "\n",
            "고객 :  명품 이랑 똑같이 한 거 예요 ?\n",
            "정답점원 : 네 원단 만 다르고 디자인 을 똑같이 만든 거 예요\n",
            "AI점원 : 네 , 원단 만 적혀 있어요 \n",
            "\n",
            "\n",
            "고객 :  온누리 상품권 도 되죠 ?\n",
            "정답점원 : 네 됩니다\n",
            "AI점원 : 네 됩니다 \n",
            "\n",
            "\n",
            "고객 :  브로치 하고 머리핀 하고 보려고요\n",
            "정답점원 : 머리핀 은 밖에 있고 브로치 는 안 에 있습니다\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  도자기 같은 거 말고 구슬 이나 진주 같은 거 는 없어요 ?\n",
            "정답점원 : 지금 옷 에 가볍게 하려면 진주 도 예쁘지만 이 것 도 깔끔합니다 보석 은 싫으세요 ?\n",
            "AI점원 : 옷 은 십칠만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  그건 흥미 없고 안 에 하면 안 떨어져요 ?\n",
            "정답점원 : 안 떨어져요\n",
            "AI점원 : 안 떨어져요 \n",
            "\n",
            "\n",
            "고객 :  얼마 예요 ?\n",
            "정답점원 : 핀 꼽는 거 는 좀 싼 거고 이 거 는 3만 원대 예요\n",
            "AI점원 : 이만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  이 우산 은 얼마 인데 요 ?\n",
            "정답점원 : 4만 2천 원 이요\n",
            "AI점원 : 4만 2천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  무겁지 않아요 ?\n",
            "정답점원 : 좋은 재료 를 쓰기 때문 에 무겁지 않아요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이렇게 다는 거 맞아요 ?\n",
            "정답점원 : 그렇게 달 면 안되고 이렇게 달아야 해 요\n",
            "AI점원 : 프라다 원단 들 이 많이 신어 요 \n",
            "\n",
            "\n",
            "고객 :  자석 은 다 3만 원 ?\n",
            "정답점원 : 3만 원 짜 리도 있고 2만 원 짜 리도 있어요\n",
            "AI점원 : 그 티셔츠 삼만 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  머리핀 종류 도 한 번 보여주세요 곱창 은 요새 안 나와요 ?\n",
            "정답점원 : 곱창 밴드 는 안 나와요 촌스러워서 유행 다 지났어요\n",
            "AI점원 : 네 , 다 있진 않아요 \n",
            "\n",
            "\n",
            "고객 :  브로치 종류 도 있어요 ?\n",
            "정답점원 : 아뇨 없어요\n",
            "AI점원 : 네 , 없어요 \n",
            "\n",
            "\n",
            "고객 :  스카프 도 없어요 ?\n",
            "정답점원 : 스카프 는 이 쪽 에 종류 가 있어요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이런 거 실크 입 니까 ?\n",
            "정답점원 : 실크 아니예요\n",
            "AI점원 : 프라다 원단 들 이에요 \n",
            "\n",
            "\n",
            "고객 :  이런 거 는 뭐라 그래요 ?\n",
            "정답점원 : 실캣 으로 만든 거 죠\n",
            "AI점원 : 예 , 점퍼 로 많이 나오죠 \n",
            "\n",
            "\n",
            "고객 :  이런 거 는 얼마 예요 ?\n",
            "정답점원 : 대충 2만 원 내외 요\n",
            "AI점원 : 이 거 는 이만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  이런 거 는 물 세탁 됩니까 ?\n",
            "정답점원 : 물 세탁 조금 해도 상관 은 없으세요\n",
            "AI점원 : 네 , 세탁기 로 물 세탁 하셔도 돼요 \n",
            "\n",
            "\n",
            "고객 :  근데 이 거 제 가 한 거 아닌데 약간 올이 나갔네요\n",
            "정답점원 : 이 거 원하시면 주문 가능하세요\n",
            "AI점원 : 이 거 어떠세요 ? \n",
            "\n",
            "\n",
            "고객 :  또 언제 들어와요 ?\n",
            "정답점원 : 스카프 는 많이 들어오지 않아서 주문 하시는 게 좋아요\n",
            "AI점원 : 다음 에 입고 될 거 예요 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 목걸이 링 이에요 ?\n",
            "정답점원 : 아뇨 반지 예요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  금 이에요 ?\n",
            "정답점원 : 액세서리 예요 금 아니예요\n",
            "AI점원 : 아니요 , 그냥 된 게 다 맞아요 \n",
            "\n",
            "\n",
            "고객 :  이 거 한 번 해봐도 돼요 ?\n",
            "정답점원 : 네 가능합니다\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  신 상품 더 들어오죠 ?\n",
            "정답점원 : 네 들어올 거 예요\n",
            "AI점원 : 네 들어올 거 예요 \n",
            "\n",
            "\n",
            "고객 :  이 모양 으로 목걸이 팔찌 세트 구입 할까 하는데\n",
            "정답점원 : 똑같은 모양 은 주문 을 넣어야 할 거 같은데요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  가격 은 어떻게 돼요 ?\n",
            "정답점원 : 모양 을 보고 견적 을 내 봐야 해 요\n",
            "AI점원 : 가격 은 오만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  이 금 팔찌 는 무게 가 얼마 정도 인지 확인 할 수 있어요 ?\n",
            "정답점원 : 세 돈 이 조금 넘네요\n",
            "AI점원 : 18 k 로 되어 있는 가격 이 가장 비싼 것 은 가격 이 가장 비싼 거 인데 한 돈 인데 , 지금 만원 이 가장 비싼 거 는 이 세 \n",
            "\n",
            "\n",
            "고객 :  견본 인 팔찌 가 있어요 ?\n",
            "정답점원 : 여기 있습니다\n",
            "AI점원 : 여기 있습니다 \n",
            "\n",
            "\n",
            "고객 :  여기는 금 매입 도 해 요 ?\n",
            "정답점원 : 네 해 요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이 거 판다 고 얼마 정도 받을 수 있어요 ?\n",
            "정답점원 : 대충 39만 3천 원 정도 나오네요\n",
            "AI점원 : 6만 9천원 이에요 \n",
            "\n",
            "\n",
            "고객 :  팔찌 두 돈 짜 리도 한 번 보여주시고 다른 거도 보여주세요\n",
            "정답점원 : 유행 하는 로 즈 골드 하셔도 되고 골드 하셔도 돼요\n",
            "AI점원 : 골드 랑 실버 로 많이 하셔도 돼요 \n",
            "\n",
            "\n",
            "고객 :  가격 이 구입 하려면 얼마 인데 요 ?\n",
            "정답점원 : 현금 가격 기준 으로 62만 9천 원 이요\n",
            "AI점원 : 그 가격 은 오만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  이 거 18 케이 예요 ?\n",
            "정답점원 : 네 18 케이 예요\n",
            "AI점원 : 네 , 맞아요 \n",
            "\n",
            "\n",
            "고객 :  시내 에 있는 금 도매 상 하고 여기 랑 가격 차이 가 많이 나 요 ?\n",
            "정답점원 : 그 쪽 은 유지비 가 많이 나가니까 아무래도 여기 가 더 싸죠\n",
            "AI점원 : 그 티 는 , 저 제품 은 별로 사가지 않아요 \n",
            "\n",
            "\n",
            "고객 :  액세서리 세 일 제품 이 있나요 ?\n",
            "정답점원 : 악세서리 어떤 거 찾으세요 ?\n",
            "AI점원 : 네 , 이 제품 은 다 나갔어요 \n",
            "\n",
            "\n",
            "고객 :  스카프 같은 거\n",
            "정답점원 : 이 거 괜찮아요\n",
            "AI점원 : 이 제품 은 어떠세요 ? \n",
            "\n",
            "\n",
            "고객 :  이건 소재 가 뭐 예요 ?\n",
            "정답점원 : 폴리에스테르 라고 적혀 있네요\n",
            "AI점원 : 이 제품 은 캐시미어 울 혼방 이에요 \n",
            "\n",
            "\n",
            "고객 :  색상 은 이 거 하나 뿐 이고 ?\n",
            "정답점원 : 네 다 빠지고 이 거 하나 예요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  빨 면 좀 그렇지 않을까 ?\n",
            "정답점원 : 조심해야 하는데 면 이 아니니까 집 에서 손 드라이 해도 돼요\n",
            "AI점원 : 집 에서 세탁 하면 돼요 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 가격 이 얼마 예요 ?\n",
            "정답점원 : 16000원 인데 몇 천 원 빼 드릴게요\n",
            "AI점원 : 이 거 는 오만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  이건 얼마 예요 ?\n",
            "정답점원 : 13000원 입니다\n",
            "AI점원 : 이 티 는 오만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  이 핑크색 모자 는 애기 들 꺼예요 ?\n",
            "정답점원 : 애기 용 입니다\n",
            "AI점원 : 예 , 촉 만 18 K 에요 \n",
            "\n",
            "\n",
            "고객 :  어른 들 꺼는 없어요 ?\n",
            "정답점원 : 다 빠졌어요\n",
            "AI점원 : 다 빠졌어요 \n",
            "\n",
            "\n",
            "고객 :  팔찌 제품 따로 있나요 ?\n",
            "정답점원 : 고객 님 이 하실 거 예요 ?\n",
            "AI점원 : 네 고객 님 이 팔찌 가 팔찌 에요 \n",
            "\n",
            "\n",
            "고객 :  네 지금 세 일 기간 이에요 ?\n",
            "정답점원 : 네 당분간 은 할 거 같아요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  한 몇 프로 하는데요 ?\n",
            "정답점원 : 정가 에서 한 40 프로 합니다\n",
            "AI점원 : 30 프로 할인 합니다 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 가격 대가 얼마 예요 ?\n",
            "정답점원 : 이 거 샘플 이 14 케이 인데 뭘 로 봐 드릴 까요 ?\n",
            "AI점원 : 이 거 는 오만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  18 케이 로\n",
            "정답점원 : 18 케이 로 하시면 49만 원 이요\n",
            "AI점원 : 이 제품 도 잘 나가요 \n",
            "\n",
            "\n",
            "고객 :  팔찌 좀 핫 한 제품 뭐 가 있어요 ?\n",
            "정답점원 : 깔끔하게 이런 거 잘나가요\n",
            "AI점원 : 이런 제품 이 많이 나가고 있는데 조금 많이 나가요 \n",
            "\n",
            "\n",
            "고객 :  18 케이 예요 ?\n",
            "정답점원 : 네 맞아요\n",
            "AI점원 : 네 , 맞아요 \n",
            "\n",
            "\n",
            "고객 :  돈 수로 따지면 몇 돈 이에요 ?\n",
            "정답점원 : 두 돈반 조금 안 돼요\n",
            "AI점원 : 이 제품 , 두 개 가 좀 더 붙어요 \n",
            "\n",
            "\n",
            "고객 :  얼마 예요 ?\n",
            "정답점원 : 48만 원 정도 요\n",
            "AI점원 : 이만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  굵은 게 이 거 다예 요 ?\n",
            "정답점원 : 5 돈 6 돈 짜 리도 있어요 굵은 거 찾으시면 이런 건 어떠세요 ?\n",
            "AI점원 : 네 , 이런 거 는 없어요 \n",
            "\n",
            "\n",
            "고객 :  너무 사치스러운데 핸드폰 케이스 파는 거 예요 ?\n",
            "정답점원 : 네 맞습니다\n",
            "AI점원 : 네 맞습니다 \n",
            "\n",
            "\n",
            "고객 :  여기는 가격 이 어떤 게 있어요 ?\n",
            "정답점원 : 기 종이 어떻게 되죠 ?\n",
            "AI점원 : 지금 세 일 하 는 거 라 싸요 \n",
            "\n",
            "\n",
            "고객 :  엘지 인데\n",
            "정답점원 : 만 오천 원대 부터 시작 해서 이만 오천 원 까지 있습니다\n",
            "AI점원 : 그 티 이만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  그건 얼마 예요 ?\n",
            "정답점원 : 3만 원 정도 해 요\n",
            "AI점원 : 그건 16000원 이에요 \n",
            "\n",
            "\n",
            "고객 :  색상 은 이 게 전부 예요 ?\n",
            "정답점원 : 레드 색 인데 핑크 도 있고 보랏빛 퍼플 색도 있고 색상 종류 가 다양해요\n",
            "AI점원 : 네 , 색상 은 블랙 색상 이 더 어울리세요 \n",
            "\n",
            "\n",
            "고객 :  엘지 지 식스 케이스 로 좀 보여주세요\n",
            "정답점원 : 그 기종은 여기 있어요\n",
            "AI점원 : 그 티셔츠 은 여기 있어요 \n",
            "\n",
            "\n",
            "고객 :  이건 얼마 예요 ?\n",
            "정답점원 : 3만 5천 원 입니다\n",
            "AI점원 : 이 티 는 오만 구천 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  현금 으로 사면 할인 이 된다거나 그런 게 있나요 ?\n",
            "정답점원 : 현금 으로 하면 좀 디씨 해드려요\n",
            "AI점원 : 현금 으로 하면 10 프로 할인 해드려요 \n",
            "\n",
            "\n",
            "고객 :  반지 이 거 세척 가능해요 ?\n",
            "정답점원 : 월요일 에 해야 해 요\n",
            "AI점원 : 월요일 에 오시 면 됩니다 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOBDpAVqFOW_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}