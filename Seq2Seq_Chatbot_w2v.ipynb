{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Seq2Seq_Chatbot_w2v.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ideablast/NLPer_chatbot/blob/kdg/Seq2Seq_Chatbot_w2v.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsiilWsMNHHL"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UA-8fQ2EDnp"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DAFy5c7ydzC"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers, losses, metrics\n",
        "from keras import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioT3c4eLEKon"
      },
      "source": [
        "## Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9YUdE1OydzG"
      },
      "source": [
        "# 태그 단어\n",
        "PAD = \"<PADDING>\"   # 패딩\n",
        "STA = \"<START>\"     # 시작\n",
        "END = \"<END>\"       # 끝\n",
        "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
        "\n",
        "# 태그 인덱스\n",
        "PAD_INDEX = 0\n",
        "STA_INDEX = 1\n",
        "END_INDEX = 2\n",
        "OOV_INDEX = 3\n",
        "\n",
        "# 데이터 타입\n",
        "ENCODER_INPUT  = 0\n",
        "DECODER_INPUT  = 1\n",
        "DECODER_TARGET = 2\n",
        "\n",
        "# 한 문장에서 단어 시퀀스의 최대 개수\n",
        "max_sequences = 30\n",
        "\n",
        "# 임베딩 벡터 차원\n",
        "embedding_dim = 100\n",
        "\n",
        "# LSTM 히든레이어 차원 : 100 이 좋단다.\n",
        "lstm_hidden_dim = 100\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "# 정규 표현식 필터\n",
        "RE_FILTER = re.compile(\"[\\\"':;~()]\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhVVnW_uEWT1"
      },
      "source": [
        "## Data Load & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80IauV0FpUv2",
        "outputId": "ab8e9bb0-aea3-4310-c736-ce1db05cfb03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEHDnPXNzZlM",
        "outputId": "e1e9e0e1-d747-4f4f-a548-5d8bd40effd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "wear_data = pd.read_csv(\"/content/drive/My Drive/wear.csv\")\n",
        "print(wear_data.shape)\n",
        "customer = wear_data[wear_data.SPEAKER == \"고객\"].SENTENCE\n",
        "store = wear_data[wear_data.SPEAKER == \"점원\"].SENTENCE\n",
        "print(customer.shape, store.shape) # 질문의 개수와 답의 개수가 일치하지 않는다."
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15826, 20)\n",
            "(8381,) (7445,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLNSiqcHM4WY",
        "outputId": "63d97180-b4d8-4149-dfcd-16283da1a24b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "prev = \"고객\"\n",
        "store_arr = []\n",
        "customer_arr = []\n",
        "store_stc = \"\"\n",
        "customer_stc = \"\"\n",
        "\n",
        "for i in range(wear_data.shape[0]):\n",
        "    if (prev == wear_data.iloc[i].SPEAKER):\n",
        "        if prev == \"점원\":\n",
        "             store_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "        else : \n",
        "             customer_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "            \n",
        "    elif prev == \"점원\":\n",
        "        store_arr.append(store_stc)\n",
        "        customer_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"고객\"\n",
        "    else :\n",
        "        customer_arr.append(customer_stc)\n",
        "        store_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"점원\"\n",
        "\n",
        "print(len(store_arr))\n",
        "print(len(customer_arr))\n",
        "print(store_arr[-1])\n",
        "print(customer_arr[-1]) # 자료 상에서 이후에는 계속 고객의 물음만 계속된다. 코드 레벨에서 이 부분은 빼게 구현했다. (stc는 만들어지지만 arr에 append 안하게 된다.)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7301\n",
            "7301\n",
            "요즘 파스텔 톤이 유행이에요\n",
            "요즘 유행하는 색깔이 뭐예요?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNvig2FMzjXj",
        "outputId": "f2bcb7f3-0c4c-4465-ac06-993183a685f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "question = []\n",
        "answer = []\n",
        "\n",
        "for Q in customer_arr:\n",
        "    question.append(Q.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "for A in store_arr:\n",
        "    answer.append(A.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "len(question), len(answer)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7301, 7301)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbivSckMydzN"
      },
      "source": [
        "# 형태소분석 함수\n",
        "def pos_tag(sentences):\n",
        "    \n",
        "    # KoNLPy 형태소분석기 설정\n",
        "    tagger = Okt()\n",
        "    \n",
        "    # 문장 품사 변수 초기화\n",
        "    sentences_pos = []\n",
        "    \n",
        "    # 모든 문장 반복\n",
        "    for sentence in sentences:\n",
        "        # [\\\"':;~()] 특수기호 제거\n",
        "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
        "        \n",
        "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
        "        sentence = \" \".join(tagger.morphs(sentence))\n",
        "        sentences_pos.append(sentence)\n",
        "        \n",
        "    return sentences_pos"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seqSNWcydzP",
        "outputId": "4b133059-163c-48d9-9947-afdad2f001d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# 형태소분석 수행\n",
        "question = pos_tag(question)\n",
        "answer = pos_tag(answer)\n",
        "\n",
        "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
        "for i in range(5):\n",
        "    print('Q : ' + question[i])\n",
        "    print('A : ' + answer[i])\n",
        "    print()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q : 신발 은 여기 있는 게 다예 요 ?\n",
            "A : 네 성인 이나 아동 다 있어요 발 사이즈 몇 신으세요 ?\n",
            "\n",
            "Q : 230 이요\n",
            "A : 편하게 신 을 수 있는 거 찾으세요 ?\n",
            "\n",
            "Q : 네 봄 이니까 편하게 신 을 수 있는 거\n",
            "A : 이런 건 어떠세요 ? 이런 거도 신발 무척 편하거든요\n",
            "\n",
            "Q : 굽 좀 높은 거 없나요 ?\n",
            "A : 봄 상품 은 아직 어른 제품 이 많이 안 나왔습니다\n",
            "\n",
            "Q : 언제 들어와요 ?\n",
            "A : 이번 주 지나면 들어올 거 예요\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrnct_nzydzR"
      },
      "source": [
        "# 질문과 대답 문장들을 하나로 합침\n",
        "sentences = []\n",
        "sentences.extend(question)\n",
        "sentences.extend(answer)\n",
        "\n",
        "words = []\n",
        "\n",
        "# 단어들의 배열 생성\n",
        "for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "        words.append(word)\n",
        "\n",
        "# 길이가 0인 단어는 삭제\n",
        "words = [word for word in words if len(word) > 0]\n",
        "\n",
        "# 중복된 단어 삭제\n",
        "words = list(set(words))\n",
        "\n",
        "# 제일 앞에 태그 단어 삽입\n",
        "words[:0] = [PAD, STA, END, OOV]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE9ZhJpEy_rT",
        "outputId": "a37a6780-a85d-4f16-a812-aaeb59d5470b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"손님과 점원의 말에서 사용된 총 단어의 수 :\",len(words))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "손님과 점원의 말에서 사용된 총 단어의 수 : 6409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkvyOnSvydzX"
      },
      "source": [
        "# 단어와 인덱스의 딕셔너리 생성\n",
        "word_to_index = {word: index for index, word in enumerate(words)}\n",
        "index_to_word = {index: word for index, word in enumerate(words)}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfoTztrvydzc"
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "def convert_text_to_index(sentences, vocabulary, type): \n",
        "    \n",
        "    sentences_index = []\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for sentence in sentences:\n",
        "        sentence_index = []\n",
        "        \n",
        "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
        "        if type == DECODER_INPUT:\n",
        "            sentence_index.extend([vocabulary[STA]])\n",
        "        \n",
        "        # 문장의 단어들을 띄어쓰기로 분리\n",
        "        for word in sentence.split():\n",
        "            if vocabulary.get(word) is not None:\n",
        "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[word]])\n",
        "            else:\n",
        "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "        # 최대 길이 검사\n",
        "        if type == DECODER_TARGET:\n",
        "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
        "            if len(sentence_index) >= max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
        "            else:\n",
        "                sentence_index += [vocabulary[END]]\n",
        "        else:\n",
        "            if len(sentence_index) > max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences]\n",
        "            \n",
        "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "        \n",
        "        # 문장의 인덱스 배열을 추가\n",
        "        sentences_index.append(sentence_index)\n",
        "\n",
        "    return np.asarray(sentences_index)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zezFPTvcydzf",
        "outputId": "55ccb95e-1033-457d-d698-dab79f074427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# 인코더 입력 인덱스 변환\n",
        "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
        "\n",
        "# 첫 번째 인코더 입력 출력 (신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_encoder[0]\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4966, 5168, 1688, 6280, 1356, 4391, 5957, 4581,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmql1Lf_ydzh",
        "outputId": "bac31067-f0a0-41fd-cd9f-0b1c79eca99c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# 디코더 입력 인덱스 변환\n",
        "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (<START> 신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_decoder[0]\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,  607, 4418, 1608,  742, 5731, 4078, 5841, 1805, 3108, 2934,\n",
              "       4581,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIhDbaLydzk",
        "outputId": "c6375a3f-eec4-4726-8fa3-88bbd16cdb77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# 디코더 목표 인덱스 변환\n",
        "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (신발 은 여기 있는 게 다예 요 <END>)\n",
        "print(question[0])\n",
        "y_decoder[0]\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 607, 4418, 1608,  742, 5731, 4078, 5841, 1805, 3108, 2934, 4581,\n",
              "          2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcnO_cKfo8B8"
      },
      "source": [
        "## Embedding layer Train.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiU0z7PApAF5"
      },
      "source": [
        "sentence_arr = [] #데이터의 모든 문장\n",
        "pos_tag_sentence_arr = [] #특수문자 처리와, 토큰화 된 문장\n",
        "tokenized_sentence_arr = [[]] # 토큰화된 문장의 단어들 떨어뜨리기\n",
        "for i in range(len(wear_data.SENTENCE)):\n",
        "  sentence_arr.append(wear_data.SENTENCE[i])\n",
        "pos_tag_sentence_arr = pos_tag(sentence_arr)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYR9vIn3CLu5"
      },
      "source": [
        "for s in pos_tag_sentence_arr:\n",
        "  split_s = s.split()\n",
        "  tokenized_sentence_arr.append(split_s)\n",
        "tokenized_sentence_arr = tokenized_sentence_arr[1:]"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IULN6P7MCOuy"
      },
      "source": [
        "w2v_model = Word2Vec(sentences=tokenized_sentence_arr, size=embedding_dim, window=5, min_count=1)\n",
        "emb_layer = w2v_model.wv.get_keras_embedding(train_embeddings=True)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pav-8Jd3ydzp"
      },
      "source": [
        "## 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8y-mjWtydzp"
      },
      "source": [
        "#--------------------------------------------\n",
        "# 훈련 모델 인코더 정의\n",
        "#--------------------------------------------\n",
        "\n",
        "# 입력 문장의 인덱스 시퀀스를 입력으로 받음\n",
        "encoder_inputs = layers.Input(shape=(None,))\n",
        "encoder_emb = emb_layer(encoder_inputs)\n",
        "encoder_masking = layers.Masking(mask_value=0)(encoder_emb)\n",
        "encoder_outputs, state_h, state_c = layers.LSTM(lstm_hidden_dim,\n",
        "                                                return_state=True)(encoder_masking)\n",
        "\n",
        "# 히든 상태와 셀 상태를 하나로 묶음\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "#--------------------------------------------\n",
        "# 훈련 모델 디코더 정의\n",
        "#--------------------------------------------\n",
        "\n",
        "# 목표 문장의 인덱스 시퀀스를 입력으로 받음\n",
        "decoder_inputs = layers.Input(shape=(None,))\n",
        "\n",
        "# 임베딩 레이어\n",
        "decoder_embedding = emb_layer(encoder_inputs)\n",
        "decoder_masking = layers.Masking(mask_value=0)(decoder_embedding)\n",
        "\n",
        "# 인코더와 달리 return_sequences를 True로 설정하여 모든 타임 스텝 출력값 리턴\n",
        "# 모든 타임 스텝의 출력값들을 다음 레이어의 Dense()로 처리하기 위함\n",
        "decoder_lstm = layers.LSTM(lstm_hidden_dim,\n",
        "                           return_state=True,\n",
        "                           return_sequences=True)\n",
        "\n",
        "# initial_state를 인코더의 상태로 초기화\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_masking,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# 단어의 개수만큼 노드의 개수를 설정하여 원핫 형식으로 각 단어 인덱스를 출력\n",
        "decoder_dense = layers.Dense(len(words), activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------\n",
        "# 훈련 모델 정의\n",
        "#--------------------------------------------\n",
        "\n",
        "# 입력과 출력으로 함수형 API 모델 생성\n",
        "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# 학습 방법 설정\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1bkvRU0ydzr"
      },
      "source": [
        "#--------------------------------------------\n",
        "#  예측 모델 인코더 정의\n",
        "#--------------------------------------------\n",
        "\n",
        "# 훈련 모델의 인코더 상태를 사용하여 예측 모델 인코더 설정\n",
        "encoder_model = models.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "#--------------------------------------------\n",
        "# 예측 모델 디코더 정의\n",
        "#--------------------------------------------\n",
        "\n",
        "# 예측시에는 훈련시와 달리 타임 스텝을 한 단계씩 수행\n",
        "# 매번 이전 디코더 상태를 입력으로 받아서 새로 설정\n",
        "decoder_state_input_h = layers.Input(shape=(lstm_hidden_dim,))\n",
        "decoder_state_input_c = layers.Input(shape=(lstm_hidden_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]    \n",
        "\n",
        "# 임베딩 레이어\n",
        "decoder_outputs = emb_layer(decoder_inputs)\n",
        "\n",
        "# LSTM 레이어\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_outputs,\n",
        "                                                 initial_state=decoder_states_inputs)\n",
        "\n",
        "# 히든 상태와 셀 상태를 하나로 묶음\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "# Dense 레이어를 통해 원핫 형식으로 각 단어 인덱스를 출력\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# 예측 모델 디코더 설정\n",
        "decoder_model = models.Model([decoder_inputs] + decoder_states_inputs,\n",
        "                      [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubnZvGdnydzs"
      },
      "source": [
        "예측 모델은 이미 학습된 훈련 모델의 레이어들을 그대로 재사용합니다. 예측 모델 인코더는 훈련 모델 인코더과 동일합니다. 그러나 예측 모델 디코더는 매번 LSTM 상태값을 입력으로 받습니다. 또한 디코더의 LSTM 상태를 출력값과 같이 내보내서, 다음 번 입력에 넣습니다. \n",
        "\n",
        "이렇게 하는 이유는 LSTM을 딱 한번의 타임 스텝만 실행하기 때문입니다. 그래서 매번 상태값을 새로 초기화 해야 합니다. 이와 반대로 훈련할때는 문장 전체를 계속 LSTM으로 돌리기 때문에 자동으로 상태값이 전달됩니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOEiyOizydzt"
      },
      "source": [
        "\n",
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxi2B-vjydzt"
      },
      "source": [
        "# 인덱스를 문장으로 변환\n",
        "def convert_index_to_text(indexs, vocabulary): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == END_INDEX:\n",
        "            # 종료 인덱스면 중지\n",
        "            break;\n",
        "        if vocabulary.get(index) is not None:\n",
        "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
        "            sentence += vocabulary[index]\n",
        "        else:\n",
        "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
        "            sentence.extend([vocabulary[OOV_INDEX]])\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1KKrPyKNmfS",
        "outputId": "8921789e-161f-476c-8bfa-4fb0f61c5956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "x_encoder[2]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2103,  718, 4415,   75, 4896, 6094,  301, 3898,  273,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHjf2nmyB3Pf",
        "outputId": "ece4336b-7ef7-4787-d52a-d44752188248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "x_encoder[2].reshape(1, x_encoder[2].shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3245, 1886, 6060, 4767, 1496, 5142, 6206,  624, 3873,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeEaQyYRydzv",
        "outputId": "e9eb59b0-c623-47e0-e224-1e236dbee9e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 에폭 반복\n",
        "for epoch in range(epochs):\n",
        "    print('Total Epoch :', epoch + 1)\n",
        "\n",
        "    # 훈련 시작\n",
        "    history = model.fit(x = [x_encoder, x_decoder],\n",
        "                        y = y_decoder,\n",
        "                        verbose=1,\n",
        "                        validation_split = 0.1\n",
        "                        )\n",
        "    #'신발 은 여기 있는 게 다예 요 ?'에 대한 대답\n",
        "    input_encoder = x_encoder[0].reshape(1, x_encoder[0].shape[0])\n",
        "    input_decoder = x_decoder[0].reshape(1, x_decoder[0].shape[0])\n",
        "    results = model.predict([input_encoder, input_decoder])\n",
        "    \n",
        "    # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
        "    # 1축을 기준으로 가장 높은 값의 위치를 구함\n",
        "    indexs = np.argmax(results[0], 1)\n",
        "    \n",
        "    # 인덱스를 문장으로 변환\n",
        "    sentence = convert_index_to_text(indexs, index_to_word)\n",
        "    print(sentence)\n",
        "    print()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Epoch : 1\n",
            "206/206 [==============================] - 9s 43ms/step - loss: 2.1524 - accuracy: 0.7654 - val_loss: 1.6101 - val_accuracy: 0.7796\n",
            "네 \n",
            "\n",
            "Total Epoch : 2\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.5753 - accuracy: 0.7762 - val_loss: 1.5489 - val_accuracy: 0.7701\n",
            "네 이 \n",
            "\n",
            "Total Epoch : 3\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.5514 - accuracy: 0.7770 - val_loss: 1.5462 - val_accuracy: 0.7588\n",
            "네 이 \n",
            "\n",
            "Total Epoch : 4\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.5314 - accuracy: 0.7775 - val_loss: 1.5683 - val_accuracy: 0.7632\n",
            "네 이 \n",
            "\n",
            "Total Epoch : 5\n",
            "206/206 [==============================] - 4s 22ms/step - loss: 1.5150 - accuracy: 0.7782 - val_loss: 1.5376 - val_accuracy: 0.7672\n",
            "네 이 은 \n",
            "\n",
            "Total Epoch : 6\n",
            "206/206 [==============================] - 4s 22ms/step - loss: 1.5006 - accuracy: 0.7784 - val_loss: 1.5353 - val_accuracy: 0.7662\n",
            "네 이 은 \n",
            "\n",
            "Total Epoch : 7\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.4884 - accuracy: 0.7785 - val_loss: 1.5333 - val_accuracy: 0.7664\n",
            "네 이 은 \n",
            "\n",
            "Total Epoch : 8\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.4744 - accuracy: 0.7789 - val_loss: 1.5425 - val_accuracy: 0.7658\n",
            "네 이 은 \n",
            "\n",
            "Total Epoch : 9\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.4602 - accuracy: 0.7794 - val_loss: 1.5454 - val_accuracy: 0.7618\n",
            "네 이 은 이 \n",
            "\n",
            "Total Epoch : 10\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.4453 - accuracy: 0.7800 - val_loss: 1.5176 - val_accuracy: 0.7584\n",
            "네 은 은 \n",
            "\n",
            "Total Epoch : 11\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.4336 - accuracy: 0.7803 - val_loss: 1.5125 - val_accuracy: 0.7606\n",
            "네 은 은 \n",
            "\n",
            "Total Epoch : 12\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.4187 - accuracy: 0.7808 - val_loss: 1.5467 - val_accuracy: 0.7567\n",
            "네 이 이 이 \n",
            "\n",
            "Total Epoch : 13\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.4063 - accuracy: 0.7817 - val_loss: 1.5572 - val_accuracy: 0.7687\n",
            "네 거 은 이 \n",
            "\n",
            "Total Epoch : 14\n",
            "206/206 [==============================] - 5s 22ms/step - loss: 1.3958 - accuracy: 0.7820 - val_loss: 1.5440 - val_accuracy: 0.7569\n",
            "네 거 이 이 \n",
            "\n",
            "Total Epoch : 15\n",
            "206/206 [==============================] - 5s 23ms/step - loss: 1.3862 - accuracy: 0.7824 - val_loss: 1.6331 - val_accuracy: 0.7407\n",
            "네 거 이 이 이 이 이 \n",
            "\n",
            "Total Epoch : 16\n",
            "206/206 [==============================] - 5s 22ms/step - loss: 1.3743 - accuracy: 0.7830 - val_loss: 1.5003 - val_accuracy: 0.7673\n",
            "네 은 은 \n",
            "\n",
            "Total Epoch : 17\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.3660 - accuracy: 0.7834 - val_loss: 1.5246 - val_accuracy: 0.7600\n",
            "네 거 은 \n",
            "\n",
            "Total Epoch : 18\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.3556 - accuracy: 0.7843 - val_loss: 1.5412 - val_accuracy: 0.7594\n",
            "네 거 은 은 \n",
            "\n",
            "Total Epoch : 19\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.3471 - accuracy: 0.7846 - val_loss: 1.5532 - val_accuracy: 0.7568\n",
            "네 은 은 이 이 \n",
            "\n",
            "Total Epoch : 20\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.3371 - accuracy: 0.7856 - val_loss: 1.5594 - val_accuracy: 0.7602\n",
            "네 은 은 이 이 이 \n",
            "\n",
            "Total Epoch : 21\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.3285 - accuracy: 0.7861 - val_loss: 1.5492 - val_accuracy: 0.7629\n",
            "이 거 은 이 \n",
            "\n",
            "Total Epoch : 22\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.3198 - accuracy: 0.7870 - val_loss: 1.5783 - val_accuracy: 0.7615\n",
            "네 은 은 이 이 이 \n",
            "\n",
            "Total Epoch : 23\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.3107 - accuracy: 0.7877 - val_loss: 1.5715 - val_accuracy: 0.7582\n",
            "네 은 은 이 이 이 \n",
            "\n",
            "Total Epoch : 24\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.3006 - accuracy: 0.7882 - val_loss: 1.5820 - val_accuracy: 0.7527\n",
            "네 은 은 이 이 이 \n",
            "\n",
            "Total Epoch : 25\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.2941 - accuracy: 0.7891 - val_loss: 1.5860 - val_accuracy: 0.7532\n",
            "네 은 은 이 \n",
            "\n",
            "Total Epoch : 26\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.2852 - accuracy: 0.7897 - val_loss: 1.6095 - val_accuracy: 0.7455\n",
            "네 , 은 이 이 이 \n",
            "\n",
            "Total Epoch : 27\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.2761 - accuracy: 0.7907 - val_loss: 1.6541 - val_accuracy: 0.7435\n",
            "네 은 은 이 이 이 \n",
            "\n",
            "Total Epoch : 28\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.2674 - accuracy: 0.7913 - val_loss: 1.6662 - val_accuracy: 0.7371\n",
            "네 , 은 이 이 이 이 \n",
            "\n",
            "Total Epoch : 29\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.2580 - accuracy: 0.7919 - val_loss: 1.6344 - val_accuracy: 0.7458\n",
            "네 은 은 이 이 이 \n",
            "\n",
            "Total Epoch : 30\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.2506 - accuracy: 0.7927 - val_loss: 1.6572 - val_accuracy: 0.7446\n",
            "네 , 은 이 이 이 \n",
            "\n",
            "Total Epoch : 31\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.2416 - accuracy: 0.7938 - val_loss: 1.6303 - val_accuracy: 0.7501\n",
            "네 이 이 이 이 이 \n",
            "\n",
            "Total Epoch : 32\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.2337 - accuracy: 0.7939 - val_loss: 1.6391 - val_accuracy: 0.7481\n",
            "네 , 은 이 이 이 \n",
            "\n",
            "Total Epoch : 33\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.2246 - accuracy: 0.7953 - val_loss: 1.6935 - val_accuracy: 0.7430\n",
            "네 은 은 이 이 이 이 \n",
            "\n",
            "Total Epoch : 34\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.2159 - accuracy: 0.7959 - val_loss: 1.7066 - val_accuracy: 0.7414\n",
            "네 은 은 이 이 이 \n",
            "\n",
            "Total Epoch : 35\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.2099 - accuracy: 0.7968 - val_loss: 1.6547 - val_accuracy: 0.7504\n",
            "네 은 은 이 이 이 \n",
            "\n",
            "Total Epoch : 36\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1999 - accuracy: 0.7980 - val_loss: 1.7072 - val_accuracy: 0.7378\n",
            "네 , 은 이 이 이 \n",
            "\n",
            "Total Epoch : 37\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1935 - accuracy: 0.7986 - val_loss: 1.7950 - val_accuracy: 0.7249\n",
            "네 , 은 이 이 이 이 예요 \n",
            "\n",
            "Total Epoch : 38\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1856 - accuracy: 0.7993 - val_loss: 1.6953 - val_accuracy: 0.7456\n",
            "네 은 은 다 이 \n",
            "\n",
            "Total Epoch : 39\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1799 - accuracy: 0.8000 - val_loss: 1.7013 - val_accuracy: 0.7458\n",
            "네 , 은 이 이 이 \n",
            "\n",
            "Total Epoch : 40\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1732 - accuracy: 0.8009 - val_loss: 1.7673 - val_accuracy: 0.7329\n",
            "네 , 은 이 이 이 예요 \n",
            "\n",
            "Total Epoch : 41\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1646 - accuracy: 0.8017 - val_loss: 1.7400 - val_accuracy: 0.7425\n",
            "네 , 은 이 이 이 \n",
            "\n",
            "Total Epoch : 42\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1590 - accuracy: 0.8027 - val_loss: 1.7748 - val_accuracy: 0.7438\n",
            "네 , 은 이 이 있어요 \n",
            "\n",
            "Total Epoch : 43\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1528 - accuracy: 0.8034 - val_loss: 1.7837 - val_accuracy: 0.7373\n",
            "네 , 은 다 이 이 있어요 \n",
            "\n",
            "Total Epoch : 44\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1471 - accuracy: 0.8040 - val_loss: 1.7773 - val_accuracy: 0.7426\n",
            "네 는 은 그 \n",
            "\n",
            "Total Epoch : 45\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1400 - accuracy: 0.8049 - val_loss: 1.7917 - val_accuracy: 0.7387\n",
            "네 , 은 이 이 이 \n",
            "\n",
            "Total Epoch : 46\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1329 - accuracy: 0.8057 - val_loss: 1.7700 - val_accuracy: 0.7411\n",
            "네 , 은 이 있어요 \n",
            "\n",
            "Total Epoch : 47\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1256 - accuracy: 0.8064 - val_loss: 1.8725 - val_accuracy: 0.7323\n",
            "네 , 은 다 이 이 \n",
            "\n",
            "Total Epoch : 48\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1231 - accuracy: 0.8069 - val_loss: 1.7895 - val_accuracy: 0.7425\n",
            "네 , 은 다 거 이 \n",
            "\n",
            "Total Epoch : 49\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1152 - accuracy: 0.8081 - val_loss: 1.8433 - val_accuracy: 0.7356\n",
            "네 , 은 이 이 이 있어요 \n",
            "\n",
            "Total Epoch : 50\n",
            "206/206 [==============================] - 4s 21ms/step - loss: 1.1088 - accuracy: 0.8087 - val_loss: 1.8526 - val_accuracy: 0.7350\n",
            "네 , 은 그 가 이 이 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1DdJ7dBGvBR"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E66RpbXydzy"
      },
      "source": [
        "# 예측을 위한 입력 생성\n",
        "def make_predict_input(sentence):\n",
        "\n",
        "    sentences = []\n",
        "    sentences.append(sentence)\n",
        "    sentences = pos_tag(sentences)\n",
        "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
        "    \n",
        "    return input_seq"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUV-fKE0ydz0"
      },
      "source": [
        "# 텍스트 생성\n",
        "def generate_text(input_seq):\n",
        "    \n",
        "    # 입력을 인코더에 넣어 마지막 상태 구함\n",
        "    states = encoder_model.predict(input_seq)\n",
        "\n",
        "    # 목표 시퀀스 초기화\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    \n",
        "    # 목표 시퀀스의 첫 번째에 <START> 태그 추가\n",
        "    target_seq[0, 0] = STA_INDEX\n",
        "    \n",
        "    # 인덱스 초기화\n",
        "    indexs = []\n",
        "    \n",
        "    # 디코더 타임 스텝 반복\n",
        "    while 1:\n",
        "        # 디코더로 현재 타임 스텝 출력 구함\n",
        "        # 처음에는 인코더 상태를, 다음부터 이전 디코더 상태로 초기화\n",
        "        decoder_outputs, state_h, state_c = decoder_model.predict(\n",
        "                                                [target_seq] + states)\n",
        "\n",
        "        # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
        "        index = np.argmax(decoder_outputs[0, 0, :])\n",
        "        indexs.append(index)\n",
        "        \n",
        "        # 종료 검사\n",
        "        if index == END_INDEX or len(indexs) >= max_sequences:\n",
        "            break\n",
        "\n",
        "        # 목표 시퀀스를 바로 이전의 출력으로 설정\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = index\n",
        "        \n",
        "        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n",
        "        states = [state_h, state_c]\n",
        "\n",
        "    # 인덱스를 문장으로 변환\n",
        "    sentence = convert_index_to_text(indexs, index_to_word)\n",
        "        \n",
        "    return sentence"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nfzs40Jydz9",
        "outputId": "90a5d814-73ca-4b8d-d61f-27014ee0e740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "input_seq = make_predict_input('교환 가능한가요?')\n",
        "input_seq\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2168,   82, 4581,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfAuRhDwydz_",
        "outputId": "9b9e9a49-3203-4679-bf72-44462b67ca13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 예측 모델로 텍스트 생성\n",
        "sentence = generate_text(input_seq)\n",
        "sentence\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'네 카드 개월 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3YqOZ-MEOVW",
        "outputId": "74dd3ad7-b5c6-4f34-b507-b83c40cc6079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# for train data predict\n",
        "for seq_index in range(0,100):\n",
        "\n",
        "  print(\"고객 : \",question[seq_index])\n",
        "  print(\"정답점원 :\",answer[seq_index])\n",
        "  print(\"AI점원 :\",generate_text(make_predict_input(question[seq_index])))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "고객 :  신발 은 여기 있는 게 다예 요 ?\n",
            "정답점원 : 네 성인 이나 아동 다 있어요 발 사이즈 몇 신으세요 ?\n",
            "AI점원 : 네 이 는 는 는 는 는 는 예요 이에요 \n",
            "\n",
            "\n",
            "고객 :  230 이요\n",
            "정답점원 : 편하게 신 을 수 있는 거 찾으세요 ?\n",
            "AI점원 : 이 \n",
            "\n",
            "\n",
            "고객 :  네 봄 이니까 편하게 신 을 수 있는 거\n",
            "정답점원 : 이런 건 어떠세요 ? 이런 거도 신발 무척 편하거든요\n",
            "AI점원 : 이 이 이 이 이 이 어떠세요 ? \n",
            "\n",
            "\n",
            "고객 :  굽 좀 높은 거 없나요 ?\n",
            "정답점원 : 봄 상품 은 아직 어른 제품 이 많이 안 나왔습니다\n",
            "AI점원 : 이 이 은 은 은 은 은 은 은 \n",
            "\n",
            "\n",
            "고객 :  언제 들어와요 ?\n",
            "정답점원 : 이번 주 지나면 들어올 거 예요\n",
            "AI점원 : 가죽 거 는 는 해 해 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 가죽 이에요 ?\n",
            "정답점원 : 가죽 아니고 쎄 무예 요\n",
            "AI점원 : 가죽 가죽 가죽 가죽 \n",
            "\n",
            "\n",
            "고객 :  가죽 은 얼마 예요 ?\n",
            "정답점원 : 2만 9천 원 입니다\n",
            "AI점원 : 이 는 는 이에요 이에요 \n",
            "\n",
            "\n",
            "고객 :  털 달린 거 저 거 는 사이즈 있어요 ?\n",
            "정답점원 : 230 이 없어요 이 거 한 번 신어 보세요\n",
            "AI점원 : 사이즈 사이즈 사이즈 사이즈 사이즈 \n",
            "\n",
            "\n",
            "고객 :  좀 크네 또 안 들어와요 ?\n",
            "정답점원 : 네 이건 다 끝났어요\n",
            "AI점원 : 네 이 거 없어요 \n",
            "\n",
            "\n",
            "고객 :  가방 매는 거 보고 있어요\n",
            "정답점원 : 여기 있어요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  가격 이 얼마 예요 ?\n",
            "정답점원 : 이 종류 는 2만 원 이고 이 종류 는 3만 8천 원 이에요\n",
            "AI점원 : 이 원 원 원 원 원 <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> \n",
            "\n",
            "\n",
            "고객 :  가죽 으로 된 거 는 없어요 ?\n",
            "정답점원 : 가죽 은 없고 레자 만 있어요\n",
            "AI점원 : 이 거 은 <PADDING> 거 \n",
            "\n",
            "\n",
            "고객 :  레자 는 얼마 예요 ?\n",
            "정답점원 : 5만 5천 원요\n",
            "AI점원 : 이 는 는 원 원 원 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 천이 죠 ?\n",
            "정답점원 : 네 맞아요\n",
            "AI점원 : 네 가죽 \n",
            "\n",
            "\n",
            "고객 :  이건 얼마 예요 ?\n",
            "정답점원 : 그것 도 5만 5천 원요\n",
            "AI점원 : 이 는 는 이에요 \n",
            "\n",
            "\n",
            "고객 :  이 거 끈 은 따로 없어요 ?\n",
            "정답점원 : 안 에 있어요\n",
            "AI점원 : 이 \n",
            "\n",
            "\n",
            "고객 :  내일 은 문 열어요 ?\n",
            "정답점원 : 휴무 입니다\n",
            "AI점원 : 그렇죠 요 \n",
            "\n",
            "\n",
            "고객 :  며칠 까지 휴무 예요 ?\n",
            "정답점원 : 설 까지 쉬 고 다음 날 열 거 같아요\n",
            "AI점원 : 그럼 는 는 는 는 는 거 거 돼요 \n",
            "\n",
            "\n",
            "고객 :  여기 마스크 는 얼마 예요 ?\n",
            "정답점원 : 5천 원요\n",
            "AI점원 : 입니다 입니다 \n",
            "\n",
            "\n",
            "고객 :  이 거 나무 예요 ? 다 돌 인가요 ?\n",
            "정답점원 : 나무 도 있고 도자기 도 있어요\n",
            "AI점원 : 가죽 가죽 가죽 거 \n",
            "\n",
            "\n",
            "고객 :  이런 건 세트 로 팔아요 ?\n",
            "정답점원 : 네 세트 로만 팔아요\n",
            "AI점원 : 이 거 은 없어요 \n",
            "\n",
            "\n",
            "고객 :  이건 뭐 예요 ?\n",
            "정답점원 : 마블 이라고 종이 를 말아가지고 하는 거 예요\n",
            "AI점원 : 가죽 가죽 가죽 \n",
            "\n",
            "\n",
            "고객 :  제일 큰 거 는 얼마 인데 요 ?\n",
            "정답점원 : 세트 에 7만 원 이요\n",
            "AI점원 : 이 거 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  스카프 좀 보려구요\n",
            "정답점원 : 네 천천히 보세요\n",
            "AI점원 : 이 그럼 이 이 에 에 에 은 은 \n",
            "\n",
            "\n",
            "고객 :  실크 스카프 도 봄 에 하나요 ?\n",
            "정답점원 : 실크 봄 가을 에 하죠\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 뭐 예요 ?\n",
            "정답점원 : 토시 예요\n",
            "AI점원 : 가죽 가죽 이에요 \n",
            "\n",
            "\n",
            "고객 :  여기 가격 은 그대로 파시 는 거 예요 ?\n",
            "정답점원 : 네 핸드 메이드 로 해가지고 그 가격 으로 팔아요\n",
            "AI점원 : 이 는 는 는 는 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  착용 해볼 수 있어요 ?\n",
            "정답점원 : 네 가능하세요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 요즘 들어온 거 예요 ?\n",
            "정답점원 : 네 어제 들어왔어요\n",
            "AI점원 : 이 그거 없어요 없어요 \n",
            "\n",
            "\n",
            "고객 :  세탁 은 물 세탁 되죠 ?\n",
            "정답점원 : 끝 부분 이 가죽 이라서 조심해야 해 요\n",
            "AI점원 : 네 사이즈 \n",
            "\n",
            "\n",
            "고객 :  지금 여기 있는 게 다예 요 ?\n",
            "정답점원 : 네 다예 요\n",
            "AI점원 : 이 , 이 아뇨 는 예요 예요 \n",
            "\n",
            "\n",
            "고객 :  몇 시 에 문 닫아요 ?\n",
            "정답점원 : 8시 까지 합니다\n",
            "AI점원 : 그렇다면 11시 \n",
            "\n",
            "\n",
            "고객 :  일요일 도 하세요 ?\n",
            "정답점원 : 아뇨 닫아요\n",
            "AI점원 : 네 요 \n",
            "\n",
            "\n",
            "고객 :  스카프 있어요 ?\n",
            "정답점원 : 네 여기는 2 단 이 거 는 3 단 제품 있어요\n",
            "AI점원 : 이 이 는 는 는 는 에 에 에 있어요 \n",
            "\n",
            "\n",
            "고객 :  이런 건 세탁 을 어떻게 해 요 ?\n",
            "정답점원 : 울 샴푸 를 물 에 몇 방울 떨어뜨려서 조물조물 하면 됩니다\n",
            "AI점원 : 가죽 가죽 가죽 가죽 \n",
            "\n",
            "\n",
            "고객 :  원단 은 뭐 예요 ?\n",
            "정답점원 : 원단 이 구김 안 가고 참 괜찮아요\n",
            "AI점원 : 네 거 은 만 이 \n",
            "\n",
            "\n",
            "고객 :  얼마 인데 요 ?\n",
            "정답점원 : 2만 원 입니다\n",
            "AI점원 : 이 는 는 원 원 원 <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> \n",
            "\n",
            "\n",
            "고객 :  브로치 같은 건 어디 있나요 ?\n",
            "정답점원 : 여기 있는 거 밖에 없어요\n",
            "AI점원 : 이 이 에 에 \n",
            "\n",
            "\n",
            "고객 :  이런 거도 2만 원 이예 요 ?\n",
            "정답점원 : 헤르메스 인데 이 것 도 괜찮아요\n",
            "AI점원 : 이 거 은 요 요 \n",
            "\n",
            "\n",
            "고객 :  명품 이랑 똑같이 한 거 예요 ?\n",
            "정답점원 : 네 원단 만 다르고 디자인 을 똑같이 만든 거 예요\n",
            "AI점원 : 이 , 는 는 는 는 는 해 돼요 \n",
            "\n",
            "\n",
            "고객 :  온누리 상품권 도 되죠 ?\n",
            "정답점원 : 네 됩니다\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  브로치 하고 머리핀 하고 보려고요\n",
            "정답점원 : 머리핀 은 밖에 있고 브로치 는 안 에 있습니다\n",
            "AI점원 : 이 는 는 는 는 는 에 에 에 에 \n",
            "\n",
            "\n",
            "고객 :  도자기 같은 거 말고 구슬 이나 진주 같은 거 는 없어요 ?\n",
            "정답점원 : 지금 옷 에 가볍게 하려면 진주 도 예쁘지만 이 것 도 깔끔합니다 보석 은 싫으세요 ?\n",
            "AI점원 : 이 감사합니다 에 에 것 \n",
            "\n",
            "\n",
            "고객 :  그건 흥미 없고 안 에 하면 안 떨어져요 ?\n",
            "정답점원 : 안 떨어져요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  얼마 예요 ?\n",
            "정답점원 : 핀 꼽는 거 는 좀 싼 거고 이 거 는 3만 원대 예요\n",
            "AI점원 : 이 는 는 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  이 우산 은 얼마 인데 요 ?\n",
            "정답점원 : 4만 2천 원 이요\n",
            "AI점원 : 2만 는 는 이에요 \n",
            "\n",
            "\n",
            "고객 :  무겁지 않아요 ?\n",
            "정답점원 : 좋은 재료 를 쓰기 때문 에 무겁지 않아요\n",
            "AI점원 : 그럼 는 는 는 는 에 에 해 \n",
            "\n",
            "\n",
            "고객 :  이렇게 다는 거 맞아요 ?\n",
            "정답점원 : 그렇게 달 면 안되고 이렇게 달아야 해 요\n",
            "AI점원 : 네 아뇨 는 해 이 돼요 \n",
            "\n",
            "\n",
            "고객 :  자석 은 다 3만 원 ?\n",
            "정답점원 : 3만 원 짜 리도 있고 2만 원 짜 리도 있어요\n",
            "AI점원 : 이 는 는 는 원 원 원 원 \n",
            "\n",
            "\n",
            "고객 :  머리핀 종류 도 한 번 보여주세요 곱창 은 요새 안 나와요 ?\n",
            "정답점원 : 곱창 밴드 는 안 나와요 촌스러워서 유행 다 지났어요\n",
            "AI점원 : 네 가방 가방 가방 가방 가방 \n",
            "\n",
            "\n",
            "고객 :  브로치 종류 도 있어요 ?\n",
            "정답점원 : 아뇨 없어요\n",
            "AI점원 : 이 거 은 없어요 없어요 있어요 \n",
            "\n",
            "\n",
            "고객 :  스카프 도 없어요 ?\n",
            "정답점원 : 스카프 는 이 쪽 에 종류 가 있어요\n",
            "AI점원 : 이 이 에 에 에 있어요 \n",
            "\n",
            "\n",
            "고객 :  이런 거 실크 입 니까 ?\n",
            "정답점원 : 실크 아니예요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이런 거 는 뭐라 그래요 ?\n",
            "정답점원 : 실캣 으로 만든 거 죠\n",
            "AI점원 : 이 거 는 는 거 \n",
            "\n",
            "\n",
            "고객 :  이런 거 는 얼마 예요 ?\n",
            "정답점원 : 대충 2만 원 내외 요\n",
            "AI점원 : 이 거 원 이에요 <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> \n",
            "\n",
            "\n",
            "고객 :  이런 거 는 물 세탁 됩니까 ?\n",
            "정답점원 : 물 세탁 조금 해도 상관 은 없으세요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  근데 이 거 제 가 한 거 아닌데 약간 올이 나갔네요\n",
            "정답점원 : 이 거 원하시면 주문 가능하세요\n",
            "AI점원 : 이 거 거 는 는 는 없어요 \n",
            "\n",
            "\n",
            "고객 :  또 언제 들어와요 ?\n",
            "정답점원 : 스카프 는 많이 들어오지 않아서 주문 하시는 게 좋아요\n",
            "AI점원 : 그럼 는 는 는 는 에 거 해 돼요 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 목걸이 링 이에요 ?\n",
            "정답점원 : 아뇨 반지 예요\n",
            "AI점원 : 네 가죽 가죽 \n",
            "\n",
            "\n",
            "고객 :  금 이에요 ?\n",
            "정답점원 : 액세서리 예요 금 아니예요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이 거 한 번 해봐도 돼요 ?\n",
            "정답점원 : 네 가능합니다\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  신 상품 더 들어오죠 ?\n",
            "정답점원 : 네 들어올 거 예요\n",
            "AI점원 : 네 , , , 나갑니다 . . . . . . . . . . 이 . 면 에 면 \n",
            "\n",
            "\n",
            "고객 :  이 모양 으로 목걸이 팔찌 세트 구입 할까 하는데\n",
            "정답점원 : 똑같은 모양 은 주문 을 넣어야 할 거 같은데요\n",
            "AI점원 : 그럼 는 는 는 는 는 에 에 거 \n",
            "\n",
            "\n",
            "고객 :  가격 은 어떻게 돼요 ?\n",
            "정답점원 : 모양 을 보고 견적 을 내 봐야 해 요\n",
            "AI점원 : 가죽 원 \n",
            "\n",
            "\n",
            "고객 :  이 금 팔찌 는 무게 가 얼마 정도 인지 확인 할 수 있어요 ?\n",
            "정답점원 : 세 돈 이 조금 넘네요\n",
            "AI점원 : 가죽 가죽 거 는 \n",
            "\n",
            "\n",
            "고객 :  견본 인 팔찌 가 있어요 ?\n",
            "정답점원 : 여기 있습니다\n",
            "AI점원 : 이 있습니다 이 \n",
            "\n",
            "\n",
            "고객 :  여기는 금 매입 도 해 요 ?\n",
            "정답점원 : 네 해 요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  이 거 판다 고 얼마 정도 받을 수 있어요 ?\n",
            "정답점원 : 대충 39만 3천 원 정도 나오네요\n",
            "AI점원 : 가죽 원 원 원 원 원 원 \n",
            "\n",
            "\n",
            "고객 :  팔찌 두 돈 짜 리도 한 번 보여주시고 다른 거도 보여주세요\n",
            "정답점원 : 유행 하는 로 즈 골드 하셔도 되고 골드 하셔도 돼요\n",
            "AI점원 : 이 는 는 는 는 는 는 는 거 거 \n",
            "\n",
            "\n",
            "고객 :  가격 이 구입 하려면 얼마 인데 요 ?\n",
            "정답점원 : 현금 가격 기준 으로 62만 9천 원 이요\n",
            "AI점원 : 이 는 는 원 원 원 원 이요 원 원 \n",
            "\n",
            "\n",
            "고객 :  이 거 18 케이 예요 ?\n",
            "정답점원 : 네 18 케이 예요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  시내 에 있는 금 도매 상 하고 여기 랑 가격 차이 가 많이 나 요 ?\n",
            "정답점원 : 그 쪽 은 유지비 가 많이 나가니까 아무래도 여기 가 더 싸죠\n",
            "AI점원 : 이 이 는 는 는 는 는 는 는 는 는 거 \n",
            "\n",
            "\n",
            "고객 :  액세서리 세 일 제품 이 있나요 ?\n",
            "정답점원 : 악세서리 어떤 거 찾으세요 ?\n",
            "AI점원 : 이 , 에 에 있어요 \n",
            "\n",
            "\n",
            "고객 :  스카프 같은 거\n",
            "정답점원 : 이 거 괜찮아요\n",
            "AI점원 : 이 는 는 는 는 는 에 해 \n",
            "\n",
            "\n",
            "고객 :  이건 소재 가 뭐 예요 ?\n",
            "정답점원 : 폴리에스테르 라고 적혀 있네요\n",
            "AI점원 : 가죽 가죽 가죽 \n",
            "\n",
            "\n",
            "고객 :  색상 은 이 거 하나 뿐 이고 ?\n",
            "정답점원 : 네 다 빠지고 이 거 하나 예요\n",
            "AI점원 : 이 , , , , , 아뇨 \n",
            "\n",
            "\n",
            "고객 :  빨 면 좀 그렇지 않을까 ?\n",
            "정답점원 : 조심해야 하는데 면 이 아니니까 집 에서 손 드라이 해도 돼요\n",
            "AI점원 : 그럼 는 는 는 는 는 는 거 거 거 돼요 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 가격 이 얼마 예요 ?\n",
            "정답점원 : 16000원 인데 몇 천 원 빼 드릴게요\n",
            "AI점원 : 이 거 원 원 <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> \n",
            "\n",
            "\n",
            "고객 :  이건 얼마 예요 ?\n",
            "정답점원 : 13000원 입니다\n",
            "AI점원 : 이 는 는 이에요 \n",
            "\n",
            "\n",
            "고객 :  이 핑크색 모자 는 애기 들 꺼예요 ?\n",
            "정답점원 : 애기 용 입니다\n",
            "AI점원 : 그거 요 요 \n",
            "\n",
            "\n",
            "고객 :  어른 들 꺼는 없어요 ?\n",
            "정답점원 : 다 빠졌어요\n",
            "AI점원 : 이 은 은 <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> \n",
            "\n",
            "\n",
            "고객 :  팔찌 제품 따로 있나요 ?\n",
            "정답점원 : 고객 님 이 하실 거 예요 ?\n",
            "AI점원 : 이 \n",
            "\n",
            "\n",
            "고객 :  네 지금 세 일 기간 이에요 ?\n",
            "정답점원 : 네 당분간 은 할 거 같아요\n",
            "AI점원 : 네 은 은 은 이 이 \n",
            "\n",
            "\n",
            "고객 :  한 몇 프로 하는데요 ?\n",
            "정답점원 : 정가 에서 한 40 프로 합니다\n",
            "AI점원 : 가죽 가죽 이에요 \n",
            "\n",
            "\n",
            "고객 :  이 거 는 가격 대가 얼마 예요 ?\n",
            "정답점원 : 이 거 샘플 이 14 케이 인데 뭘 로 봐 드릴 까요 ?\n",
            "AI점원 : 이 는 는 원 원 <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> \n",
            "\n",
            "\n",
            "고객 :  18 케이 로\n",
            "정답점원 : 18 케이 로 하시면 49만 원 이요\n",
            "AI점원 : 사이즈 사이즈 사이즈 물론 \n",
            "\n",
            "\n",
            "고객 :  팔찌 좀 핫 한 제품 뭐 가 있어요 ?\n",
            "정답점원 : 깔끔하게 이런 거 잘나가요\n",
            "AI점원 : 이 거 요 ? \n",
            "\n",
            "\n",
            "고객 :  18 케이 예요 ?\n",
            "정답점원 : 네 맞아요\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  돈 수로 따지면 몇 돈 이에요 ?\n",
            "정답점원 : 두 돈반 조금 안 돼요\n",
            "AI점원 : 가죽 이 가죽 가죽 가죽 \n",
            "\n",
            "\n",
            "고객 :  얼마 예요 ?\n",
            "정답점원 : 48만 원 정도 요\n",
            "AI점원 : 이 는 는 원 이에요 \n",
            "\n",
            "\n",
            "고객 :  굵은 게 이 거 다예 요 ?\n",
            "정답점원 : 5 돈 6 돈 짜 리도 있어요 굵은 거 찾으시면 이런 건 어떠세요 ?\n",
            "AI점원 : 이 는 는 는 는 는 는 는 는 거 거 거 \n",
            "\n",
            "\n",
            "고객 :  너무 사치스러운데 핸드폰 케이스 파는 거 예요 ?\n",
            "정답점원 : 네 맞습니다\n",
            "AI점원 : 네 \n",
            "\n",
            "\n",
            "고객 :  여기는 가격 이 어떤 게 있어요 ?\n",
            "정답점원 : 기 종이 어떻게 되죠 ?\n",
            "AI점원 : 카드 이 는 는 원 원 원 \n",
            "\n",
            "\n",
            "고객 :  엘지 인데\n",
            "정답점원 : 만 오천 원대 부터 시작 해서 이만 오천 원 까지 있습니다\n",
            "AI점원 : 이 는 는 원 원 원 원 \n",
            "\n",
            "\n",
            "고객 :  그건 얼마 예요 ?\n",
            "정답점원 : 3만 원 정도 해 요\n",
            "AI점원 : 이 는 는 원 이에요 <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> <PADDING> \n",
            "\n",
            "\n",
            "고객 :  색상 은 이 게 전부 예요 ?\n",
            "정답점원 : 레드 색 인데 핑크 도 있고 보랏빛 퍼플 색도 있고 색상 종류 가 다양해요\n",
            "AI점원 : 네 , 이 \n",
            "\n",
            "\n",
            "고객 :  엘지 지 식스 케이스 로 좀 보여주세요\n",
            "정답점원 : 그 기종은 여기 있어요\n",
            "AI점원 : 네 , , , 물론 . . . . . . . . . . . . . . . 이 . . . 까요 . . . . . \n",
            "\n",
            "\n",
            "고객 :  이건 얼마 예요 ?\n",
            "정답점원 : 3만 5천 원 입니다\n",
            "AI점원 : 이 는 는 이에요 \n",
            "\n",
            "\n",
            "고객 :  현금 으로 사면 할인 이 된다거나 그런 게 있나요 ?\n",
            "정답점원 : 현금 으로 하면 좀 디씨 해드려요\n",
            "AI점원 : 네 , 이 , 이 돼요 \n",
            "\n",
            "\n",
            "고객 :  반지 이 거 세척 가능해요 ?\n",
            "정답점원 : 월요일 에 해야 해 요\n",
            "AI점원 : 이 거 거 없어요 없어요 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOBDpAVqFOW_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}