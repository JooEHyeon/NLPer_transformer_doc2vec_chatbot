{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Seq2Seq_Chatbot_의류_Hannanum_Transformer.ipynb","provenance":[{"file_id":"https://github.com/ideablast/NLPer_chatbot/blob/kdg/Seq2Seq_Chatbot_%EC%9D%98%EB%A5%98_Transformer.ipynb","timestamp":1604390455117}],"collapsed_sections":["lsf4tJl61Xi9"],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RsiilWsMNHHL","executionInfo":{"status":"ok","timestamp":1604399966647,"user_tz":-540,"elapsed":7566,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"d6545c2b-6feb-4237-a4cc-b97b2e379ba1","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install konlpy"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Collecting tweepy>=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n","Collecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/96/1030895dea70855a2e1078e3fe0d6a63dcb7c212309e07dc9ee39d33af54/JPype1-1.1.2-cp36-cp36m-manylinux2010_x86_64.whl (450kB)\n","\u001b[K     |████████████████████████████████| 460kB 54.7MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 11.9MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: tweepy, JPype1, colorama, beautifulsoup4, konlpy\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.1.2 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9UA-8fQ2EDnp"},"source":["## Import"]},{"cell_type":"code","metadata":{"id":"1DAFy5c7ydzC","executionInfo":{"status":"ok","timestamp":1604399971156,"user_tz":-540,"elapsed":3245,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["from keras import models\n","from keras import layers\n","from keras import optimizers, losses, metrics\n","from keras import preprocessing\n","\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import re\n","\n","from konlpy.tag import Okt, Hannanum, Kkma, Komoran"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ioT3c4eLEKon"},"source":["## Hyperparameter"]},{"cell_type":"code","metadata":{"id":"P9YUdE1OydzG","executionInfo":{"status":"ok","timestamp":1604399971538,"user_tz":-540,"elapsed":608,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["# 태그 단어\n","PAD = \"<PADDING>\"   # 패딩\n","STA = \"<START>\"     # 시작\n","END = \"<END>\"       # 끝\n","OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n","\n","# 태그 인덱스\n","PAD_INDEX = 0\n","STA_INDEX = 1\n","END_INDEX = 2\n","OOV_INDEX = 3\n","\n","# 데이터 타입\n","ENCODER_INPUT  = 0\n","DECODER_INPUT  = 1\n","DECODER_TARGET = 2\n","\n","# Hyper-parameters\n","NUM_LAYERS = 2\n","D_MODEL = 256 ##word embedding dim\n","NUM_HEADS = 8 ## D_Model % NUM_HEADS == 0이 되야하므로...\n","UNITS = 512\n","DROPOUT = 0.1\n","EPOCHS = 50\n","# for data pipelining\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 1000\n","\n","VOCAB_SIZE = 0 # 후에 len(words) 로 바뀜.\n","\n","# 한 문장에서 단어 시퀀스의 최대 개수\n","max_sequences = 30\n","\n","# 정규 표현식 필터\n","RE_FILTER = re.compile(\"[\\\"':;~()]\")"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HhVVnW_uEWT1"},"source":["## Data Load & Preprocessing"]},{"cell_type":"code","metadata":{"id":"80IauV0FpUv2","executionInfo":{"status":"ok","timestamp":1604399995658,"user_tz":-540,"elapsed":20918,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"b167ccf9-6ce9-4f39-b3a5-c45a6e0f3132","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NEHDnPXNzZlM","executionInfo":{"status":"ok","timestamp":1604399997562,"user_tz":-540,"elapsed":7501,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"5b832ffb-629b-4b0c-f292-5e09636693a3","colab":{"base_uri":"https://localhost:8080/"}},"source":["wear_data = pd.read_csv(\"/content/drive/My Drive/자연어처리,추천/NLPer/chatbot_pra/csv_file/wear.csv\")\n","print(wear_data.shape)\n","customer = wear_data[wear_data.SPEAKER == \"고객\"].SENTENCE\n","store = wear_data[wear_data.SPEAKER == \"점원\"].SENTENCE\n","print(customer.shape, store.shape) # 질문의 개수와 답의 개수가 일치하지 않는다."],"execution_count":5,"outputs":[{"output_type":"stream","text":["(15826, 20)\n","(8381,) (7445,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FLNSiqcHM4WY","executionInfo":{"status":"ok","timestamp":1604400002697,"user_tz":-540,"elapsed":9686,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"b4084f2f-38fd-4294-befe-5ca29f9d09c2","colab":{"base_uri":"https://localhost:8080/"}},"source":["prev = \"고객\"\n","store_arr = []\n","customer_arr = []\n","store_stc = \"\"\n","customer_stc = \"\"\n","\n","for i in range(wear_data.shape[0]):\n","    if (prev == wear_data.iloc[i].SPEAKER):\n","        if prev == \"점원\":\n","             store_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n","        else : \n","             customer_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n","            \n","    elif prev == \"점원\":\n","        store_arr.append(store_stc)\n","        customer_stc = wear_data.iloc[i].SENTENCE\n","        prev = \"고객\"\n","    else :\n","        customer_arr.append(customer_stc)\n","        store_stc = wear_data.iloc[i].SENTENCE\n","        prev = \"점원\"\n","\n","print(len(store_arr))\n","print(len(customer_arr))\n","print(store_arr[-1])\n","print(customer_arr[-1]) # 자료 상에서 이후에는 계속 고객의 물음만 계속된다. 코드 레벨에서 이 부분은 빼게 구현했다. (stc는 만들어지지만 arr에 append 안하게 된다.)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["7301\n","7301\n","요즘 파스텔 톤이 유행이에요\n","요즘 유행하는 색깔이 뭐예요?\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WNvig2FMzjXj","executionInfo":{"status":"ok","timestamp":1604400002697,"user_tz":-540,"elapsed":8868,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"68e82479-45fe-41b1-b9f9-5095b6f4fd5e","colab":{"base_uri":"https://localhost:8080/"}},"source":["question = []\n","answer = []\n","\n","for Q in customer_arr:\n","    question.append(Q.replace(\"[^\\w]\", \" \"))\n","\n","for A in store_arr:\n","    answer.append(A.replace(\"[^\\w]\", \" \"))\n","\n","len(question), len(answer)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7301, 7301)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"qbivSckMydzN","executionInfo":{"status":"ok","timestamp":1604400013144,"user_tz":-540,"elapsed":785,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["# 형태소분석 함수\n","def pos_tag(sentences):\n","    \n","    # KoNLPy 형태소분석기 설정\n","    tagger = Hannanum()\n","    \n","    # 문장 품사 변수 초기화\n","    sentences_pos = []\n","    \n","    # 모든 문장 반복\n","    for sentence in sentences:\n","        # [\\\"':;~()] 특수기호 제거\n","        sentence = re.sub(RE_FILTER, \"\", sentence)\n","        \n","        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n","        sentence = \" \".join(tagger.morphs(sentence))\n","        sentences_pos.append(sentence)\n","        \n","    return sentences_pos"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"4seqSNWcydzP","executionInfo":{"status":"ok","timestamp":1604400186694,"user_tz":-540,"elapsed":12066,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"932da78d-2f5b-4990-b134-3021cc65297d","colab":{"base_uri":"https://localhost:8080/"}},"source":["import time\n","start = time.time()\n","# 형태소분석 수행\n","question = pos_tag(question)\n","answer = pos_tag(answer)\n","\n","print(\"time :\", time.time() - start)\n","print()\n","\n","# 형태소분석으로 변환된 챗봇 데이터 출력\n","for i in range(5):\n","    print('Q : ' + question[i])\n","    print('A : ' + answer[i])\n","    print()\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["time : 11.272570371627808\n","\n","Q : 신발 은 여기 있 늘 ㄴ 것 이 다예요 ?\n","A : 네 성 이 ㄴ 이 나 아동 다 있 어 요 발 사이즈 몇 신으세요 ?\n","\n","Q : 230이요\n","A : 편하 어 것 이 신 을 수 있 늘 ㄴ 것 찾으세요 ?\n","\n","Q : 네 보 ㅁ 이 니까 편하 어 것 이 신 을 수 있 늘 ㄴ 것\n","A : 이런 것 은 어떠세요 ? 이런 것 도 신발 무척 편하 어 거든요\n","\n","Q : 굽 좀 높 은 것 없 나 요 ?\n","A : 보 ㅁ 상품 은 아직 어른 제품 이 많 이 안나왔습니 이 다\n","\n","Q : 언제 들 ㄹ 어 오 아 요 ?\n","A : 이번주 지나 아 면 들 ㄹ 어 오 ㄹ 것 이 예요\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Yrnct_nzydzR","executionInfo":{"status":"ok","timestamp":1604400186694,"user_tz":-540,"elapsed":6691,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["# 질문과 대답 문장들을 하나로 합침\n","sentences = []\n","sentences.extend(question)\n","sentences.extend(answer)\n","\n","words = []\n","\n","# 단어들의 배열 생성\n","for sentence in sentences:\n","    for word in sentence.split():\n","        words.append(word)\n","\n","# 길이가 0인 단어는 삭제\n","words = [word for word in words if len(word) > 0]\n","\n","# 중복된 단어 삭제\n","words = list(set(words))\n","\n","# 제일 앞에 태그 단어 삽입\n","words[:0] = [PAD, STA, END, OOV]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"fE9ZhJpEy_rT","executionInfo":{"status":"ok","timestamp":1604400186695,"user_tz":-540,"elapsed":6033,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"0d039db1-031f-471d-97ec-98843ed80fea","colab":{"base_uri":"https://localhost:8080/"}},"source":["VOCAB_SIZE = len(words)\n","print(\"손님과 점원의 말에서 사용된 총 단어의 수 :\",len(words))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["손님과 점원의 말에서 사용된 총 단어의 수 : 5051\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AkvyOnSvydzX","executionInfo":{"status":"ok","timestamp":1604400186695,"user_tz":-540,"elapsed":2792,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["# 단어와 인덱스의 딕셔너리 생성\n","word_to_index = {word: index for index, word in enumerate(words)}\n","index_to_word = {index: word for index, word in enumerate(words)}"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"rfoTztrvydzc","executionInfo":{"status":"ok","timestamp":1604400186695,"user_tz":-540,"elapsed":2346,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["# 문장을 인덱스로 변환\n","def convert_text_to_index(sentences, vocabulary, type): \n","    \n","    sentences_index = []\n","    \n","    # 모든 문장에 대해서 반복\n","    for sentence in sentences:\n","        sentence_index = []\n","        \n","        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n","        if type == DECODER_INPUT:\n","            sentence_index.extend([vocabulary[STA]])\n","        \n","        # 문장의 단어들을 띄어쓰기로 분리\n","        for word in sentence.split():\n","            if vocabulary.get(word) is not None:\n","                # 사전에 있는 단어면 해당 인덱스를 추가\n","                sentence_index.extend([vocabulary[word]])\n","            else:\n","                # 사전에 없는 단어면 OOV 인덱스를 추가\n","                sentence_index.extend([vocabulary[OOV]])\n","\n","        # 최대 길이 검사\n","        if type == DECODER_TARGET:\n","            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n","            if len(sentence_index) >= max_sequences:\n","                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n","            else:\n","                sentence_index += [vocabulary[END]]\n","        else:\n","            if len(sentence_index) > max_sequences:\n","                sentence_index = sentence_index[:max_sequences]\n","            \n","        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n","        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n","        \n","        # 문장의 인덱스 배열을 추가\n","        sentences_index.append(sentence_index)\n","\n","    return np.asarray(sentences_index)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"zezFPTvcydzf","executionInfo":{"status":"ok","timestamp":1604400187011,"user_tz":-540,"elapsed":512,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"0cbcc5f2-f2dd-45ea-dc97-3b5a3a8c3c2a","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 인코더 입력 인덱스 변환\n","x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n","\n","# 첫 번째 인코더 입력 출력 (신발 은 여기 있는 게 다예 요)\n","print(question[0])\n","x_encoder[0]\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["신발 은 여기 있 늘 ㄴ 것 이 다예요 ?\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([2770, 1754, 4433, 3076,  461, 3195, 4121, 3853, 3223, 1793,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"fmql1Lf_ydzh","executionInfo":{"status":"ok","timestamp":1604400235648,"user_tz":-540,"elapsed":919,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"4ef19ccf-b259-45c7-ca55-47b732776298","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 디코더 입력 인덱스 변환\n","x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n","\n","# 첫 번째 디코더 입력 출력 (<START> 신발 은 여기 있는 게 다예 요)\n","print(question[0])\n","x_decoder[0]\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["신발 은 여기 있 늘 ㄴ 것 이 다예요 ?\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([   1, 2460, 1237, 3853, 3195, 3853, 3682,  223, 2766, 3076, 1334,\n","       1971,  546,   78,  739, 2545, 1793,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"-qIhDbaLydzk","executionInfo":{"status":"ok","timestamp":1604400236158,"user_tz":-540,"elapsed":1087,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"47e32a18-72b2-47ea-f698-be78e154aded","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 디코더 목표 인덱스 변환\n","y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n","\n","# 첫 번째 디코더 입력 출력 (신발 은 여기 있는 게 다예 요 <END>)\n","print(question[0])\n","y_decoder[0]\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["신발 은 여기 있 늘 ㄴ 것 이 다예요 ?\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([2460, 1237, 3853, 3195, 3853, 3682,  223, 2766, 3076, 1334, 1971,\n","        546,   78,  739, 2545, 1793,    2,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"lsf4tJl61Xi9"},"source":["## Transformer"]},{"cell_type":"code","metadata":{"id":"FsxmXWS41XVd","executionInfo":{"status":"ok","timestamp":1604400245195,"user_tz":-540,"elapsed":6372,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["# decoder inputs use the previous target as input\n","dataset = tf.data.Dataset.from_tensor_slices((\n","    {\n","        'inputs': x_encoder,\n","        'dec_inputs': x_decoder\n","    },\n","    {\n","        'outputs': y_decoder\n","    },\n","))\n","\n","dataset = dataset.cache()\n","dataset = dataset.shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE)\n","dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"cstXcPJo4rKD","executionInfo":{"status":"ok","timestamp":1604400245196,"user_tz":-540,"elapsed":6365,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"08f40b3c-6efc-4b2d-b5ae-528ebe608b89","colab":{"base_uri":"https://localhost:8080/"}},"source":["dataset"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset shapes: ({inputs: (None, 30), dec_inputs: (None, 30)}, {outputs: (None, 30)}), types: ({inputs: tf.int64, dec_inputs: tf.int64}, {outputs: tf.int64})>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"ZxXCQWvw2jwx"},"source":["$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$"]},{"cell_type":"code","metadata":{"id":"eH-k-kk_1_Vu","executionInfo":{"status":"ok","timestamp":1604400245196,"user_tz":-540,"elapsed":6363,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["## scaled dot product Attention\n","def scaled_dot_product_attention(query, key, value, mask):\n","  matmul_qk = tf.matmul(query, key, transpose_b=True) # QK^T\n","\n","  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","  logits = matmul_qk / tf.math.sqrt(depth) #  QK^T / sqrt(d_k)\n","\n","  if mask is not None:\n","    logits += (mask * -1e9) # zero padding token softmax 결과가 0이 나오도록\n","  \n","  attention_weights = tf.nn.softmax(logits, axis = -1) # softmax(QK^T / sqrt(d_k))\n","\n","  output = tf.matmul(attention_weights, value) # softmax(QK^T / sqrt(d_k)) * V\n","\n","  return output"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"7orcKMr13xY8","executionInfo":{"status":"ok","timestamp":1604400245196,"user_tz":-540,"elapsed":6362,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["## multi-head attention\n","## each head need (scaled_dot_product_attention)\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n","    super(MultiHeadAttention, self).__init__(name=name)\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","\n","    assert d_model % self.num_heads == 0 # 128,8\n","\n","    self.depth = d_model // self.num_heads\n","\n","    self.query_dense = tf.keras.layers.Dense(units=d_model)\n","    self.key_dense = tf.keras.layers.Dense(units=d_model)\n","    self.value_dense = tf.keras.layers.Dense(units=d_model)\n","\n","    self.dense = tf.keras.layers.Dense(units=d_model)\n","  \n","  def split_heads(self, inputs, batch_size):\n","    inputs = tf.reshape(inputs, shape=(batch_size,-1,self.num_heads, self.depth))\n","    return tf.transpose(inputs, perm=[0, 2, 1, 3]) ##????\n","  \n","  def call(self, inputs):\n","    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n","    batch_size = tf.shape(query)[0]\n","\n","    #linear\n","    query = self.query_dense(query)\n","    key = self.key_dense(key)\n","    value = self.value_dense(value)\n","\n","    #split heads\n","    query = self.split_heads(query, batch_size)\n","    key = self.split_heads(key, batch_size)\n","    value = self.split_heads(value, batch_size)\n","\n","    #scaled dot-product attention\n","    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","    #concatenation of heads\n","    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","\n","    #final linear\n","    outputs = self.dense(concat_attention)\n","\n","    return outputs"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"vmlW0oi89nEC","executionInfo":{"status":"ok","timestamp":1604400245197,"user_tz":-540,"elapsed":6362,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["def create_padding_mask(x):\n","  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n","  # (batch_size, 1, 1, sequence length)\n","  return mask[:, tf.newaxis, tf.newaxis, :]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"37sh3f8P-JUB","executionInfo":{"status":"ok","timestamp":1604400245197,"user_tz":-540,"elapsed":6356,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"7f640cb2-7bb5-46b7-d3ca-534b02f124af","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[[[0. 0. 1. 0. 1.]]]\n","\n","\n"," [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5W7ld50z3vT2","executionInfo":{"status":"ok","timestamp":1604400245197,"user_tz":-540,"elapsed":6354,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["# it handle mask future tokens in a sequence used decoder. and mask pad tokens\n","def create_look_ahead_mask(x):\n","  seq_len = tf.shape(x)[1]\n","  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","  padding_mask = create_padding_mask(x)\n","  return tf.maximum(look_ahead_mask, padding_mask)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"W25teKwt_F80","executionInfo":{"status":"ok","timestamp":1604400245523,"user_tz":-540,"elapsed":6675,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"076c1002-dab0-4e8e-e324-10ca7a5cee5b","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[[[0. 1. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 1. 0. 1.]\n","   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pLhXEIJgASo3"},"source":["Positional encoding\n","\n","since we don't use any rnn, cnn, positional encoding give model position information of words in sentence.\n","\n","positional encoding vector is added to embedding vector\n","\n","$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n","$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"]},{"cell_type":"code","metadata":{"id":"B7s19-x3_Hpq","executionInfo":{"status":"ok","timestamp":1604400245524,"user_tz":-540,"elapsed":6675,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["class PositionalEncoding(tf.keras.layers.Layer):\n","  def __init__(self, position, d_model):\n","    super(PositionalEncoding, self).__init__()\n","    self.pos_encoding = self.positional_encoding(position, d_model)\n","  \n","  def get_angles(self, position, i, d_model):\n","    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n","    return position * angles #pos/10000^(2i/d_model)\n","\n","  def positional_encoding(self, position, d_model):\n","    angle_rads = self.get_angles(\n","        position = tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n","        i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n","        d_model = d_model)\n","    sines = tf.math.sin(angle_rads[:, 0::2])\n","    cosines = tf.math.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = tf.concat([sines, cosines], axis=-1)\n","    pos_encoding = pos_encoding[tf.newaxis, ...]\n","    return tf.cast(pos_encoding, tf.float32)\n","  \n","  def call(self, inputs):\n","    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oLiumNZZDZGY"},"source":["### Encoder Layer\n","1. Multi-head attention (with padding mask)\n","2. 2 dense layers followed by dropout\n","\n","also has residual connection followd by a layer normalization."]},{"cell_type":"code","metadata":{"id":"oarRWUMLDYnC","executionInfo":{"status":"ok","timestamp":1604400245524,"user_tz":-540,"elapsed":6673,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  attention = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention\")({\n","          'query':inputs,\n","          'key':inputs,\n","          'value':inputs,\n","          'mask':padding_mask\n","      })\n","  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n","  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n","\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N3rO9IcDHGE5"},"source":["### Encoder\n","1. Input Embedding\n","2. Positional Encoding\n","3. `num_layers` encoder layers\n","\n","Embedding + positional encoding : input\n","\n","going encoder layers.\n","\n","output going decoder"]},{"cell_type":"code","metadata":{"id":"uOwoi2_jHvbA","executionInfo":{"status":"ok","timestamp":1604400245524,"user_tz":-540,"elapsed":6672,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["def encoder(vocab_size,\n","            num_layers,\n","            units,\n","            d_model,\n","            num_heads,\n","            dropout,\n","            name=\"encoder\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)#??왜 vocab_size가 들어가지?\n","\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  for i in range(num_layers):\n","    outputs = encoder_layer(\n","        units = units,\n","        d_model = d_model,\n","        num_heads = num_heads,\n","        dropout = dropout,\n","        name = \"encoder_layer_{}\".format(i),\n","    )([outputs, padding_mask])\n","  \n","  return tf.keras.Model(\n","      inputs = [inputs, padding_mask], outputs = outputs, name=name)"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r8XHH5dpJr-G"},"source":["### Decoder Layer\n","1. Masked multi-head attention (with look ahead mask and padding mask)\n","2. Multi-head attention (with padding mask). `value` and `key` is from encoder output. `query` is from Multi-head attention layer output\n","3. 2 dense layers followed by dropout\n","\n","also has residual connection followd by a layer normalization."]},{"cell_type":"code","metadata":{"id":"WtAfKdk-JrxK","executionInfo":{"status":"ok","timestamp":1604400245525,"user_tz":-540,"elapsed":6672,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n","  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n","  padding_mask = tf.keras.Input(shape=(1,1,None), name=\"padding_mask\")\n","\n","  attention1 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_1\")(inputs={\n","          'query' : inputs,\n","          'key' : inputs,\n","          'value' : inputs,\n","          'mask' : look_ahead_mask\n","      })\n","  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n","\n","  attention2 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_2\")(inputs={\n","          'query' : attention1,\n","          'key' : enc_outputs,\n","          'value' : enc_outputs,\n","          'mask' : padding_mask\n","      })\n","  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n","  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n","\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n","\n","  return tf.keras.Model(\n","      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs = outputs,\n","      name = name)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vnBSBcm1NAYv"},"source":["### Decoder\n","1. output Embedding\n","2. Positional Encoding\n","3. `num_layers` decoder layers\n","\n","Embedding + positional encoding : input (target)\n","\n","going decoder layers.\n","\n","output going final linear layer"]},{"cell_type":"code","metadata":{"id":"rnA-8FEAOT4F","executionInfo":{"status":"ok","timestamp":1604400245525,"user_tz":-540,"elapsed":6671,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["def decoder(vocab_size,\n","            num_layers,\n","            units,\n","            d_model,\n","            num_heads,\n","            dropout,\n","            name=\"decoder\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n","  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n","  padding_mask = tf.keras.Input(shape=(1,1,None), name='padding_mask')\n","\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  for i in range(num_layers):\n","    outputs = decoder_layer(\n","        units = units,\n","        d_model = d_model,\n","        num_heads = num_heads,\n","        dropout = dropout,\n","        name = \"decoder_layer_{}\".format(i),\n","    )(inputs = [outputs, enc_outputs, look_ahead_mask, padding_mask])\n","  \n","  return tf.keras.Model(\n","      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs = outputs,\n","      name = name)"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jb-vmtqKQjhf"},"source":["### Transformer\n","1. encoder\n","2. decoder\n","3. final linear layer"]},{"cell_type":"code","metadata":{"id":"PEMfL5SFQqr4","executionInfo":{"status":"ok","timestamp":1604400245525,"user_tz":-540,"elapsed":6669,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["def transformer(vocab_size,\n","                num_layers,\n","                units,\n","                d_model,\n","                num_heads,\n","                dropout,\n","                name=\"transformer\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n","\n","  enc_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1,1,None),\n","      name=\"enc_padding_mask\")(inputs)\n","  \n","  #mask future tokens for decoder inputs at 1st attention block\n","  look_ahead_mask = tf.keras.layers.Lambda(\n","      create_look_ahead_mask, output_shape=(1,None,None),\n","      name=\"look_ahead_mask\")(dec_inputs)\n","  \n","  #mask encoder outputs for the 2nd attention block\n","  dec_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1,1,None),\n","      name=\"dec_padding_mask\")(inputs)\n","  \n","  enc_outputs = encoder(\n","      vocab_size=vocab_size,\n","      num_layers=num_layers,\n","      units=units,\n","      d_model=d_model,\n","      num_heads=num_heads,\n","      dropout=dropout,\n","  )(inputs=[inputs, enc_padding_mask])\n","\n","  dec_outputs = decoder(\n","      vocab_size=vocab_size,\n","      num_layers=num_layers,\n","      units=units,\n","      d_model=d_model,\n","      num_heads=num_heads,\n","      dropout=dropout,\n","  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n","\n","  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pav-8Jd3ydzp"},"source":["## 모델 생성"]},{"cell_type":"code","metadata":{"id":"I8y-mjWtydzp","executionInfo":{"status":"ok","timestamp":1604400252007,"user_tz":-540,"elapsed":3848,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["tf.keras.backend.clear_session()\n","\n","model = transformer(\n","    vocab_size=VOCAB_SIZE,\n","    num_layers=NUM_LAYERS,\n","    units=UNITS,\n","    d_model=D_MODEL,\n","    num_heads=NUM_HEADS,\n","    dropout=DROPOUT)"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XK3IwtA4TOnN"},"source":["### Loss function\n","since target sequences are padded, deal this."]},{"cell_type":"code","metadata":{"id":"yi7YnqpVTYn2","executionInfo":{"status":"ok","timestamp":1604400252008,"user_tz":-540,"elapsed":2373,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["def loss_function(y_true, y_pred):\n","  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n","\n","  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","      from_logits=True, reduction='none')(y_true, y_pred)\n","  \n","  mask = tf.cast(tf.not_equal(y_true,0), tf.float32)\n","  loss = tf.multiply(loss, mask)\n","\n","  return tf.reduce_mean(loss)"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bzHEmCzUVhTu"},"source":["### Custom learning rate\n","use Adam optimizer with custom learning rate\n","$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"]},{"cell_type":"code","metadata":{"id":"CkFm9m_LVt8c","executionInfo":{"status":"ok","timestamp":1604400252356,"user_tz":-540,"elapsed":591,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps**-1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gb8PGbKgWAbP"},"source":["### Compile Model"]},{"cell_type":"code","metadata":{"id":"vql4FYFUV_3_","executionInfo":{"status":"ok","timestamp":1604400254856,"user_tz":-540,"elapsed":980,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["learning_rate = CustomSchedule(D_MODEL)\n","\n","optimizer = tf.keras.optimizers.Adam(\n","    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","def accuracy(y_true, y_pred):\n","  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n","  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n","  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mTXbb1Z2I4IM"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"Dl3V7BllWWFG","executionInfo":{"status":"ok","timestamp":1604400494236,"user_tz":-540,"elapsed":233448,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"6950e43b-830c-42a3-890e-b30fdb292fd1","colab":{"base_uri":"https://localhost:8080/"}},"source":["model.fit(dataset, epochs=EPOCHS)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","115/115 [==============================] - 4s 39ms/step - loss: 2.9456 - accuracy: 0.0240\n","Epoch 2/50\n","115/115 [==============================] - 4s 39ms/step - loss: 2.4690 - accuracy: 0.0450\n","Epoch 3/50\n","115/115 [==============================] - 4s 39ms/step - loss: 1.9385 - accuracy: 0.0699\n","Epoch 4/50\n","115/115 [==============================] - 4s 38ms/step - loss: 1.5982 - accuracy: 0.1090\n","Epoch 5/50\n","115/115 [==============================] - 4s 39ms/step - loss: 1.4005 - accuracy: 0.1393\n","Epoch 6/50\n","115/115 [==============================] - 4s 38ms/step - loss: 1.2560 - accuracy: 0.1569\n","Epoch 7/50\n","115/115 [==============================] - 4s 38ms/step - loss: 1.1527 - accuracy: 0.1690\n","Epoch 8/50\n","115/115 [==============================] - 4s 38ms/step - loss: 1.0748 - accuracy: 0.1781\n","Epoch 9/50\n","115/115 [==============================] - 4s 38ms/step - loss: 1.0099 - accuracy: 0.1852\n","Epoch 10/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.9526 - accuracy: 0.1914\n","Epoch 11/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.8972 - accuracy: 0.1982\n","Epoch 12/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.8491 - accuracy: 0.2036\n","Epoch 13/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.8006 - accuracy: 0.2093\n","Epoch 14/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.7509 - accuracy: 0.2154\n","Epoch 15/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.7065 - accuracy: 0.2207\n","Epoch 16/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.6593 - accuracy: 0.2269\n","Epoch 17/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.6134 - accuracy: 0.2334\n","Epoch 18/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.5714 - accuracy: 0.2394\n","Epoch 19/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.5290 - accuracy: 0.2458\n","Epoch 20/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.4860 - accuracy: 0.2528\n","Epoch 21/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.4409 - accuracy: 0.2613\n","Epoch 22/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.4031 - accuracy: 0.2675\n","Epoch 23/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.3645 - accuracy: 0.2748\n","Epoch 24/50\n","115/115 [==============================] - 5s 42ms/step - loss: 0.3291 - accuracy: 0.2825\n","Epoch 25/50\n","115/115 [==============================] - 5s 43ms/step - loss: 0.2992 - accuracy: 0.2888\n","Epoch 26/50\n","115/115 [==============================] - 5s 40ms/step - loss: 0.2693 - accuracy: 0.2948\n","Epoch 27/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.2454 - accuracy: 0.3004\n","Epoch 28/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.2266 - accuracy: 0.3034\n","Epoch 29/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.2072 - accuracy: 0.3080\n","Epoch 30/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.1956 - accuracy: 0.3106\n","Epoch 31/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.1864 - accuracy: 0.3126\n","Epoch 32/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.1747 - accuracy: 0.3149\n","Epoch 33/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.1689 - accuracy: 0.3165\n","Epoch 34/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.1623 - accuracy: 0.3178\n","Epoch 35/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.1568 - accuracy: 0.3194\n","Epoch 36/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.1533 - accuracy: 0.3199\n","Epoch 37/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.1414 - accuracy: 0.3236\n","Epoch 38/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.1319 - accuracy: 0.3261\n","Epoch 39/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.1226 - accuracy: 0.3290\n","Epoch 40/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.1172 - accuracy: 0.3304\n","Epoch 41/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.1087 - accuracy: 0.3330\n","Epoch 42/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.1046 - accuracy: 0.3339\n","Epoch 43/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.1007 - accuracy: 0.3350\n","Epoch 44/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0950 - accuracy: 0.3367\n","Epoch 45/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0897 - accuracy: 0.3383\n","Epoch 46/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0850 - accuracy: 0.3396\n","Epoch 47/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0842 - accuracy: 0.3396\n","Epoch 48/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0779 - accuracy: 0.3416\n","Epoch 49/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0762 - accuracy: 0.3423\n","Epoch 50/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0729 - accuracy: 0.3432\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f39d75990f0>"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"MfPsD5bbwMcJ","executionInfo":{"status":"ok","timestamp":1604401253502,"user_tz":-540,"elapsed":223950,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"a493effe-24fd-4970-ca75-07feeb507a98","colab":{"base_uri":"https://localhost:8080/"}},"source":["model.fit(dataset, epochs=EPOCHS)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","115/115 [==============================] - 5s 39ms/step - loss: 0.0736 - accuracy: 0.3432\n","Epoch 2/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0695 - accuracy: 0.3441\n","Epoch 3/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0660 - accuracy: 0.3450\n","Epoch 4/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0638 - accuracy: 0.3459\n","Epoch 5/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0614 - accuracy: 0.3466\n","Epoch 6/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0597 - accuracy: 0.3468\n","Epoch 7/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0584 - accuracy: 0.3472\n","Epoch 8/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0560 - accuracy: 0.3482\n","Epoch 9/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0543 - accuracy: 0.3485\n","Epoch 10/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0522 - accuracy: 0.3494\n","Epoch 11/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0518 - accuracy: 0.3495\n","Epoch 12/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0511 - accuracy: 0.3500\n","Epoch 13/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0506 - accuracy: 0.3497\n","Epoch 14/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0491 - accuracy: 0.3503\n","Epoch 15/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0466 - accuracy: 0.3508\n","Epoch 16/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0473 - accuracy: 0.3508\n","Epoch 17/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0439 - accuracy: 0.3518\n","Epoch 18/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0458 - accuracy: 0.3513\n","Epoch 19/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0426 - accuracy: 0.3522\n","Epoch 20/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0415 - accuracy: 0.3522\n","Epoch 21/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0406 - accuracy: 0.3528\n","Epoch 22/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0424 - accuracy: 0.3521\n","Epoch 23/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0407 - accuracy: 0.3526\n","Epoch 24/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0383 - accuracy: 0.3534\n","Epoch 25/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0387 - accuracy: 0.3533\n","Epoch 26/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0373 - accuracy: 0.3537\n","Epoch 27/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0370 - accuracy: 0.3537\n","Epoch 28/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0375 - accuracy: 0.3535\n","Epoch 29/50\n","115/115 [==============================] - 4s 39ms/step - loss: 0.0361 - accuracy: 0.3539\n","Epoch 30/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0341 - accuracy: 0.3546\n","Epoch 31/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0341 - accuracy: 0.3544\n","Epoch 32/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0339 - accuracy: 0.3549\n","Epoch 33/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0331 - accuracy: 0.3548\n","Epoch 34/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0327 - accuracy: 0.3549\n","Epoch 35/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0330 - accuracy: 0.3548\n","Epoch 36/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0320 - accuracy: 0.3552\n","Epoch 37/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0312 - accuracy: 0.3554\n","Epoch 38/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0300 - accuracy: 0.3558\n","Epoch 39/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0304 - accuracy: 0.3556\n","Epoch 40/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0306 - accuracy: 0.3557\n","Epoch 41/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0285 - accuracy: 0.3563\n","Epoch 42/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0304 - accuracy: 0.3555\n","Epoch 43/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0286 - accuracy: 0.3562\n","Epoch 44/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0286 - accuracy: 0.3562\n","Epoch 45/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0285 - accuracy: 0.3559\n","Epoch 46/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0281 - accuracy: 0.3562\n","Epoch 47/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0264 - accuracy: 0.3566\n","Epoch 48/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0277 - accuracy: 0.3563\n","Epoch 49/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0268 - accuracy: 0.3567\n","Epoch 50/50\n","115/115 [==============================] - 4s 38ms/step - loss: 0.0259 - accuracy: 0.3568\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f39d61cb940>"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"e6EDnEOwI_G7"},"source":["## Predict"]},{"cell_type":"code","metadata":{"id":"Gxi2B-vjydzt","executionInfo":{"status":"ok","timestamp":1604400502395,"user_tz":-540,"elapsed":742,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["# 인덱스를 문장으로 변환\n","def convert_index_to_text(indexs, vocabulary): \n","    \n","    sentence = ''\n","    \n","    # 모든 문장에 대해서 반복\n","    for index in indexs:\n","        if index == END_INDEX:\n","            # 종료 인덱스면 중지\n","            break;\n","        if vocabulary.get(index) is not None:\n","            # 사전에 있는 인덱스면 해당 단어를 추가\n","            sentence += vocabulary[index]\n","        else:\n","            # 사전에 없는 인덱스면 OOV 단어를 추가\n","            sentence.extend([vocabulary[OOV_INDEX]])\n","            \n","        # 빈칸 추가\n","        sentence += ' '\n","\n","    return sentence"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"2E66RpbXydzy","executionInfo":{"status":"ok","timestamp":1604400494555,"user_tz":-540,"elapsed":228618,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["# 예측을 위한 입력 생성\n","def make_predict_input(sentence):\n","\n","    sentences = []\n","    sentences.append(sentence)\n","    sentences = pos_tag(sentences)\n","    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n","    \n","    return input_seq"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"umBNECObKCJj","executionInfo":{"status":"ok","timestamp":1604400494556,"user_tz":-540,"elapsed":225883,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["def evaluate(input_seq):\n","\n","  input_seq = input_seq.squeeze()\n","  sentence = tf.expand_dims(input_seq, axis=0)\n","  output = tf.expand_dims([1], 0)\n","\n","  for i in range(max_sequences):\n","    predictions = model(inputs=[sentence, output], training=False)\n","\n","    # select the last word from the seq_len dimension\n","    predictions = predictions[:, -1:, :]\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","    # return the result if the predicted_id is equal to the end token\n","    if tf.equal(predicted_id, 2):\n","      break\n","\n","    # concatenated the predicted_id to the output which is given to the decoder\n","    # as its input.\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  return tf.squeeze(output, axis=0)"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3YqOZ-MEOVW","executionInfo":{"status":"ok","timestamp":1604401377052,"user_tz":-540,"elapsed":123535,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["# for train data predict\n","Hannanum_ans_100 = []\n","for seq_index in range(100):\n","#   print(\"고객 : \",question[seq_index])\n","#   print(\"정답점원 :\",answer[seq_index])\n","    Hannanum_ans_100.append(convert_index_to_text(evaluate(make_predict_input(question[seq_index])).numpy()[1:],index_to_word))\n","#   print(\"AI점원 :\",ai_ans)\n","#   print(\"\\n\")"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"ko-GqzLTclKN","executionInfo":{"status":"ok","timestamp":1604397641010,"user_tz":-540,"elapsed":943,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}},"outputId":"3310606f-58fe-4669-983c-9259cd2d9a03","colab":{"base_uri":"https://localhost:8080/"}},"source":["#Okt_ans_50\n","#Okt_ans_100"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"markdown","metadata":{"id":"FYv7EewQhIAd"},"source":["## Train_Test data prediction\n"," - Train_set 100개\n"," - Test_set 100개\n"," "]},{"cell_type":"code","metadata":{"id":"8uZiQH0Ziu_h","executionInfo":{"status":"ok","timestamp":1604400758307,"user_tz":-540,"elapsed":968,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["test_question_arr = []\n","test_question = \"\"\n","\n","for i in range(14900,wear_data.shape[0]):\n","        test_question = wear_data.iloc[i].SENTENCE\n","        test_question_arr.append(test_question)\n","\n","# test_question_arr = pos_tag(test_question_arr)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"RroUo2wthdA-","executionInfo":{"status":"ok","timestamp":1604401685293,"user_tz":-540,"elapsed":125578,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["# for train data predict\n","Hannanum_ans_100_test = []\n","for seq_index in range(0,100):\n","    Hannanum_ans_100_test.append(convert_index_to_text(evaluate(make_predict_input(test_question_arr[seq_index])).numpy()[1:],index_to_word))\n","#   print(\"고객 : \",test_question_arr[seq_index])\n","#   print(\"AI점원 :\",convert_index_to_text(evaluate(make_predict_input(test_question_arr[seq_index])).numpy()[1:],index_to_word))\n","#   print(\"\\n\")"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"zAs_p0bLhlPy","executionInfo":{"status":"ok","timestamp":1604401724854,"user_tz":-540,"elapsed":780,"user":{"displayName":"송두기","photoUrl":"","userId":"17235278193210258641"}}},"source":["import pickle\n","\n","with open('Hannanum_ans_100_test.pkl','wb') as f:\n","    pickle.dump(Hannanum_ans_100_test, f)\n"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Vn5AB5Zmal6"},"source":["import pickle\n","\n","with open('Hannanum_ans_50_test.pkl','wb') as f:\n","    pickle.dump(Hannanum_ans_50_test, f)"],"execution_count":null,"outputs":[]}]}