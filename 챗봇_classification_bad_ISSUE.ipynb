{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "챗봇_classification_bad_ISSUE",
      "provenance": [],
      "collapsed_sections": [
        "9UA-8fQ2EDnp",
        "ioT3c4eLEKon",
        "jx-jxXncYmlp",
        "e6EDnEOwI_G7",
        "kjLQI4czaTs1"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ideablast/NLPer_chatbot/blob/kdg/%EC%B1%97%EB%B4%87_classification_bad_ISSUE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsiilWsMNHHL"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UA-8fQ2EDnp"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DAFy5c7ydzC"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers, losses, metrics\n",
        "from keras import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioT3c4eLEKon"
      },
      "source": [
        "## Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9YUdE1OydzG"
      },
      "source": [
        "# 태그 단어\n",
        "PAD = \"<PADDING>\"   # 패딩\n",
        "STA = \"<START>\"     # 시작\n",
        "END = \"<END>\"       # 끝\n",
        "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
        "\n",
        "# 태그 인덱스\n",
        "PAD_INDEX = 0\n",
        "STA_INDEX = 1\n",
        "END_INDEX = 2\n",
        "OOV_INDEX = 3\n",
        "\n",
        "# 데이터 타입\n",
        "ENCODER_INPUT  = 0\n",
        "DECODER_INPUT  = 1\n",
        "DECODER_TARGET = 2\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256 ##word embedding dim\n",
        "NUM_HEADS = 8 ## D_Model % NUM_HEADS == 0이 되야하므로...\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "EPOCHS = 50\n",
        "# for data pipelining\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "VOCAB_SIZE = 0 # 후에 len(words) 로 바뀜.\n",
        "\n",
        "# 한 문장에서 단어 시퀀스의 최대 개수\n",
        "max_sequences = 30\n",
        "\n",
        "# 정규 표현식 필터\n",
        "RE_FILTER = re.compile(\"[\\\"':;~()]\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhVVnW_uEWT1"
      },
      "source": [
        "## Data Load & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80IauV0FpUv2",
        "outputId": "9c2c9f2b-bea5-4b27-c721-76595f38c2a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEHDnPXNzZlM",
        "outputId": "1ec8d8c6-f365-4465-f928-28449225ba15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wear_data = pd.read_csv(\"/content/drive/My Drive/wear.csv\")\n",
        "print(wear_data.shape)\n",
        "customer = wear_data[wear_data.SPEAKER == \"고객\"].SENTENCE\n",
        "store = wear_data[wear_data.SPEAKER == \"점원\"].SENTENCE\n",
        "print(customer.shape, store.shape) # 질문의 개수와 답의 개수가 일치하지 않는다."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15826, 20)\n",
            "(8381,) (7445,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh9AoDEiUev-",
        "outputId": "a2335531-91e6-4780-c9a7-30ec780253bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 점원,고객 중 두번 말하면 그것을 한 문장으로 전처리\n",
        "prev = \"고객\"\n",
        "store_arr = []\n",
        "customer_arr = []\n",
        "store_stc = \"\"\n",
        "customer_stc = \"\"\n",
        "\n",
        "for i in range(wear_data.shape[0]):\n",
        "    if (prev == wear_data.iloc[i].SPEAKER):\n",
        "        if prev == \"점원\":\n",
        "             store_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "        else : \n",
        "             customer_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "            \n",
        "    elif prev == \"점원\":\n",
        "        store_arr.append(store_stc)\n",
        "        customer_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"고객\"\n",
        "    else :\n",
        "        customer_arr.append(customer_stc)\n",
        "        store_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"점원\"\n",
        "print(len(store_arr))\n",
        "print(len(customer_arr))\n",
        "print(store_arr[-1])\n",
        "print(customer_arr[-1]) "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7301\n",
            "7301\n",
            "요즘 파스텔 톤이 유행이에요\n",
            "요즘 유행하는 색깔이 뭐예요?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly-2lhdFZhVY",
        "outputId": "46afa94e-fdb8-47cc-cc01-3120066f5774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "faqs = [] # [[index, 고객의 문장, 점원의 문장, 카테고리, 의도)]...]\n",
        "\n",
        "for i in range(len(store_arr)):\n",
        "    faqs_tmp =[]\n",
        "    faqs_tmp.append(str(i+1))\n",
        "    faqs_tmp.append(customer_arr[i].lstrip())\n",
        "    faqs_tmp.append(store_arr[i])\n",
        "    faqs_tmp.append(max(wear_data[wear_data.SENTENCE == customer_arr[i].lstrip()].CATEGORY.tolist())) \n",
        "    #카테고리중 가장 많은 값을 채우려다 customer_arr[i]와 일치하는 문장이 없는 경우가 있어서 막힘.\n",
        "    faqs_tmp.append(max(wear_data[wear_data.SENTENCE == customer_arr[i].lstrip()].MAIN.tolist()))\n",
        "\n",
        "    faqs.append(faqs_tmp)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-66e3f0e0e0ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfaqs_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomer_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfaqs_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfaqs_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwear_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwear_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSENTENCE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcustomer_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCATEGORY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mfaqs_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwear_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwear_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSENTENCE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcustomer_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LITeVj8czrxp",
        "outputId": "f8cafa87-d346-4578-e8f0-634996122d5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wear_data.SENTENCE.values.tolist()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['신발은 여기 있는 게 다예요?',\n",
              " '네 성인이나 아동 다 있어요',\n",
              " '발 사이즈 몇 신으세요?',\n",
              " '230이요',\n",
              " '편하게 신을 수 있는 거 찾으세요?',\n",
              " '네 봄이니까 편하게 신을 수 있는 거',\n",
              " '이런 건 어떠세요? 이런 거도 신발 무척 편하거든요',\n",
              " '굽 좀 높은 거 없나요?',\n",
              " '봄 상품은 아직 어른 제품이 많이 안나왔습니다',\n",
              " '언제 들어와요?',\n",
              " '이번주 지나면 들어올 거예요',\n",
              " '이거는 가죽이에요?',\n",
              " '가죽 아니고 쎄무예요',\n",
              " '가죽은 얼마예요?',\n",
              " '2만 9천 원입니다',\n",
              " '털 달린 거 저거는 사이즈 있어요?',\n",
              " '230이 없어요 ',\n",
              " '이거 한 번 신어보세요',\n",
              " '좀 크네',\n",
              " '또 안 들어와요?',\n",
              " '네 이건 다 끝났어요',\n",
              " '가방 매는 거 보고 있어요',\n",
              " '여기 있어요',\n",
              " '가격이 얼마예요?',\n",
              " '이 종류는 2만 원이고 이 종류는 3만 8천 원이에요',\n",
              " '가죽으로 된 거는 없어요?',\n",
              " '가죽은 없고 레자만 있어요',\n",
              " '레자는 얼마예요?',\n",
              " '5만 5천 원요',\n",
              " '이거는 천이죠?',\n",
              " '네 맞아요',\n",
              " '이건 얼마예요?',\n",
              " '그것도 5만 5천 원요',\n",
              " '이거 끈은 따로 없어요?',\n",
              " '안에 있어요',\n",
              " '내일은 문 열어요?',\n",
              " '휴무입니다',\n",
              " '며칠까지 휴무예요?',\n",
              " '설까지 쉬고 다음날 열 거 같아요',\n",
              " '여기 마스크는 얼마예요?',\n",
              " '5천 원요',\n",
              " '이거 나무예요? 다 돌인가요?',\n",
              " '나무도 있고 도자기도 있어요',\n",
              " '이런 건 세트로 팔아요?',\n",
              " '네 세트로만 팔아요',\n",
              " '이건 뭐예요?',\n",
              " '마블이라고 종이를 말아가지고 하는 거예요',\n",
              " '제일 큰 거는 얼마인데요?',\n",
              " '세트에 7만 원이요',\n",
              " '스카프 좀 보려구요',\n",
              " '네 천천히 보세요',\n",
              " '실크스카프도 봄에 하나요?',\n",
              " '실크 봄 가을에 하죠',\n",
              " '이거는 뭐예요?',\n",
              " '토시예요',\n",
              " '여기 가격은 그대로 파시는 거예요?',\n",
              " '네 핸드메이드로 해가지고 그 가격으로 팔아요',\n",
              " '착용해볼 수 있어요?',\n",
              " '네 가능하세요',\n",
              " '이거는 요즘 들어온 거예요?',\n",
              " '네 어제 들어왔어요',\n",
              " '세탁은 물세탁되죠?',\n",
              " '끝부분이 가죽이라서 조심해야해요',\n",
              " '지금 여기 있는 게 다예요?',\n",
              " '네 다예요',\n",
              " '몇 시에 문 닫아요?',\n",
              " '8시까지 합니다',\n",
              " '일요일도 하세요?',\n",
              " '아뇨 닫아요',\n",
              " '스카프 있어요?',\n",
              " '네 여기는 2단 이거는 3단 제품있어요',\n",
              " '이런 건 세탁을 어떻게 해요?',\n",
              " '울샴푸를 물에 몇 방울 떨어뜨려서 조물조물하면 됩니다',\n",
              " '원단은 뭐예요?',\n",
              " '원단이 구김 안 가고 참 괜찮아요',\n",
              " '얼마인데요?',\n",
              " '2만 원입니다',\n",
              " '브로치 같은 건 어디 있나요?',\n",
              " '여기 있는 거밖에 없어요',\n",
              " '이런 거도 2만 원이예요?',\n",
              " '헤르메스인데 이것도 괜찮아요',\n",
              " '명품이랑 똑같이 한 거예요?',\n",
              " '네 원단만 다르고 디자인을 똑같이 만든 거예요',\n",
              " '온누리 상품권도 되죠?',\n",
              " '네 됩니다',\n",
              " '브로치하고 머리핀하고 보려고요',\n",
              " '머리핀은 밖에 있고 브로치는 안에 있습니다',\n",
              " '도자기 같은 거 말고 구슬이나 진주 같은 거는 없어요?',\n",
              " '지금 옷에 가볍게 하려면 진주도 예쁘지만 이것도 깔끔합니다',\n",
              " '보석은 싫으세요?',\n",
              " '그건 흥미없고',\n",
              " '안에 하면 안 떨어져요?',\n",
              " '안 떨어져요',\n",
              " '얼마예요?',\n",
              " '핀 꼽는 거는 좀 싼 거고 이거는 3만 원대예요',\n",
              " '이 우산은 얼마인데요?',\n",
              " '4만 2천 원이요',\n",
              " '무겁지 않아요?',\n",
              " '좋은 재료를 쓰기 때문에 무겁지 않아요',\n",
              " '이렇게 다는 거 맞아요?',\n",
              " '그렇게 달면 안되고 이렇게 달아야 해요',\n",
              " '자석은 다 3만 원?',\n",
              " '3만 원 짜리도 있고 2만 원 짜리도 있어요',\n",
              " '머리핀 종류도 한 번 보여주세요 곱창은 요새 안나와요?',\n",
              " '곱창 밴드는 안나와요 촌스러워서 유행 다 지났어요',\n",
              " '브로치 종류도 있어요?',\n",
              " '아뇨 없어요',\n",
              " '스카프도 없어요?',\n",
              " '스카프는 이쪽에 종류가 있어요',\n",
              " '이런 거 실크입니까?',\n",
              " '실크 아니예요',\n",
              " '이런 거는 뭐라 그래요?',\n",
              " '실캣으로 만든 거죠',\n",
              " '이런 거는 얼마예요?',\n",
              " '대충 2만 원 내외요',\n",
              " '이런 거는 물세탁 됩니까?',\n",
              " '물세탁 조금 해도 상관은 없으세요',\n",
              " '근데 이거 제가 한 거 아닌데 약간 올이 나갔네요',\n",
              " '이거 원하시면 주문 가능하세요',\n",
              " '또 언제 들어와요?',\n",
              " '스카프는 많이 들어오지 않아서 주문하시는 게 좋아요',\n",
              " '이거는 목걸이 링이에요?',\n",
              " '아뇨 반지예요',\n",
              " '금이에요?',\n",
              " '액세서리예요 금 아니예요',\n",
              " '이거 한 번 해봐도 돼요?',\n",
              " '네 가능합니다',\n",
              " '신상품 더 들어오죠?',\n",
              " '네 들어올 거예요',\n",
              " '이 모양으로 목걸이 팔찌 세트 구입할까 하는데',\n",
              " '똑같은 모양은 주문을 넣어야 할 거 같은데요',\n",
              " '가격은 어떻게 돼요?',\n",
              " '모양을 보고 견적을 내봐야 해요',\n",
              " '이 금팔찌는 무게가 얼마 정도인지 확인할 수 있어요?',\n",
              " '세 돈이 조금 넘네요',\n",
              " '견본인 팔찌가 있어요?',\n",
              " '여기 있습니다',\n",
              " '여기는 금 매입도 해요?',\n",
              " '네 해요',\n",
              " '이거 판다고 얼마 정도 받을 수 있어요?',\n",
              " '대충 39만 3천 원 정도 나오네요',\n",
              " '팔찌 두 돈 짜리도 한 번 보여주시고 다른 거도 보여주세요',\n",
              " '유행하는 로즈골드 하셔도 되고 골드 하셔도 돼요',\n",
              " '가격이 구입하려면 얼마인데요?',\n",
              " '현금 가격 기준으로 62만 9천 원이요',\n",
              " '이거 18케이예요?',\n",
              " '네 18케이예요',\n",
              " '시내에 있는 금 도매상하고 여기랑 가격 차이가 많이나요?',\n",
              " '그쪽은 유지비가 많이 나가니까 아무래도 여기가 더 싸죠',\n",
              " '액세서리 세일 제품이 있나요?',\n",
              " '악세서리 어떤 거 찾으세요?',\n",
              " '스카프 같은 거',\n",
              " '이거 괜찮아요',\n",
              " '이건 소재가 뭐예요?',\n",
              " '폴리에스테르라고 적혀 있네요',\n",
              " '색상은 이거 하나뿐이고?',\n",
              " '네 다 빠지고 이거 하나예요',\n",
              " '빨면 좀 그렇지 않을까?',\n",
              " '조심해야 하는데 면이 아니니까 집에서 손 드라이해도 돼요',\n",
              " '이거는 가격이 얼마예요?',\n",
              " '16000원인데 몇 천 원 빼드릴게요',\n",
              " '이건 얼마예요?',\n",
              " '13000원입니다',\n",
              " '이 핑크색 모자는 애기들 꺼예요?',\n",
              " '애기용입니다',\n",
              " '어른들 꺼는 없어요?',\n",
              " '다 빠졌어요',\n",
              " '팔찌 제품 따로 있나요?',\n",
              " '고객님이 하실 거예요?',\n",
              " '네 ',\n",
              " '지금 세일 기간이에요?',\n",
              " '네 당분간은 할 거 같아요',\n",
              " '한 몇 프로 하는데요?',\n",
              " '정가에서 한 40프로 합니다',\n",
              " '이거는 가격대가 얼마예요?',\n",
              " '이거 샘플이 14케이인데 뭘로 봐드릴까요?',\n",
              " '18케이로',\n",
              " '18케이로 하시면 49만 원이요',\n",
              " '팔찌 좀 핫한 제품 뭐가 있어요?',\n",
              " '깔끔하게 이런 거 잘나가요',\n",
              " '18케이예요?',\n",
              " '네 맞아요',\n",
              " '돈수로 따지면 몇 돈이에요?',\n",
              " '두 돈반 조금 안돼요',\n",
              " '얼마예요?',\n",
              " '48만 원 정도요',\n",
              " '굵은 게 이거 다예요?',\n",
              " '5돈 6돈짜리도 있어요',\n",
              " '굵은 거 찾으시면 이런 건 어떠세요?',\n",
              " '너무 사치스러운데 ',\n",
              " '핸드폰 케이스 파는 거예요?',\n",
              " '네 맞습니다',\n",
              " '여기는 가격이 어떤 게 있어요?',\n",
              " '기종이 어떻게 되죠? ',\n",
              " '엘지인데',\n",
              " '만 오천 원대부터 시작해서 이만 오천 원까지 있습니다',\n",
              " '그건 얼마예요?',\n",
              " '3만 원 정도 해요',\n",
              " '색상은 이게 전부예요?',\n",
              " '레드색인데 핑크도 있고 보랏빛 퍼플색도 있고 색상 종류가 다양해요',\n",
              " '엘지 지식스 케이스로 좀 보여주세요',\n",
              " '그 기종은 여기 있어요',\n",
              " '이건 얼마예요?',\n",
              " '3만 5천 원입니다',\n",
              " '현금으로 사면 할인이 된다거나 그런 게 있나요?',\n",
              " '현금으로 하면 좀 디씨해드려요',\n",
              " '반지 이거 세척 가능해요?',\n",
              " '월요일에 해야해요',\n",
              " '세척하려면 돈 드려야하죠?',\n",
              " '이건 다른 데 가져가셔야합니다 우리 기계하고 안맞아요',\n",
              " '집에서 울샴푸 넣어가지고 세척 해도 되는 거예요?',\n",
              " '네 그렇게 해보세요',\n",
              " '이게 순금인지 18케이인지 한 번 봐주시겠어요?',\n",
              " '18케이입니다',\n",
              " '팔찌 좀 굵은 걸로 석 돈짜리로 한 번 봐주시겠어요?',\n",
              " '세 돈은 굵은 스타일로 안됩니다',\n",
              " '제가 목걸이랑 세트로 하려고 하는데',\n",
              " '이런 게 3돈반 이런 목걸이는 8돈 나옵니다',\n",
              " '이거는 가격이 얼마나 해요?',\n",
              " '이게 1돈반인데 44만 8천 원이에요',\n",
              " '현금으로 하면 할인은 안되나요?',\n",
              " '이게 현금 가격이구요 카드로 하면 말씀하셔야 해요',\n",
              " '요즘 금 시세는 얼마나해요?',\n",
              " '18만 8천 원이요',\n",
              " '18케이 말씀하시는 거죠?',\n",
              " '순금이요',\n",
              " '이 팔찌도 예쁜데 가격이 비슷할까요?',\n",
              " '그건 25만 3천 원요',\n",
              " '금 두 세 돈짜리로 팔찌 보여주실 수 있어요?',\n",
              " '순금으로 보여드릴까요?',\n",
              " '18케이로',\n",
              " '이게 두 세 돈짜리예요',\n",
              " '좀 잘나가는 유형은 어떤 거예요?',\n",
              " '이런 게 잘 나가요',\n",
              " '이거 동글동글한 거 두 줄짜리는 18케이에요?',\n",
              " '네 맞아요',\n",
              " '가격은 얼마예요?',\n",
              " '카드는 28만 원 현금은 25만 원입니다',\n",
              " '외국에서 구매한 반지 여기서 세척할 수 있나요?',\n",
              " '공장에 맡겨야합니다',\n",
              " '세척은 얼마 정도 하는데요?',\n",
              " '5천 원에서 1만 원 정도예요',\n",
              " '두 줄짜리 딱 붙은 거 이거 한 번 볼까요?',\n",
              " '네 여기 있습니다',\n",
              " '이거는 가격이?',\n",
              " '95만 원이요',\n",
              " '여자 시계는 어떤 거 있어요?',\n",
              " '누가 하실 건데요?',\n",
              " '제가 할 거예요',\n",
              " '어떤 디자인 찾으세요?',\n",
              " '그냥 기본 디자인 찾고 있어요',\n",
              " '이렇게 심플한 거 많이 나가거든요',\n",
              " '착용해볼 수 있어요?',\n",
              " '비닐 떼지 마시고 그냥 착용해보세요',\n",
              " '귀걸이 한 번 볼 수 있어요?',\n",
              " '원터치로 보여드릴까요?',\n",
              " '원터치로 좀 붙는 걸로',\n",
              " '얼마예요?',\n",
              " '18케이라서 15만 3천 원이요',\n",
              " '이거는 얼마예요?',\n",
              " '12만 8천 원이요',\n",
              " '팔찌는 가격 어떻게 해요?',\n",
              " '15000원이요',\n",
              " '재질은 뭔데요?',\n",
              " '옥 같은거예요',\n",
              " '이건 그냥 악세서리로 하는 거죠?',\n",
              " '네 그렇죠',\n",
              " '민트색인가요?',\n",
              " '네 민트색이예요',\n",
              " '겨울 상품 세일하는 거예요?',\n",
              " '네 맞아요',\n",
              " '몇 시에 문 닫으세요?',\n",
              " '10시까지는 합니다',\n",
              " '귀걸이 보러 왔는데요',\n",
              " '이쪽에 보시면 돼요',\n",
              " '이게 이미테이션이에요?',\n",
              " '아뇨 다 은이에요',\n",
              " '하트링으로 되어 있는 거는 얼마예요?',\n",
              " '현금하시면 14000원 카드하시면 15000원이요',\n",
              " '이건 팔찌예요?',\n",
              " '네 맞아요',\n",
              " '은 목걸이 이거는 가격이 어떻게 돼요?',\n",
              " '2만 원인데 현금하시면 19000원이요',\n",
              " '가게 앞에 주차 단속하나요?',\n",
              " '한 10분 정도까지는 괜찮습니다',\n",
              " '팔찌 중간에 있는 구슬은 뭐예요?',\n",
              " '비즈예요',\n",
              " '카카오페이 결제 되나요?',\n",
              " '계좌이체 되기 때문에 카카오페이 계좌 바꿔서 하시면 돼요',\n",
              " '몇 시까지 하나요?',\n",
              " '9시까지 합니다',\n",
              " '귀걸이가 은인가요?',\n",
              " '앞에만 은인 거도 있고 침까지 은인 거도 있어요',\n",
              " '티타늄은 무슨 재질이에요?',\n",
              " '서지컬인데 병원에 가위 같은 데 쓰는 거라서 인체 공학적으로 안전해요',\n",
              " '알레르기 있으세요?',\n",
              " '저는 은침해도 한 시간 지나면 심해져서요',\n",
              " '귀걸이 14케이나 18케이는 어떤 게 있어요?',\n",
              " '앞에 진열돼있어요',\n",
              " '이건 얼마예요?',\n",
              " '8만 원이요',\n",
              " '이건 다 수공예로 하신 거예요?',\n",
              " '한 거도 있고 떼온 거도 있어요',\n",
              " '이건 목 둘러서 앞으로 하는 거죠?',\n",
              " '안에 넣어도 되구요',\n",
              " '현금으로 하면 할인해주시나요?',\n",
              " '만 원인데 천 원 할인해드릴게요',\n",
              " '귀도 뚫어주시나요?',\n",
              " '그럼요 귀 전문인데요',\n",
              " '고무줄은 어디 있어요?',\n",
              " '여기 검은 고무줄 있어요',\n",
              " '진주 있는 이런 방울도 하는가요?',\n",
              " '요즘은 잘 안하죠 까만 거만 해요',\n",
              " '선물해주려고 하는데',\n",
              " '따님요?',\n",
              " '네',\n",
              " '뭐 달려있는 거는 요새 잘 안해요',\n",
              " '이거는 재질이 뭐예요?',\n",
              " '은침이죠',\n",
              " '앞에는요?',\n",
              " '앞에는 그냥 액세서리예요',\n",
              " '여기 있는 건 다 은침인가요?',\n",
              " '은침이 많고 아니면 이쪽은 다 금이예요',\n",
              " '위에 꺼는 액세서리예요?',\n",
              " '피어싱이요 ',\n",
              " '누가 끼시는 거죠?',\n",
              " '제가요',\n",
              " '그럼 이거 끼세요 부작용도 없고 너무 예뻐요',\n",
              " '제가 금 밖에 안되거든요?',\n",
              " '이게 티타늄이라서 하셔도 될 거예요',\n",
              " '한 쪽만 사도 되나요??',\n",
              " '따로 하셔도 되고 세트 하셔도 돼요',\n",
              " '한 개당 얼마예요?',\n",
              " '개당 가격이 7000원이예요',\n",
              " '한 쪽만 먼저 착용 해보시겠어요?',\n",
              " '고민 좀 해볼게요',\n",
              " '현금이나 카드 똑같이 7000원이에요?',\n",
              " '네 똑같아요',\n",
              " '문은 언제 닫아요?',\n",
              " '8시요',\n",
              " '액세서리 시계 있어요?',\n",
              " '시계 종류 어떤 거요?',\n",
              " '메탈 시계요',\n",
              " '지금 하나 남아 있어요',\n",
              " '귀걸이는 은 제품도 있어요?',\n",
              " '거기 다 은이에요',\n",
              " '침만 은인가요?',\n",
              " '침만 은이고 전체 다 은인 것도 있어요',\n",
              " '요즘은 어떤 게 유행이에요?',\n",
              " '머리가 좀 길면 긴 거 하시고 링도 요즘 많이 나가요',\n",
              " '이건 얼마예요?',\n",
              " '11000원이요',\n",
              " '알레르기 있으신가요?',\n",
              " '티타늄도 알러지가 생겨버려요',\n",
              " '이 초록색 이건 얼마예요?',\n",
              " '16000원이예요 ',\n",
              " '착용해볼 수 있어요?',\n",
              " '착용은 안되고 살짝 대보시면 됩니다',\n",
              " '가게 문 언제까지 하는데요?',\n",
              " '6시 반까지해요',\n",
              " '아침에는 언제 열어요?',\n",
              " '아침에는 안 열고 1시쯤에 열어요',\n",
              " '가격은 카드하나 현금하나 똑같아요?',\n",
              " '현금하시면 조금 빼드려요',\n",
              " '봄 옷 안 들어와요?',\n",
              " '내일 들어와요',\n",
              " '이거 할인 해주세요?',\n",
              " '네 그 가격표에서 반값이에요',\n",
              " '이런 거는 사이즈가 어떻게 돼요?',\n",
              " '그거는 77, 88이라 좀 큰 거예요',\n",
              " '66도 있어요?',\n",
              " '아뇨 그건 재고가 없어요',\n",
              " '티는 여기 있는 게 다예요?',\n",
              " '일반 티는 밖에 있어요',\n",
              " '이게 숫자 적힌 게 사이즈입니까?',\n",
              " '네 사이즈가 어떻게 되세요?',\n",
              " '32',\n",
              " '이거는 3번이니까 고객님에게 큰 거예요',\n",
              " '제 사이즈는 얼만데요?',\n",
              " '66이나 77이 맞겠습니다',\n",
              " '이런 건 얼마에요?',\n",
              " '그거는 계속 나가는 거라 반값 할인이 안돼요',\n",
              " '이게 겨울옷인가요?',\n",
              " '네 맞아요',\n",
              " '3월에 입어도 되겠어요 그죠?',\n",
              " '꽃샘추위가 있어서 3월에 입어도 돼요 ',\n",
              " '세탁은 어떻게 해요 이거?',\n",
              " '무지라서 일반 바지 빨듯이 하면 돼요',\n",
              " '면바지 종류는 있어요?',\n",
              " '지금 사이즈 다 빠져서 라지밖에 없어요',\n",
              " '라지라면 사이즈 얼마?',\n",
              " '29 30요',\n",
              " '밴딩에다가 끈도 조금 있으면은 좋더라고요 그런 건 없나요?',\n",
              " '이런 거 말씀하시는 건가요?',\n",
              " '네',\n",
              " '조끼 한 번 입어봐도 돼요?',\n",
              " '네 입어보세요',\n",
              " '같은 걸로 다른 색도 있어요?',\n",
              " '그레이 색 있어요',\n",
              " '이거 두 개가 디자인은 똑같은 거예요?',\n",
              " '디자인은 똑같은데 구슬 있고 없고의 차이에요',\n",
              " '그럼요 이거 주세요',\n",
              " '네 알겠습니다',\n",
              " '저녁에 몇 시에 문 닫죠?',\n",
              " '6시 반이요',\n",
              " '교환이나 환불 되나요?',\n",
              " '교환, 환불, 반품은 안됩니다.',\n",
              " '제가 카드밖에 없는데',\n",
              " '카드로 결제 해드릴게요',\n",
              " '패딩조끼 오래 입으려면 드라이 맡기는 게 좋죠?',\n",
              " '패딩이니까 세탁기 돌려도 돼요',\n",
              " '블라우스는 없나요?',\n",
              " '블라우스는 앞에 조금 있고 아직 많이는 안 나왔어요',\n",
              " '이거는 겨울옷이네요?',\n",
              " '그거는 지금 입는 거예요',\n",
              " '흰색 같은 그런 거는 있나요?',\n",
              " '흰색은 위에 있어요',\n",
              " '이것도 괜찮지 않아요?',\n",
              " '이런 거는 사이즈가?',\n",
              " '프리사이즈입니다',\n",
              " '남방 종류는 없어요?',\n",
              " '남방은 지금 이거 하얀 거하고 빨간 거 있어요',\n",
              " '회색은 무슨 색이랑 잘 어울려요?',\n",
              " '회색은 거의 다 잘 어울려요',\n",
              " '여기는 다 프리사이즈예요?',\n",
              " '사이즈가 많이 안 나와요 나온다 하더라도 66 77 이렇게 나와요',\n",
              " '원피스는 어떤 게 예뻐요?',\n",
              " '원피스는 이런 시폰 예뻐요',\n",
              " '이게 시폰입니까?',\n",
              " '네 맞아요',\n",
              " '이런 시폰은 세탁은 어떻게 하나요?',\n",
              " '이쁘게 입으시려면 드라이하는 게 나아요',\n",
              " '이런 거는 원단이 뭡니까?',\n",
              " '프라다입니다',\n",
              " '코트는 얼마나 해요?',\n",
              " '98000원입니다',\n",
              " '나가면 또 들어오나요?',\n",
              " '들어올 겁니다',\n",
              " '이런 블라우스는 얼마예요?',\n",
              " '9만 8천 원이요',\n",
              " '좀 비싸네요 왜 그래요?',\n",
              " '원가가 비싼 제품이네요',\n",
              " '이거는 면입니까?',\n",
              " '네 맞아요',\n",
              " '세탁은 어떻게 해요?',\n",
              " '물 빨래하셔도 돼요',\n",
              " 'made in Korea네요?',\n",
              " '네 중국옷은 없을 거예요',\n",
              " '이거 브랜드가 빌리브입니까?',\n",
              " '네 맞습니다',\n",
              " '이런 거는 얼마라고요?',\n",
              " '88000원입니다',\n",
              " '원피스 종류도 있어요?',\n",
              " '지금 원피스는 없어요',\n",
              " '제가 입어도 어울리는 거 맞나요? 좀 안 어울리죠?',\n",
              " '바지가 조금 안 어울리는 것 같아요',\n",
              " '이 검은 조끼를 입으려면 안에 뭐를 입으면 좋을까요?',\n",
              " '엉덩이 하고 배만 가릴 수 있는 기장의 셔츠가 나을 거 같아요',\n",
              " '이런 거는 얼마예요?',\n",
              " '98000원이요',\n",
              " '티보다는 칼라 있는 게 어울릴까요?',\n",
              " '칼라 있는 것도 이뻐요',\n",
              " '조끼에다가 바지만 입으셔도 예쁜데 한 번 입어보시겠어요?',\n",
              " '가격은 이거보다 조금 낮은 거는 없어요?',\n",
              " '제일 낮은 건 이거 하고 노랑 색깔 58000원짜리 있어요',\n",
              " '색상으로 봤을 때는 이 색상이 제일 어울려 보이는데요?',\n",
              " '네 저도 그 색이 제일 좋은 거 같아요',\n",
              " '이거 사이즈 다 한 개예요?',\n",
              " '네 사이즈 하나예요',\n",
              " '이거 또 안 들어와요?',\n",
              " '다음 주에 들어와요',\n",
              " '제가 입을만한 옷 있을까요?',\n",
              " '뭐를 찾으십니까?',\n",
              " '이 조끼 안에 입을만한 옷이요',\n",
              " '남방 같은 거 어떠세요?',\n",
              " '점잖아 보인다',\n",
              " '네 이런 남방류 잘 입어지실거예요',\n",
              " '이제는 얇은 거만 나오나요?',\n",
              " '네',\n",
              " '그런 거는 얼마예요?',\n",
              " '이거 3만 원에 드릴게요',\n",
              " '이런 바지 없나요?',\n",
              " '있어요 그거는 75000원짜리입니다',\n",
              " '이런 남방은 얼마예요?',\n",
              " '45000원이요',\n",
              " '남방 컬러 종류는 어떤 게 있나요?',\n",
              " '주로 검은색 아니면 이 색이에요 다른 색깔은 없어요',\n",
              " '이런 거는 얼마예요?',\n",
              " '그거는 45000원이에요',\n",
              " '이런 거 가격 좀 잘해주세요',\n",
              " '싸게 드리는거에요',\n",
              " '이거는 사이즈는 한 가지입니까?',\n",
              " '네 그거는 사이즈 한 가지예요',\n",
              " '한 번 입어 보세요',\n",
              " '사이즈가 맞기는 한데요',\n",
              " '이런 흰 면바지는 얼마예요?',\n",
              " '38000원이요',\n",
              " '겨자색 저거는 얼마예요?',\n",
              " '3만 원이요',\n",
              " '겨울 옷 있어요?',\n",
              " '겨울 옷은 일부 있는 거 세일해드려요',\n",
              " '찾으시는 거 있어요?',\n",
              " '여기 옷은 브랜드는 아니죠?',\n",
              " '서울에서 물건이 들어와요',\n",
              " '이거는 다 봄 옷이다 그죠?',\n",
              " '네 그거는 봄 옷이에요',\n",
              " '이거는 스판이고요?',\n",
              " '정말 스판이에요',\n",
              " '이거는 겨울 거죠?',\n",
              " '네 맞아요',\n",
              " '손님 66 입으세요? 55 입으세요?',\n",
              " '어떤 사이즈가 맞을까요?',\n",
              " '골반이 좀 있으시니까 66 입으셔야 될 거 같아요',\n",
              " '얼마인데요?',\n",
              " '이거는 지금 도매가에 드려서 32000원이요',\n",
              " '한 번 입어볼게요',\n",
              " '네 입어보세요',\n",
              " '조금 더 큰 거 없어요?',\n",
              " '이거보다 크면 안 예뻐요',\n",
              " '이거랑 같이 신을 신발은 뭐 있어요?',\n",
              " '이런 신발 신으시면 좋겠습니다',\n",
              " '신발 35사이즈 신으세요?',\n",
              " '네',\n",
              " '이런 거는 얼마예요?',\n",
              " '4만 원이에요',\n",
              " '이거는 얼마인데요?',\n",
              " '그거는 3만 원입니다',\n",
              " '이거는 세탁은 어떻게 해요?',\n",
              " '그냥 손세탁하시면 돼요',\n",
              " '3만 원에 주시면 안 되나요?',\n",
              " '안됩니다',\n",
              " '그거 담아드려요?',\n",
              " '네',\n",
              " '이 제품은 할인 상품이기 때문에 현금으로 계산해 주세요',\n",
              " '현찰은 없어요',\n",
              " '그럼 이번만 카드로 계산해드릴게요',\n",
              " '네',\n",
              " '이거 원래 얼마예요?',\n",
              " '원래 가격은 45000원입니다',\n",
              " '니트 3만 8천 원이면 여기서 10% dc 된다 그죠?',\n",
              " '네 이거 10% 하면 3만 4천 원이요',\n",
              " '이런 거는 어떻게 관리해요?',\n",
              " '니트류는 드라이가 나아요',\n",
              " '이런 종류 좋아하는데 어떤 게 잘 나가요?',\n",
              " '이런 거는 봄에 검은색 바지와 같이 많이 입어요',\n",
              " '이거는 무슨 면인가요?',\n",
              " '이거는 니트예요',\n",
              " '색상은 이것뿐이에요?',\n",
              " '네 이것뿐이에요',\n",
              " '이런 꽃무늬는 어떠세요?',\n",
              " '이런거 얼마에요?',\n",
              " '그것도 세일하면 3만 2천 원요',\n",
              " '세일 제품은 이건 가요?',\n",
              " '네 니트류는 다 세일 들어가고 있어요',\n",
              " '현금으로 사면 또 싸게 돼요?',\n",
              " '현금하시면 천 원 정도 더 빼어드릴 수 있어요',\n",
              " '여기 근처에 atm기 있어요?',\n",
              " '네 그런데 수수료가 붙어요',\n",
              " '여기 몇 시까지 해요?',\n",
              " '9시까지 해요',\n",
              " '보통 몇 시부터 문 열고요?',\n",
              " '보통 한시 반이나 두시 사이에 열어요',\n",
              " '쉬는 날 있어요?',\n",
              " '금요일 날 쉬어요',\n",
              " '어떤 게 잘 나가요?',\n",
              " '다양하게 잘 나가요',\n",
              " '티 중에 저한테 어울릴 거 추천 좀 해주세요',\n",
              " '어떤 스타일 찾으세요?',\n",
              " '아기자기한 거 좋아하거든요',\n",
              " '아기자기한 거면 이런 거 어떠세요?',\n",
              " '그런 거 집에 많아요',\n",
              " '저 목티는 코랄 색인가요?',\n",
              " '약간 하늘색 같은 거예요',\n",
              " '저거 색상은 이거 한 개뿐이에요?',\n",
              " '저 디자인 하나밖에 안 남았어요',\n",
              " '가격이 얼마예요?',\n",
              " '2만 3천 원인데 지금 현금이나 계좌이체로 하시면 50% 세일돼요',\n",
              " '왜 이렇게 싸요?',\n",
              " '겨울옷은 지금 정리 중이어서 싸게 하고 있어요',\n",
              " '이거 한 번 입어볼 수 있나요?',\n",
              " '입는 거는 안되고 대보는 건 가능하세요',\n",
              " '조금 작아 보이네요 다른 사이즈 있나요?',\n",
              " '팔이 지금 가오리 핏이라서 짧아 보이시는 거예요',\n",
              " '목티 좀 두꺼운 거 젊은 스타일 없어요?',\n",
              " '그런 스타일은 없어요',\n",
              " '이런 보라색, 고동색은 가격대는 얼마 해요?',\n",
              " '가격이 다 다르긴 한데 다 세일가라서 만 원대 정도 해요',\n",
              " '아주 얇은 봄 옷도 있기는 있네요?',\n",
              " '네 봄 신상 새로 들어오고 있어요',\n",
              " '봄 신상은 가격대가 어떻게 돼요?',\n",
              " '이쪽은 세일 안 하는 제품들이에요',\n",
              " '여기는 몇 시까지 문 열어요?',\n",
              " '11시까지 합니다',\n",
              " '몇 시부터?',\n",
              " '11시 반부터 합니다',\n",
              " '쉬는 날 있어요?',\n",
              " '쉬는 날 없어요',\n",
              " '티 종류 조금 얇은 거 있나요?',\n",
              " '반팔 티 찾으시는 건가요?',\n",
              " '아뇨',\n",
              " '긴 팔로 찾으세요?',\n",
              " '네',\n",
              " '주로 어떤 게 잘 나가요?',\n",
              " '이런 게 입으면 칼라가 고급스러워서 잘 나가요',\n",
              " '색상이 이거 한 가지인가요?',\n",
              " '아니요 라임 검정 화이트 있어요',\n",
              " '이건 가격이 얼마예요?',\n",
              " '이거는 가격이 46200원이에요',\n",
              " '이 티셔츠는 어떤 바지랑 어울려요?',\n",
              " '청바지 반바지 긴바지 흰 바지 다 잘 어울립니다',\n",
              " '티셔츠는 못 입어보죠?',\n",
              " '입을 수는 있는데 조금 조심해서 입어주세요',\n",
              " '적립되는 카드나 할인되는 카드가 있나요?',\n",
              " '카드마다 다른데요 매장 자체적으로 5%까지 해드려요',\n",
              " '현금으로 구입하면 더 저렴한가요?',\n",
              " '아니요',\n",
              " '세일 상품 코너는 어디에요?',\n",
              " '여기하고 바깥쪽에 있어요',\n",
              " '조금 둘러볼게요',\n",
              " '천천히 보세요',\n",
              " '이 마이는 이 색상 하나뿐이죠?',\n",
              " '까만색하고 두 개 있는 거예요',\n",
              " '이거는 지금 이 가격에서 할인이 되는 거예요?',\n",
              " '원래는 27만 원인데 13만 5천 원으로 할인된 거예요',\n",
              " '사이즈는 원 사이즈죠?',\n",
              " '네 원 사이즈입니다',\n",
              " '여기 쉬는 날이 있어요?',\n",
              " '쉬는 날 없어요',\n",
              " '밖에 디스플레이 돼 있는 주황색 좀 두꺼운 거 얼마인가요?',\n",
              " '할인 들어가서 3만 원이요',\n",
              " '현금가?',\n",
              " '네 맞아요',\n",
              " '더 싸게는 안돼요? 2만 5천 원?',\n",
              " '안돼요',\n",
              " '저거는 색상이 몇 개?',\n",
              " '한 칼라 나와요',\n",
              " '세일 품목은 저 위에 있는 거예요?',\n",
              " '그 위에 있는 것들이 마지막 상품이라서 할인하는 것들이에요',\n",
              " '이거는 뭐랑 입으면 잘 어울려요?',\n",
              " '청바지와 제일 많이 입고 흰색 바지에도 어울립니다',\n",
              " '사이즈도 원 사이즈죠?',\n",
              " '네 맞아요',\n",
              " '여기 근처에 atm기 있어요?',\n",
              " 'atm기는 횡단보도 건너면 바로 있어요',\n",
              " '밖에 있는 거랑 이거랑은 디자인 좀 비슷한 건가요?',\n",
              " '비슷해요',\n",
              " '가격은 비슷해요?',\n",
              " '똑같아요 그것도 3만 원이에요',\n",
              " '이 돕바는 얼마예요?',\n",
              " '6만 3천 원이요',\n",
              " '드라이해줘야 되는 거죠? 물세탁은 전혀 안되죠?',\n",
              " '그렇죠 그런 외투들은 안돼요',\n",
              " '이거는 얼마예요?',\n",
              " '세일해서 3만 5천 원입니다',\n",
              " '몇 시까지 문 열어나예?',\n",
              " '9시까지요',\n",
              " '몇 시부터요?',\n",
              " '12시 반부터 해요',\n",
              " '일요일 날은 열어놔요?',\n",
              " '네 해요',\n",
              " '티 얼마예요?',\n",
              " '2만 5천 원에 갖고 가세요',\n",
              " '색상은 이거 하나밖에 없어요?',\n",
              " '흰 색깔하고 이거 있어요',\n",
              " '이거랑 비슷한 디자인 있어요?',\n",
              " '흰색 있어요',\n",
              " '이거는 어떤 거랑 어울려요?',\n",
              " '면바지랑 잘 어울려요',\n",
              " '흰 조끼 저거는 얼마예요?',\n",
              " '이건 2만 2천 원이에요',\n",
              " '소재가 뭐예요?',\n",
              " '그냥 솜이에요',\n",
              " '세탁은 어떻게 해요?',\n",
              " '세탁기에 세탁해도 돼요',\n",
              " '이거 검은색 없어요?',\n",
              " '없어요 겨울거는 다 나가서 골고루 없어요',\n",
              " '몇 시에 닫아요?',\n",
              " '6시 안쪽으로 가요',\n",
              " '일요일은 열어요?',\n",
              " '일요일은 안 열어요',\n",
              " '아침에는 몇 시에 문 여는데요?',\n",
              " '9시 반에서 10시 사이에 열어요',\n",
              " '여기 걸려있는 거는 다 세일 제품이에요?',\n",
              " '네 안에도 다 세일해요',\n",
              " '티 종류는 이쪽에 있는 거예요?',\n",
              " '네 여기도 있고 안에도 있어요',\n",
              " '잘 나가는 제품은 있나요?',\n",
              " '이렇게 다 잘 나가요',\n",
              " '여기 붙어있는 가격에 30% 하는 거예요?',\n",
              " '30%짜리도 있고 50%짜리도 있어요',\n",
              " '이거는 할인해요?',\n",
              " '여기는 할인 아니고요',\n",
              " '이게 사이즈가 다 작죠?',\n",
              " '아니요 맞습니다',\n",
              " '색상이 아이보리하고 빨간색?',\n",
              " '이렇게 세 가지 나와요',\n",
              " '이게 브랜드예요?',\n",
              " '네 라이온스라는 브랜드예요',\n",
              " '사이즈가 한 종류예요?',\n",
              " '네 티는 프리사이즈예요',\n",
              " '여기 세일 기간은 언제까지 해요?',\n",
              " '지금 물건이 있을 때까지 해요',\n",
              " '다 팔리면 다시 또 오는 거 아니에요?',\n",
              " '겨울 거는 이제 없어요 봄 상품 들어와요',\n",
              " '이거는 가격이 얼마예요?',\n",
              " '한 벌에 44500원이에요',\n",
              " '따로 사고 싶은데 따로는 구입이 안돼요?',\n",
              " '세트로만 팔아요',\n",
              " '재질이 뭐예요?',\n",
              " '폴리죠',\n",
              " '하늘하늘한 원피스 나왔어요?',\n",
              " '원피스는 저기 한 개 지금 있어요',\n",
              " '색상이 하나예요?',\n",
              " '블랙하고 흰색 두 가지 있어요',\n",
              " '현금으로 사면 좀 싸게 되나요?',\n",
              " '그런 거는 없어요 ',\n",
              " '할인되는 카드 없고?',\n",
              " '없어요',\n",
              " '여기 문 연지는 오래됐어요?',\n",
              " '한 6개월 넘었어요',\n",
              " '몇 시부터 몇 시까지 문 열어요?',\n",
              " '겨울에는 아침 10시부터 밤 10시 반까지 해요',\n",
              " '토요일 일요일은?',\n",
              " '안 쉬어요',\n",
              " '신발은 230은 따로 없죠?',\n",
              " '230은 부츠 있어요',\n",
              " '이거는 소재가 벨벳 같은데요?',\n",
              " '아니 세무예요',\n",
              " '이거는 얼마예요?',\n",
              " '할인해서 29700원이요',\n",
              " '원 사이즈로 나오죠?',\n",
              " '네 원 사이즈로 나와요',\n",
              " '이거 초록색 티 얼마 해요?',\n",
              " '한 5만 원 해요',\n",
              " '이거는 색상이 뭐 있어요?',\n",
              " '빨간색 있어요',\n",
              " '누구 선물하시게요?',\n",
              " '네',\n",
              " '체격 크세요?',\n",
              " '네 조금 크기는 한데',\n",
              " '이거는 가격이 얼마예요?',\n",
              " '이거는 4만 원이에요',\n",
              " '좀 잘 나가는 거 없어요?',\n",
              " '이게 제일 잘나갑니다',\n",
              " '이거 가격 얼마예요?',\n",
              " '5만 원입니다',\n",
              " '조끼 종류는 어떤 게 있어요?',\n",
              " '조끼는 있는데 좀 비싸요',\n",
              " '이거는 가격 얼마예요?',\n",
              " '이런 거는 7만 2천 원입니다 ',\n",
              " '이런 거는 색상이 이것뿐이에요?',\n",
              " '이거 하고 이 색 있어요',\n",
              " '바지가 얼마예요?',\n",
              " '바지 6만 원입니다',\n",
              " '현금으로 사면 싸게 해주나요?',\n",
              " '현금 사면 만 원 빼어드릴게요',\n",
              " '내일은 영업해요?',\n",
              " '내일은 문 닫아요',\n",
              " '이 바지도 가격이 똑같아요?',\n",
              " '더 비쌉니다',\n",
              " '오늘 몇 시까지 열고 계시는데요?',\n",
              " '6시 반 되면 갑니다',\n",
              " '이거 검은 티 얼마예요?',\n",
              " '이거 3만 2천 원인데 세일해서 2만 5천 원요',\n",
              " '색상은 다른 거 없어요?',\n",
              " '네 없어요',\n",
              " '소재가 뭐예요? 밍크예요?',\n",
              " '아뇨 페이크 퍼인데요 동물 털 아니고 극세사 같은 합성섬유입니다',\n",
              " '페이크 퍼도 따뜻하죠?',\n",
              " '네 많이 따뜻해요',\n",
              " '티셔츠 종류 여기 있는 게 다죠?',\n",
              " '네 맞습니다',\n",
              " '사이즈가 작은 것 같은데',\n",
              " '사이즈는 다 있어요',\n",
              " '얇은 티는 아직 안 나왔나요?',\n",
              " '얇은 티 안에 있어요',\n",
              " '소재는 뭐예요?',\n",
              " '면 100%라서 되게 좋아요',\n",
              " '색깔은 이거 하나?',\n",
              " '네 하나예요',\n",
              " '이거는 가격이 얼마예요?',\n",
              " '3만 2천 원입니다',\n",
              " '헌금으로 사도 마찬가지예요?',\n",
              " '현금하시면 3만 원만 주세요',\n",
              " '세탁은 물세탁 해요?',\n",
              " '네 세탁기로 물세탁 하시면 돼요 망에 넣으면 좋고요',\n",
              " '연세 드신 분 입으시는 내의 있나요?',\n",
              " '있어요',\n",
              " '가격대는 얼마 정도에 살 수 있어요?',\n",
              " '사이즈 몇 짜리 보시는데요?',\n",
              " '105 정도요',\n",
              " '이게 신축성이 있어서 괜찮을 것 같아요',\n",
              " '따뜻하겠네요',\n",
              " '가격대는 다양해요',\n",
              " '색상은 검은색뿐이에요?',\n",
              " '네 검은색만 있어요',\n",
              " '보라색 이거는 얼마예요?',\n",
              " '3만 5000원이에요',\n",
              " '사이즈 작으면 바꾸러 와도 되나요?',\n",
              " '바꾸러 오시는 거 괜찮아요',\n",
              " '이거 보라색밖에 없어요?',\n",
              " '이거는 보라색만 있어요',\n",
              " '저 핑크색 원피스 실내복은 얼마예요?',\n",
              " '이것도 한 3만 5000원 합니다',\n",
              " '색상은 이거와 연한 핑크 두 가지예요??',\n",
              " '이거밖에 없어요',\n",
              " '따뜻한 여성용 내의도 하나요?',\n",
              " '기모도 돼 있는 거 찾으시는 거예요?',\n",
              " '네 기모요',\n",
              " '몇 호 입으시는데요?',\n",
              " '105 사이즈',\n",
              " '여자 105 사이즈는 없어요',\n",
              " '내의 105 사이즈는 안 나와예?',\n",
              " '남자는 105 여자는 100까지 나와요',\n",
              " '발열 내의 이거는 100도 큰데 어떠세요?',\n",
              " '색상은 이거 검은색뿐이에요?',\n",
              " '발열 내의는 이거 하나밖에 없어요',\n",
              " '이 땡땡이는 얼마예요?',\n",
              " '1만 2000원입니다',\n",
              " '이거는 윗도리 하나예요 아니면 세트인가요?',\n",
              " '바지하고 한 벌인데 이거는 프리사이즈예요',\n",
              " '요거는 엑스라지 없어요?',\n",
              " '그게 엑스라지가 없어요',\n",
              " '색상도 한 종류밖에 없죠?',\n",
              " '네 종류 하나에요',\n",
              " '덩치가 많이 큰데 큰 건 없죠?',\n",
              " '많이 크면 남자 거 105를 입어야 돼요',\n",
              " '티셔츠 조금 얇은 거는 어디에 있어요?',\n",
              " '여기 없어요 지금 아직은 안 가져와요',\n",
              " '여기 오픈한 지가 얼마 안 됐어요?',\n",
              " '10년 됐어요',\n",
              " '이 물건은 어디서 오는 거예요?',\n",
              " '무역회사요',\n",
              " '아이보리색 티는 얼마예요?',\n",
              " '거기는 다 3000원이요',\n",
              " '요거는 색상 다른 거 없나요?',\n",
              " '거기 두 줄 걸려 있는 게 다입니다',\n",
              " '쫄바지 고무 바지로 된 거는 있어예?',\n",
              " '여기하고 거기 고무로 된 거 많아요',\n",
              " '이 바지는 얼마예요?',\n",
              " '3000원이요',\n",
              " '여기는 문을 몇 시부터 몇 시까지 열어예?',\n",
              " '10시부터 한 7시 40분까지 합니다',\n",
              " '일요일 날은 해예?',\n",
              " '합니다',\n",
              " '여고생이 입을 수 있는 면 티셔츠 종류 있어요?',\n",
              " '여기에 반팔 티셔츠 있어요',\n",
              " '남녀 공용인가 보네요?',\n",
              " '네 남녀 공용이에요',\n",
              " '순면인가요?',\n",
              " '네 맞습니다',\n",
              " '사이즈가 어떻게 나와요 95 90 이렇게 나와요?',\n",
              " '스몰 사이즈가 95예요',\n",
              " '크게 나오네요?',\n",
              " '네 좀 크게 나와요',\n",
              " '가격이 얼마 정도 돼요?',\n",
              " '7만 3000원이요',\n",
              " '롱 원피스 여기에 있는 거 다 맞죠?',\n",
              " '그쪽은 가을거 세일하는 제품들이고 봄 신상품은 안내 쪽에 있어요',\n",
              " '이거는 봄 신상품 아니에요?',\n",
              " '네 그거는 신상품 아니에요',\n",
              " '어디 저쪽이에요?',\n",
              " '네 맞아요',\n",
              " '나이 든 사람이 입어도 돼요?',\n",
              " '고객님보다 나이 훨씬 많으신 분도 많으신데요',\n",
              " '리본 달린 면이 앞인가요?',\n",
              " '네 그게 앞이에요',\n",
              " '허리 조이는 건 없네?',\n",
              " '네 그거는 엘라인으로 입는 스타일이에요',\n",
              " '어떤 스타일이 많이 나갔어요?',\n",
              " '라인 안 잡히는 것을 고객님들이 많이 찾으세요',\n",
              " '카디건이랑 입는 게 낫다 그죠?',\n",
              " '네 카디건 입으셔도 되고 이렇게 니트와 레이어드하셔도 돼요',\n",
              " '이 안에 바지도 입을 수 있죠?',\n",
              " '네 청바지 입어도 돼요',\n",
              " '거울에 한 번 비춰봐도 돼요?',\n",
              " '네 거울 앞쪽에도 있고 안에도 있어요',\n",
              " '이거 많이 파여 있죠?',\n",
              " '앞에 많이 안 파여요',\n",
              " '안에 비치지는 않나요?',\n",
              " '안에 안감 있어요',\n",
              " '지금 세일해서 얼마인가요?',\n",
              " '19만 5300원요 30프로 세일 들어갔어요',\n",
              " '한 여름 되기 전까지 입어도 되겠네요?',\n",
              " '네 초여름까지 입으세요',\n",
              " '이쁘긴 한데 가격대가 조금 비싸요',\n",
              " '세일 많이 들어간거에요',\n",
              " '남자들 거 트렌치코트 종류 있어요?',\n",
              " '이쪽에 있어요',\n",
              " '이게 신상품이에요?',\n",
              " '네 신상품이에요',\n",
              " '키가 72인데 이거는 길이가 어느 정도 와요?',\n",
              " '허벅지 끝까지 충분할 거 같아요',\n",
              " '네이비 색상인가요?',\n",
              " '네 네이비입니다',\n",
              " '스판이 조금 안되는 거 같네요?',\n",
              " '대신 주름도 덜 가고 관리하기 편하실 거예요',\n",
              " '키가 72에 몸무게 한 60이면 어느 정도 입어요?',\n",
              " '엠 입으시면 돼요',\n",
              " '지금 세일 기간인가요?',\n",
              " '이 상품은 세일 해당 안 돼요',\n",
              " '신상품이라서 할인 안 되나요?',\n",
              " '네 맞아요',\n",
              " '사가지고 반품이나 교환이 되나요?',\n",
              " '일주일 이내에 오시면 돼요 교환은 다른 매장에서도 가능하고요',\n",
              " '이게 나이 대가 어떻게 입어요?',\n",
              " '20대부터 40대까지 다양하게 입어요',\n",
              " '50대는 입기 좀 그렇겠죠?',\n",
              " '요즘 젊게 입으시는 분들이 많으니까 괜찮아요',\n",
              " '이거 20살 여학생 입을 수 있어요?',\n",
              " '네 가능합니다',\n",
              " '신상 예쁜 거 있어요?',\n",
              " '지금 나와 있는 게 다 봄 신상입니다',\n",
              " '이거는 좀 두꺼워 보이는데요?',\n",
              " '네 그런 거 말고는 다 신상이에요',\n",
              " '옷이 조금 무거운 것 같은데',\n",
              " '입으시면 많이 무겁지는 않아요',\n",
              " '밝은 색상보다는 이게 나은가요?',\n",
              " '베이지를 더 많이 사 가세요',\n",
              " '이게 지금 인기가 있나 보네요?',\n",
              " '네 봄 신상으로 나온 거라서요',\n",
              " '관리는 어떻게 해야 돼요?',\n",
              " '세탁소에 세탁 맡기는 게 제일 좋아요',\n",
              " '구김이나 활동성은 어떤가요?',\n",
              " '불편하지는 않아요',\n",
              " '소매 길이 수선 같은 거는 여기서 해주나요?',\n",
              " '네 다만 본인 부담이 조금 들어갈 수가 있어요',\n",
              " '여학생들도 많이 입나요?',\n",
              " '대학생들이 주로 입어요',\n",
              " '원피스 종류 있어요?',\n",
              " '원피스는 없어요',\n",
              " '이거 신상인가 보다 그죠?',\n",
              " '네 간절기용이에요',\n",
              " '완전 흰색은 아니다 그죠?',\n",
              " '크림색 아이보리예요',\n",
              " '이게 지금 입으신 거랑 천이 똑같은 건가요?',\n",
              " '이거는 겨울 거라 좀 다르죠',\n",
              " '이거 밑에는 청바지 같은 거 입어도 되고 롱치마 입어도 되겠죠?',\n",
              " '네 요즘 많이 입는 긴 주름치마과 같이 입으면 돼요',\n",
              " '안에 옷이 비치고 이런 건 아닌가요?',\n",
              " '네 많이 비치지는 않을 거예요',\n",
              " '이거는 얼마 정도 해요?',\n",
              " '5만 8천 원입니다',\n",
              " '원피스 종류 있어요?',\n",
              " '그쪽 다 원피스예요',\n",
              " '이건 날씬해야지 입을 수 있겠죠?',\n",
              " '타이트하긴 해요',\n",
              " '이거 앞에 좀 많이 파인 거 아닌가요?',\n",
              " '네 싫으시면 여기 단추 다시면 돼요',\n",
              " '이게 구김은 없는 편인가요?',\n",
              " '구김 잘 없어요',\n",
              " '길이는 어느 정도 돼요?',\n",
              " '거울 한 번 봐 보세요',\n",
              " '이거 완전 초여름이 될 때까지 입어도 되겠네요?',\n",
              " '네',\n",
              " '결제는 카드 다 돼요?',\n",
              " '카드도 되고 현금도 되는데 현금은 할인해드려요',\n",
              " '이거는 얼마 정도 해요?',\n",
              " '카드하면 4만 6000원 현금하면 4만 2000원입니다',\n",
              " '이거는 앞뒤 길이가 다르네요 그죠?',\n",
              " '앞부분은 살짝 언밸런스라서 그래요',\n",
              " '반품 같은 거는 되나요?',\n",
              " '교환은 가능하신데 환불은 안 돼요',\n",
              " '색상이 다른 것도 있나요?',\n",
              " '아이보리하고 핑크 있어요',\n",
              " '이거 비침 있나요?',\n",
              " '네 그거는 비침 있어요',\n",
              " '지금 다 신상으로 나온 거다 그죠?',\n",
              " '네 봄 신상이에요',\n",
              " '여기 몇 시까지 해요?',\n",
              " '11시까지 해요',\n",
              " '이거 원피스인가요?',\n",
              " '네 원피스예요',\n",
              " '블루 색상에 가깝네요 그죠?',\n",
              " '네 맞아요',\n",
              " '구김은 없겠다 그죠?',\n",
              " '구김은 오래 앉으면 생기긴 하죠',\n",
              " '허리 졸임은 없다 그죠?',\n",
              " '네 그거는 딱 떨어지는 스타일이라 따로 벨트를 하셔야 해요',\n",
              " '시폰인가요?',\n",
              " '네 맞습니다',\n",
              " '팔 말고 다른 곳은 안 비친다 그죠?',\n",
              " '안에 안감이 있으니까 다른 곳은 안 비쳐요',\n",
              " '거울 한 번 비춰 봐볼게요',\n",
              " '안쪽에 거울 있어요',\n",
              " '길이는 무릎 아래 여기 종아리까지 오네요?',\n",
              " '네 종아리까지 와요',\n",
              " '안에 청바지도 입어도 되고요?',\n",
              " '네 청바지 스키니 바지 그런 거 입으시면 따뜻해요',\n",
              " '목폴라도 같이 입어요?',\n",
              " '히트텍이나 목폴라 같은 거 입고 입으셔도 돼요',\n",
              " '분홍색 티셔츠는 지금 얼마예요?',\n",
              " '현금하면 3만 원까지 해줄게요',\n",
              " '카드는 하면 얼만데요?',\n",
              " '카드는 3만 5천 원요',\n",
              " '티셔츠는 못 입어 보죠?',\n",
              " '입어도 돼요 입어보세요',\n",
              " '이거 길이는 어느 정도 와요? 뒤에 길이가 조금 틀리고 언밸런스한데요?',\n",
              " '엉덩이 다 덮이지는 않아고 살짝 덮여요',\n",
              " '소재가 면이에요? ',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9-MoDpEffCH",
        "outputId": "89735b5c-a1b1-4907-d0f6-2a4fe09f7a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "customer_arr[8]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'좀 크네 또 안 들어와요?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us6EdIoufUEV",
        "outputId": "f817723c-1bfa-4023-c2a7-6711b1d2bfc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wear_data[wear_data.SENTENCE.values. == customer_arr[8].lstrip()].CATEGORY"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SPEAKER</th>\n",
              "      <th>SENTENCE</th>\n",
              "      <th>DATAID</th>\n",
              "      <th>DOMAINID</th>\n",
              "      <th>DOMAIN</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>SPEAKERID</th>\n",
              "      <th>SENTENCEID</th>\n",
              "      <th>MAIN</th>\n",
              "      <th>SUB</th>\n",
              "      <th>QA</th>\n",
              "      <th>QACNCT</th>\n",
              "      <th>MQ</th>\n",
              "      <th>SQ</th>\n",
              "      <th>UA</th>\n",
              "      <th>SA</th>\n",
              "      <th>개체명</th>\n",
              "      <th>용어사전</th>\n",
              "      <th>지식베이스</th>\n",
              "      <th>Unnamed: 19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>고객</td>\n",
              "      <td>230이요</td>\n",
              "      <td>박은영_액세서리_5</td>\n",
              "      <td>B</td>\n",
              "      <td>의복의류점</td>\n",
              "      <td>신발</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>종류별신발제품문의요청</td>\n",
              "      <td>사이즈</td>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>230이요</td>\n",
              "      <td>NaN</td>\n",
              "      <td>230</td>\n",
              "      <td>NaN</td>\n",
              "      <td>230/사이즈</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>고객</td>\n",
              "      <td>네 봄이니까 편하게 신을 수 있는 거</td>\n",
              "      <td>박은영_액세서리_5</td>\n",
              "      <td>B</td>\n",
              "      <td>의복의류점</td>\n",
              "      <td>신발</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>착화감</td>\n",
              "      <td>제품문의</td>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>네 봄이니까 편하게 신을 수 있는 거</td>\n",
              "      <td>NaN</td>\n",
              "      <td>봄</td>\n",
              "      <td>NaN</td>\n",
              "      <td>봄/계절</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>고객</td>\n",
              "      <td>굽 좀 높은 거 없나요?</td>\n",
              "      <td>박은영_액세서리_5</td>\n",
              "      <td>B</td>\n",
              "      <td>의복의류점</td>\n",
              "      <td>신발</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>굽높이문의</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>NaN</td>\n",
              "      <td>굽 좀 높은 거 없나요?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>굽</td>\n",
              "      <td>NaN</td>\n",
              "      <td>굽/부분</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>고객</td>\n",
              "      <td>언제 들어와요?</td>\n",
              "      <td>박은영_액세서리_5</td>\n",
              "      <td>B</td>\n",
              "      <td>의복의류점</td>\n",
              "      <td>신발</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>재입고문의</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>NaN</td>\n",
              "      <td>언제 들어와요?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>언제</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>고객</td>\n",
              "      <td>이거는 가죽이에요?</td>\n",
              "      <td>박은영_액세서리_5</td>\n",
              "      <td>B</td>\n",
              "      <td>의복의류점</td>\n",
              "      <td>신발</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>소재문의</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>NaN</td>\n",
              "      <td>이거는 가죽이에요?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>이거, 가죽</td>\n",
              "      <td>NaN</td>\n",
              "      <td>가죽/소재</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15386</th>\n",
              "      <td>고객</td>\n",
              "      <td>포인트 적립되죠?</td>\n",
              "      <td>생성</td>\n",
              "      <td>B</td>\n",
              "      <td>의복의류점</td>\n",
              "      <td>신발</td>\n",
              "      <td>1</td>\n",
              "      <td>487</td>\n",
              "      <td>포인트적립문의</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>NaN</td>\n",
              "      <td>포인트 적립되죠?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15464</th>\n",
              "      <td>고객</td>\n",
              "      <td>어디에 있나요?</td>\n",
              "      <td>생성</td>\n",
              "      <td>B</td>\n",
              "      <td>의복의류점</td>\n",
              "      <td>신발</td>\n",
              "      <td>1</td>\n",
              "      <td>565</td>\n",
              "      <td>제품위치문의</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>NaN</td>\n",
              "      <td>어디에 있나요?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15605</th>\n",
              "      <td>고객</td>\n",
              "      <td>운동화 있나요?</td>\n",
              "      <td>생성</td>\n",
              "      <td>B</td>\n",
              "      <td>의복의류점</td>\n",
              "      <td>신발</td>\n",
              "      <td>1</td>\n",
              "      <td>706</td>\n",
              "      <td>종류별신발제품문의/요청</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>NaN</td>\n",
              "      <td>운동화 있나요?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15672</th>\n",
              "      <td>고객</td>\n",
              "      <td>이거 국산이에요?</td>\n",
              "      <td>생성</td>\n",
              "      <td>B</td>\n",
              "      <td>의복의류점</td>\n",
              "      <td>액세서리</td>\n",
              "      <td>1</td>\n",
              "      <td>773</td>\n",
              "      <td>제품제작한나라문의</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>NaN</td>\n",
              "      <td>이거 국산이에요?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15742</th>\n",
              "      <td>고객</td>\n",
              "      <td>현금영수증 가능하죠?</td>\n",
              "      <td>생성</td>\n",
              "      <td>B</td>\n",
              "      <td>의복의류점</td>\n",
              "      <td>액세서리</td>\n",
              "      <td>1</td>\n",
              "      <td>843</td>\n",
              "      <td>현금영수증발행요청</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>NaN</td>\n",
              "      <td>현금영수증 가능하죠?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7796 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      SPEAKER              SENTENCE      DATAID  ... 용어사전    지식베이스 Unnamed: 19\n",
              "3          고객                 230이요  박은영_액세서리_5  ...  NaN  230/사이즈         NaN\n",
              "5          고객  네 봄이니까 편하게 신을 수 있는 거  박은영_액세서리_5  ...  NaN     봄/계절         NaN\n",
              "7          고객         굽 좀 높은 거 없나요?  박은영_액세서리_5  ...  NaN     굽/부분         NaN\n",
              "9          고객              언제 들어와요?  박은영_액세서리_5  ...  NaN      NaN         NaN\n",
              "11         고객            이거는 가죽이에요?  박은영_액세서리_5  ...  NaN    가죽/소재         NaN\n",
              "...       ...                   ...         ...  ...  ...      ...         ...\n",
              "15386      고객             포인트 적립되죠?          생성  ...  NaN      NaN         NaN\n",
              "15464      고객              어디에 있나요?          생성  ...  NaN      NaN         NaN\n",
              "15605      고객              운동화 있나요?          생성  ...  NaN      NaN         NaN\n",
              "15672      고객             이거 국산이에요?          생성  ...  NaN      NaN         NaN\n",
              "15742      고객           현금영수증 가능하죠?          생성  ...  NaN      NaN         NaN\n",
              "\n",
              "[7796 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlclNObqaNcw",
        "outputId": "1f62f414-aa1d-4480-dcad-d5eb0ba51242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "source": [
        "for i in range(len(store_arr)):\n",
        "    print(i)\n",
        "    max(wear_data[wear_data.SENTENCE == customer_arr[i].lstrip()].CATEGORY.tolist())"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-8c13a9457a5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwear_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwear_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSENTENCE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcustomer_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCATEGORY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DPZ93dlYVyO",
        "outputId": "e83cfe9b-b8ff-428c-ed96-8f9541893a17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "faqs[10:15]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['11',\n",
              "  '가격이 얼마예요?',\n",
              "  '이 종류는 2만 원이고 이 종류는 3만 8천 원이에요',\n",
              "  '가방',\n",
              "  '의류',\n",
              "  '의류',\n",
              "  '의류',\n",
              "  '신발',\n",
              "  '신발',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의'],\n",
              " ['12', '가죽으로 된 거는 없어요?', '가죽은 없고 레자만 있어요', '가방', '소재를제시한제품문의'],\n",
              " ['13', '레자는 얼마예요?', '5만 5천 원요', '가방', '제품가격문의'],\n",
              " ['14', '이거는 천이죠?', '네 맞아요', '가방', '가방소재문의'],\n",
              " ['15',\n",
              "  '이건 얼마예요?',\n",
              "  '그것도 5만 5천 원요',\n",
              "  '가방',\n",
              "  '액세서리',\n",
              "  '액세서리',\n",
              "  '액세서리',\n",
              "  '액세서리',\n",
              "  '의류',\n",
              "  '신발',\n",
              "  '신발',\n",
              "  '가방',\n",
              "  '의류',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의',\n",
              "  '제품가격문의']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wrAk38SX6Eq",
        "outputId": "315ad90e-33bf-4bf1-f66b-c5071fe0633f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wear_data[wear_data.SENTENCE == customer_arr[0].lstrip()].CATEGORY.tolist()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['신발']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOePT2kUWVQz",
        "outputId": "dd8b8bf1-2eea-46cb-dd22-bc6684c71d8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(faqs)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O__JUR29TBUD",
        "outputId": "7c86dfc3-3481-4423-f75a-9652efdd5ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "arr"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['신발은 여기 있는 게 다예요?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLNSiqcHM4WY",
        "outputId": "a2998f69-0309-4dac-b127-88ea8a46de0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "prev = \"고객\"\n",
        "store_arr = []\n",
        "customer_arr = []\n",
        "store_stc = \"\"\n",
        "customer_stc = \"\"\n",
        "\n",
        "for i in range(wear_data.shape[0]):\n",
        "    if (prev == wear_data.iloc[i].SPEAKER):\n",
        "        if prev == \"점원\":\n",
        "             store_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "        else : \n",
        "             customer_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "            \n",
        "    elif prev == \"점원\":\n",
        "        store_arr.append(store_stc)\n",
        "        customer_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"고객\"\n",
        "    else :\n",
        "        customer_arr.append(customer_stc)\n",
        "        store_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"점원\"\n",
        "faqs = []\n",
        "\n",
        "for i in range(len(store_arr)):\n",
        "    faqs_tmp =[]\n",
        "    faqs_tmp.append(str(i+1))\n",
        "    faqs_tmp.append(customer_arr[i])\n",
        "    faqs_tmp.append(store_arr[i])\n",
        "\n",
        "    faqs.append(faqs_tmp)\n",
        "print(len(store_arr))\n",
        "print(len(customer_arr))\n",
        "print(store_arr[-1])\n",
        "print(customer_arr[-1]) # 자료 상에서 이후에는 계속 고객의 물음만 계속된다. 코드 레벨에서 이 부분은 빼게 구현했다. (stc는 만들어지지만 arr에 append 안하게 된다.)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7301\n",
            "7301\n",
            "요즘 파스텔 톤이 유행이에요\n",
            "요즘 유행하는 색깔이 뭐예요?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNvig2FMzjXj",
        "outputId": "d79c333b-76aa-4327-e47b-d4ce59f65de8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "question = []\n",
        "answer = []\n",
        "\n",
        "for Q in customer_arr:\n",
        "    question.append(Q.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "for A in store_arr:\n",
        "    answer.append(A.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "len(question), len(answer)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7301, 7301)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbivSckMydzN"
      },
      "source": [
        "# 형태소분석 함수\n",
        "def pos_tag(sentences):\n",
        "    \n",
        "    # KoNLPy 형태소분석기 설정\n",
        "    tagger = Okt()\n",
        "    \n",
        "    # 문장 품사 변수 초기화\n",
        "    sentences_pos = []\n",
        "    \n",
        "    # 모든 문장 반복\n",
        "    for sentence in sentences:\n",
        "        # [\\\"':;~()] 특수기호 제거\n",
        "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
        "        \n",
        "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
        "        sentence = \" \".join(tagger.morphs(sentence))\n",
        "        sentences_pos.append(sentence)\n",
        "        \n",
        "    return sentences_pos"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seqSNWcydzP",
        "outputId": "e6b8d300-164a-40cb-c6bd-f2ad4558a885",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 형태소분석 수행\n",
        "question = pos_tag(question)\n",
        "answer = pos_tag(answer)\n",
        "\n",
        "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
        "for i in range(5):\n",
        "    print('Q : ' + question[i])\n",
        "    print('A : ' + answer[i])\n",
        "    print()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q : 신발 은 여기 있는 게 다예 요 ?\n",
            "A : 네 성인 이나 아동 다 있어요 발 사이즈 몇 신으세요 ?\n",
            "\n",
            "Q : 230 이요\n",
            "A : 편하게 신 을 수 있는 거 찾으세요 ?\n",
            "\n",
            "Q : 네 봄 이니까 편하게 신 을 수 있는 거\n",
            "A : 이런 건 어떠세요 ? 이런 거도 신발 무척 편하거든요\n",
            "\n",
            "Q : 굽 좀 높은 거 없나요 ?\n",
            "A : 봄 상품 은 아직 어른 제품 이 많이 안 나왔습니다\n",
            "\n",
            "Q : 언제 들어와요 ?\n",
            "A : 이번 주 지나면 들어올 거 예요\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrnct_nzydzR"
      },
      "source": [
        "# 질문과 대답 문장들을 하나로 합침\n",
        "sentences = []\n",
        "sentences.extend(question)\n",
        "sentences.extend(answer)\n",
        "\n",
        "words = []\n",
        "\n",
        "# 단어들의 배열 생성\n",
        "for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "        words.append(word)\n",
        "\n",
        "# 길이가 0인 단어는 삭제\n",
        "words = [word for word in words if len(word) > 0]\n",
        "\n",
        "# 중복된 단어 삭제\n",
        "words = list(set(words))\n",
        "\n",
        "# 제일 앞에 태그 단어 삽입\n",
        "words[:0] = [PAD, STA, END, OOV]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE9ZhJpEy_rT",
        "outputId": "5ec331ee-8a14-40fb-fb52-fdd136e69276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "VOCAB_SIZE = len(words)\n",
        "print(\"손님과 점원의 말에서 사용된 총 단어의 수 :\",len(words))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "손님과 점원의 말에서 사용된 총 단어의 수 : 6409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkvyOnSvydzX"
      },
      "source": [
        "# 단어와 인덱스의 딕셔너리 생성\n",
        "word_to_index = {word: index for index, word in enumerate(words)}\n",
        "index_to_word = {index: word for index, word in enumerate(words)}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfoTztrvydzc"
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "def convert_text_to_index(sentences, vocabulary, type): \n",
        "    \n",
        "    sentences_index = []\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for sentence in sentences:\n",
        "        sentence_index = []\n",
        "        \n",
        "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
        "        if type == DECODER_INPUT:\n",
        "            sentence_index.extend([vocabulary[STA]])\n",
        "        \n",
        "        # 문장의 단어들을 띄어쓰기로 분리\n",
        "        for word in sentence.split():\n",
        "            if vocabulary.get(word) is not None:\n",
        "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[word]])\n",
        "            else:\n",
        "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "        # 최대 길이 검사\n",
        "        if type == DECODER_TARGET:\n",
        "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
        "            if len(sentence_index) >= max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
        "            else:\n",
        "                sentence_index += [vocabulary[END]]\n",
        "        else:\n",
        "            if len(sentence_index) > max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences]\n",
        "            \n",
        "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "        \n",
        "        # 문장의 인덱스 배열을 추가\n",
        "        sentences_index.append(sentence_index)\n",
        "\n",
        "    return np.asarray(sentences_index)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zezFPTvcydzf",
        "outputId": "8b1a00af-14b7-4a8b-d05a-68a7e1713dd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 인코더 입력 인덱스 변환\n",
        "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
        "\n",
        "# 첫 번째 인코더 입력 출력 (신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_encoder[0]\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4633, 4930, 2770,  696, 5080, 6196,  589, 5047,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmql1Lf_ydzh",
        "outputId": "ce7f4136-2605-4b8e-897c-fb328382244e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 입력 인덱스 변환\n",
        "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (<START> 신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_decoder[0]\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,  752, 4835, 1188, 4335,  944, 5157, 6234, 5145,  126, 3812,\n",
              "       5047,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIhDbaLydzk",
        "outputId": "d0cf1e07-1328-43dd-f4c6-a79d12512c38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 목표 인덱스 변환\n",
        "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (신발 은 여기 있는 게 다예 요 <END>)\n",
        "print(question[0])\n",
        "y_decoder[0]\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 752, 4835, 1188, 4335,  944, 5157, 6234, 5145,  126, 3812, 5047,\n",
              "          2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsf4tJl61Xi9"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsxmXWS41XVd"
      },
      "source": [
        "# decoder inputs use the previous target as input\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': x_encoder,\n",
        "        'dec_inputs': x_decoder\n",
        "    },\n",
        "    {\n",
        "        'outputs': y_decoder\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxXCQWvw2jwx"
      },
      "source": [
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH-k-kk_1_Vu"
      },
      "source": [
        "## scaled dot product Attention\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True) # QK^T\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth) #  QK^T / sqrt(d_k)\n",
        "\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9) # zero padding token softmax 결과가 0이 나오도록\n",
        "  \n",
        "  attention_weights = tf.nn.softmax(logits, axis = -1) # softmax(QK^T / sqrt(d_k))\n",
        "\n",
        "  output = tf.matmul(attention_weights, value) # softmax(QK^T / sqrt(d_k)) * V\n",
        "\n",
        "  return output"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7orcKMr13xY8"
      },
      "source": [
        "## multi-head attention\n",
        "## each head need (scaled_dot_product_attention)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0 # 128,8\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "  \n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(inputs, shape=(batch_size,-1,self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3]) ##????\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    #linear\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    #split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    #scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    #concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "\n",
        "    #final linear\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmlW0oi89nEC"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37sh3f8P-JUB",
        "outputId": "5d4b110c-d2a8-4939-c847-0538a01a5704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W7ld50z3vT2"
      },
      "source": [
        "# it handle mask future tokens in a sequence used decoder. and mask pad tokens\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W25teKwt_F80",
        "outputId": "4fa8dfce-eb76-4a76-a12f-45d59bbeeda2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLhXEIJgASo3"
      },
      "source": [
        "Positional encoding\n",
        "\n",
        "since we don't use any rnn, cnn, positional encoding give model position information of words in sentence.\n",
        "\n",
        "positional encoding vector is added to embedding vector\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7s19-x3_Hpq"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "  \n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles #pos/10000^(2i/d_model)\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position = tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model = d_model)\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLiumNZZDZGY"
      },
      "source": [
        "### Encoder Layer\n",
        "1. Multi-head attention (with padding mask)\n",
        "2. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oarRWUMLDYnC"
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query':inputs,\n",
        "          'key':inputs,\n",
        "          'value':inputs,\n",
        "          'mask':padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3rO9IcDHGE5"
      },
      "source": [
        "### Encoder\n",
        "1. Input Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` encoder layers\n",
        "\n",
        "Embedding + positional encoding : input\n",
        "\n",
        "going encoder layers.\n",
        "\n",
        "output going decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOwoi2_jHvbA"
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)#??왜 vocab_size가 들어가지?\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, padding_mask], outputs = outputs, name=name)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8XHH5dpJr-G"
      },
      "source": [
        "### Decoder Layer\n",
        "1. Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2. Multi-head attention (with padding mask). `value` and `key` is from encoder output. `query` is from Multi-head attention layer output\n",
        "3. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtAfKdk-JrxK"
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name=\"padding_mask\")\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query' : inputs,\n",
        "          'key' : inputs,\n",
        "          'value' : inputs,\n",
        "          'mask' : look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query' : attention1,\n",
        "          'key' : enc_outputs,\n",
        "          'value' : enc_outputs,\n",
        "          'mask' : padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnBSBcm1NAYv"
      },
      "source": [
        "### Decoder\n",
        "1. output Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` decoder layers\n",
        "\n",
        "Embedding + positional encoding : input (target)\n",
        "\n",
        "going decoder layers.\n",
        "\n",
        "output going final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnA-8FEAOT4F"
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"decoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name='padding_mask')\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"decoder_layer_{}\".format(i),\n",
        "    )(inputs = [outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-vmtqKQjhf"
      },
      "source": [
        "### Transformer\n",
        "1. encoder\n",
        "2. decoder\n",
        "3. final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEMfL5SFQqr4"
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"enc_padding_mask\")(inputs)\n",
        "  \n",
        "  #mask future tokens for decoder inputs at 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1,None,None),\n",
        "      name=\"look_ahead_mask\")(dec_inputs)\n",
        "  \n",
        "  #mask encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"dec_padding_mask\")(inputs)\n",
        "  \n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A44_Bc6RHJ3c"
      },
      "source": [
        "## Transformer for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9fUGKCwJS9J"
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7KTHsUdHQGm"
      },
      "source": [
        "class MultiHeadSelfAttention_classification(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super(MultiHeadSelfAttention_classification, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w25FGb6kHVxq"
      },
      "source": [
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention_classification(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khZdXSThHaTr"
      },
      "source": [
        "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvW0OXzJIC2C"
      },
      "source": [
        "inputs = layers.Input(shape=(max_sequences,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_sequences, VOCAB_SIZE, D_MODEL)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(D_MODEL, NUM_HEADS, UNITS)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(40, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dje6ooiUl4a"
      },
      "source": [
        "seq_x = convert_text_to_index(wear_data['SENTENCE'].tolist(), word_to_index, ENCODER_INPUT)\n",
        "catgory_index_arr = pd.factorize(wear_data['CATEGORY'])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_OKRIMuJY1g",
        "outputId": "070b362a-a371-4fba-8f58-acaf51faab0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(\n",
        "    seq_x, catgory_index_arr, batch_size=8, epochs=10, validation_split=0.1\n",
        ")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 1.2396 - accuracy: 0.3790 - val_loss: 1.1789 - val_accuracy: 0.3544\n",
            "Epoch 2/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 1.2082 - accuracy: 0.3966 - val_loss: 1.1966 - val_accuracy: 0.3872\n",
            "Epoch 3/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 1.1626 - accuracy: 0.4355 - val_loss: 1.1888 - val_accuracy: 0.5685\n",
            "Epoch 4/30\n",
            "1781/1781 [==============================] - 25s 14ms/step - loss: 1.1246 - accuracy: 0.4664 - val_loss: 1.1630 - val_accuracy: 0.5679\n",
            "Epoch 5/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 1.0788 - accuracy: 0.4993 - val_loss: 1.1957 - val_accuracy: 0.5648\n",
            "Epoch 6/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 1.0286 - accuracy: 0.5222 - val_loss: 1.2198 - val_accuracy: 0.5742\n",
            "Epoch 7/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.9825 - accuracy: 0.5449 - val_loss: 1.3654 - val_accuracy: 0.5679\n",
            "Epoch 8/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.9468 - accuracy: 0.5617 - val_loss: 1.2379 - val_accuracy: 0.5875\n",
            "Epoch 9/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.9235 - accuracy: 0.5698 - val_loss: 1.2673 - val_accuracy: 0.5982\n",
            "Epoch 10/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.9026 - accuracy: 0.5793 - val_loss: 1.1793 - val_accuracy: 0.5774\n",
            "Epoch 11/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.8824 - accuracy: 0.5855 - val_loss: 1.2225 - val_accuracy: 0.5938\n",
            "Epoch 12/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.8737 - accuracy: 0.5910 - val_loss: 1.4619 - val_accuracy: 0.5648\n",
            "Epoch 13/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8619 - accuracy: 0.5970 - val_loss: 1.4117 - val_accuracy: 0.5736\n",
            "Epoch 14/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.8524 - accuracy: 0.5998 - val_loss: 1.3523 - val_accuracy: 0.5812\n",
            "Epoch 15/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8395 - accuracy: 0.6035 - val_loss: 1.5502 - val_accuracy: 0.5768\n",
            "Epoch 16/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8346 - accuracy: 0.6034 - val_loss: 1.4682 - val_accuracy: 0.5824\n",
            "Epoch 17/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8255 - accuracy: 0.6089 - val_loss: 1.7574 - val_accuracy: 0.5654\n",
            "Epoch 18/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8201 - accuracy: 0.6096 - val_loss: 1.6058 - val_accuracy: 0.5698\n",
            "Epoch 19/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8056 - accuracy: 0.6134 - val_loss: 1.6498 - val_accuracy: 0.5401\n",
            "Epoch 20/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.8065 - accuracy: 0.6133 - val_loss: 1.4237 - val_accuracy: 0.5837\n",
            "Epoch 21/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8010 - accuracy: 0.6203 - val_loss: 1.5852 - val_accuracy: 0.5736\n",
            "Epoch 22/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.7946 - accuracy: 0.6178 - val_loss: 1.5129 - val_accuracy: 0.5907\n",
            "Epoch 23/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.7876 - accuracy: 0.6235 - val_loss: 1.7988 - val_accuracy: 0.5666\n",
            "Epoch 24/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.7810 - accuracy: 0.6271 - val_loss: 1.6766 - val_accuracy: 0.5761\n",
            "Epoch 25/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.7749 - accuracy: 0.6319 - val_loss: 1.7024 - val_accuracy: 0.5799\n",
            "Epoch 26/30\n",
            "1781/1781 [==============================] - 27s 15ms/step - loss: 0.7719 - accuracy: 0.6301 - val_loss: 1.7807 - val_accuracy: 0.5711\n",
            "Epoch 27/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.7621 - accuracy: 0.6326 - val_loss: 1.8464 - val_accuracy: 0.5464\n",
            "Epoch 28/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.7600 - accuracy: 0.6355 - val_loss: 1.6392 - val_accuracy: 0.5831\n",
            "Epoch 29/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.7562 - accuracy: 0.6353 - val_loss: 1.7921 - val_accuracy: 0.5610\n",
            "Epoch 30/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.7552 - accuracy: 0.6391 - val_loss: 1.9658 - val_accuracy: 0.5761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq4hjB86TeiS",
        "outputId": "c1baba82-bc97-473c-c206-e6231bfd3bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pav-8Jd3ydzp"
      },
      "source": [
        "## 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8y-mjWtydzp"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK3IwtA4TOnN"
      },
      "source": [
        "### Loss function\n",
        "since target sequences are padded, deal this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi7YnqpVTYn2"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "  \n",
        "  mask = tf.cast(tf.not_equal(y_true,0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzHEmCzUVhTu"
      },
      "source": [
        "### Custom learning rate\n",
        "use Adam optimizer with custom learning rate\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkFm9m_LVt8c"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb8PGbKgWAbP"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vql4FYFUV_3_"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTXbb1Z2I4IM"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl3V7BllWWFG",
        "outputId": "c4486f9b-39ab-4bbc-a143-8f0c42b349b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.9745 - accuracy: 0.0212\n",
            "Epoch 2/50\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.7337 - accuracy: 0.0333\n",
            "Epoch 3/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.4780 - accuracy: 0.0421\n",
            "Epoch 4/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.3197 - accuracy: 0.0458\n",
            "Epoch 5/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.2290 - accuracy: 0.0561\n",
            "Epoch 6/50\n",
            "115/115 [==============================] - 6s 57ms/step - loss: 1.1427 - accuracy: 0.0669\n",
            "Epoch 7/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 1.0619 - accuracy: 0.0749\n",
            "Epoch 8/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.9901 - accuracy: 0.0812\n",
            "Epoch 9/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.9265 - accuracy: 0.0865\n",
            "Epoch 10/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.8684 - accuracy: 0.0916\n",
            "Epoch 11/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.8145 - accuracy: 0.0964\n",
            "Epoch 12/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.7614 - accuracy: 0.1010\n",
            "Epoch 13/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.7114 - accuracy: 0.1056\n",
            "Epoch 14/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.6626 - accuracy: 0.1111\n",
            "Epoch 15/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.6111 - accuracy: 0.1175\n",
            "Epoch 16/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.5616 - accuracy: 0.1236\n",
            "Epoch 17/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.5127 - accuracy: 0.1302\n",
            "Epoch 18/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.4641 - accuracy: 0.1377\n",
            "Epoch 19/50\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4141 - accuracy: 0.1464\n",
            "Epoch 20/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.3699 - accuracy: 0.1541\n",
            "Epoch 21/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.3243 - accuracy: 0.1625\n",
            "Epoch 22/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.2804 - accuracy: 0.1720\n",
            "Epoch 23/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.2446 - accuracy: 0.1786\n",
            "Epoch 24/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.2120 - accuracy: 0.1850\n",
            "Epoch 25/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1853 - accuracy: 0.1909\n",
            "Epoch 26/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1654 - accuracy: 0.1948\n",
            "Epoch 27/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1472 - accuracy: 0.1982\n",
            "Epoch 28/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1370 - accuracy: 0.1998\n",
            "Epoch 29/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1279 - accuracy: 0.2015\n",
            "Epoch 30/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1167 - accuracy: 0.2041\n",
            "Epoch 31/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1119 - accuracy: 0.2052\n",
            "Epoch 32/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.1082 - accuracy: 0.2057\n",
            "Epoch 33/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1045 - accuracy: 0.2067\n",
            "Epoch 34/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1004 - accuracy: 0.2074\n",
            "Epoch 35/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0997 - accuracy: 0.2078\n",
            "Epoch 36/50\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 0.0928 - accuracy: 0.2092\n",
            "Epoch 37/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0908 - accuracy: 0.2099\n",
            "Epoch 38/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0832 - accuracy: 0.2120\n",
            "Epoch 39/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0788 - accuracy: 0.2133\n",
            "Epoch 40/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0733 - accuracy: 0.2148\n",
            "Epoch 41/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0689 - accuracy: 0.2158\n",
            "Epoch 42/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0662 - accuracy: 0.2163\n",
            "Epoch 43/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0630 - accuracy: 0.2175\n",
            "Epoch 44/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0610 - accuracy: 0.2180\n",
            "Epoch 45/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0573 - accuracy: 0.2191\n",
            "Epoch 46/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0539 - accuracy: 0.2200\n",
            "Epoch 47/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.0522 - accuracy: 0.2205\n",
            "Epoch 48/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.0507 - accuracy: 0.2210\n",
            "Epoch 49/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0486 - accuracy: 0.2217\n",
            "Epoch 50/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0487 - accuracy: 0.2215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbf34ac27f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx-jxXncYmlp"
      },
      "source": [
        "## Category Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seok_9PxYrlV"
      },
      "source": [
        "main = wear_data['MAIN']\n",
        "category = wear_data['CATEGORY']\n",
        "all_stc = wear_data['SENTENCE']\n",
        "\n",
        "category_info = pd.DataFrame({\"stc\":all_stc, \"cate\":main})\n",
        "rough_info = pd.DataFrame({\"stc\":all_stc, \"cate\":category})"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uawcREfY87l",
        "outputId": "5972ccb5-28dc-42de-8462-7dd2bc6901e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "category_info.dropna(inplace = True)\n",
        "category_info.reset_index(drop=True, inplace = True)\n",
        "\n",
        "rough_info.dropna(inplace = True)\n",
        "rough_info.reset_index(drop=True, inplace = True)\n",
        "\n",
        "print(category_info.shape, rough_info.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15725, 2) (15826, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-h0d_06Y_GA"
      },
      "source": [
        "def make_tokenize(info):\n",
        "    tagger = Okt()\n",
        "\n",
        "    for i in range(info.shape[0]):\n",
        "        info['stc'][i] = tagger.morphs(info['stc'][i])\n",
        "\n",
        "make_tokenize(category_info)\n",
        "make_tokenize(rough_info)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmGrD5juZ_ET"
      },
      "source": [
        "category_list = pd.factorize(category_info['cate'])[1]\n",
        "category_info['cate'] = pd.factorize(category_info['cate'])[0]\n",
        "\n",
        "rough_category_list = pd.factorize(rough_info['cate'])[1]\n",
        "rough_info['cate'] = pd.factorize(rough_info['cate'])[0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQLKF7FkbRAi"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "category_ans = to_categorical(category_info['cate']) # 카테고리 관련 원핫벡터 카테고리\n",
        "rough_ans = to_categorical(rough_info['cate']) # 4개 카테고리 관련 원핫벡터 카테고리"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZavgRPJdM79"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "ctokenizer = Tokenizer(5000) \n",
        "ctokenizer.fit_on_texts(category_info['stc'])\n",
        "ctoken_stc = ctokenizer.texts_to_sequences(category_info['stc'])\n",
        "category_stc = ctoken_stc\n",
        "\n",
        "rtokenizer = Tokenizer(5000) \n",
        "rtokenizer.fit_on_texts(rough_info['stc'])\n",
        "rtoken_stc = rtokenizer.texts_to_sequences(rough_info['stc'])\n",
        "rough_stc = rtoken_stc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soNw3c6Cen_G"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len = 15\n",
        "category_stc = pad_sequences(category_stc, maxlen=max_len) # 카테고리 관련 패딩까지 마친 문장 모음\n",
        "rough_stc = pad_sequences(rough_stc, maxlen=max_len) # 4개 카테고리 관련 패딩까지 마친 문장 모음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2SP7QT_a-4n"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cX_train, cX_test, cy_train, cy_test = train_test_split(\n",
        "    category_stc, category_ans, test_size = 0.2, shuffle = True, random_state = 11)\n",
        "\n",
        "rX_train, rX_test, ry_train, ry_test = train_test_split(\n",
        "    rough_stc, rough_ans, test_size = 0.2, shuffle = True, random_state = 11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW-r-YFCfVgv"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "\n",
        "cmodel = Sequential()\n",
        "cmodel.add(Embedding(5000, 128))\n",
        "cmodel.add(LSTM(128))\n",
        "cmodel.add(Dense(405, activation='softmax'))\n",
        "\n",
        "rmodel = Sequential()\n",
        "rmodel.add(Embedding(5000, 100))\n",
        "rmodel.add(LSTM(128))\n",
        "rmodel.add(Dense(4, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHQoXs8wfkYk"
      },
      "source": [
        "cmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "cmodel.fit(cX_train, cy_train, validation_data=(cX_test, cy_test), batch_size=32, epochs=30) # 128 64 32 실험"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYqy-6NEfrXJ"
      },
      "source": [
        "rmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "rmodel.fit(rX_train, ry_train, validation_data=(rX_test, ry_test), batch_size=10, epochs=10) # 128 64 32 실험"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXEMQH_jf5jl"
      },
      "source": [
        "def find_category(stc,tokenizer,model,category_list):\n",
        "    tagger = Okt()\n",
        "    stc = tagger.morphs(stc)\n",
        "    encode_stc = tokenizer.texts_to_sequences([stc])\n",
        "    pad_stc = pad_sequences(encode_stc, maxlen=15)\n",
        "    score = model.predict(pad_stc)\n",
        "    return (category_list[score.argmax()], score[0, score.argmax()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6EDnEOwI_G7"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxi2B-vjydzt"
      },
      "source": [
        "# 인덱스를 문장으로 변환\n",
        "def convert_index_to_text(indexs, vocabulary): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == END_INDEX:\n",
        "            # 종료 인덱스면 중지\n",
        "            break;\n",
        "        if vocabulary.get(index) is not None:\n",
        "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
        "            sentence += vocabulary[index]\n",
        "        else:\n",
        "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
        "            sentence.extend([vocabulary[OOV_INDEX]])\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E66RpbXydzy"
      },
      "source": [
        "# 예측을 위한 입력 생성\n",
        "def make_predict_input(sentence):\n",
        "\n",
        "    sentences = []\n",
        "    sentences.append(sentence)\n",
        "    sentences = pos_tag(sentences)\n",
        "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
        "    \n",
        "    return input_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umBNECObKCJj"
      },
      "source": [
        "def evaluate(input_seq):\n",
        "\n",
        "  input_seq = input_seq.squeeze()\n",
        "  sentence = tf.expand_dims(input_seq, axis=0)\n",
        "  output = tf.expand_dims([1], 0)\n",
        "\n",
        "  for i in range(max_sequences):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, 2):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjLQI4czaTs1"
      },
      "source": [
        "##doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAs_p0bLhlPy"
      },
      "source": [
        "import os\n",
        "from gensim.models import doc2vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import pandas as pd\n",
        "import jpype\n",
        "from konlpy.tag import Kkma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYLVCfVfaB88"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exGo1HnHR5Dg"
      },
      "source": [
        "kkma = Kkma()\n",
        "filter_kkma = ['NNG', 'NNP','OL','VA','VV','VXV']\n",
        "\n",
        "def tokenizer_kkma(doc):\n",
        "    # 꼬꼬마 형태소 분석기가 자바 기반이어서 파이썬에서 자바함수들을 실행할 수 있는 명령어 (jpype) 를 써줘야한다.\n",
        "    jpype.attachThreadToJVM()       \n",
        "    token_doc = [\"/\".join(word) for word in kkma.pos(doc)]\n",
        "    return token_doc\n",
        "\n",
        "def tokenize_kkma_noun_verb(doc):\n",
        "    jpype.attachThreadToJVM()\n",
        "    token_doc = [\"/\".join(word) for word in kkma.pos(doc) if word[1] in filter_kkma]\n",
        "    return token_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzqye7pxR8kD"
      },
      "source": [
        "token_faqs = [(tokenizer_kkma(row[1]), row[0]) for row in faqs]\n",
        "tagged_faqs = [TaggedDocument(d,[c]) for d,c in token_faqs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_DB1CbDSNQj",
        "outputId": "5360a19d-a53c-4000-e46f-4b65430a4f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 모델 만들기\n",
        "# cpu 몇 개 쓸 건지\n",
        "import multiprocessing\n",
        "# 내 컴에 있는 cpu 갯수 cores 에 저장\n",
        "cores = multiprocessing.cpu_count()\n",
        "# vector_size : 임베딩할 벡터 차원\n",
        "# negaive : negative sampling\n",
        "d2v_faqs = doc2vec.Doc2Vec(\n",
        "    vector_size = 100,\n",
        "    alpha = 0.025,\n",
        "    min_alpha = 0.025,\n",
        "    hs = 1,\n",
        "    negative = 0,\n",
        "    dm = 0,\n",
        "    dbow_words = 1,\n",
        "    min_count = 1,\n",
        "    workers = cores,\n",
        "    seed = 0\n",
        ")\n",
        "\n",
        "# 단어 사전 만들기\n",
        "d2v_faqs.build_vocab(tagged_faqs)\n",
        "for epoch in range(4):\n",
        "  # 모델 학습\n",
        "  print(epoch)\n",
        "  d2v_faqs.train(tagged_faqs,\n",
        "                 total_examples = d2v_faqs.corpus_count,\n",
        "                 epochs = d2v_faqs.epochs)\n",
        "  d2v_faqs.alpha -=0.0025\n",
        "  d2v_faqs.min_alpha = d2v_faqs.min_alpha"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjxPAkUcRXNQ"
      },
      "source": [
        "##합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "audGWlqWURLT"
      },
      "source": [
        "def give_cate(input_question): #카테고리추출하는 함수\n",
        "  big_cate=find_category(input_question,ctokenizer,cmodel,category_list)\n",
        "  samll_cate=find_category(input_question,rtokenizer,rmodel,rough_category_list)\n",
        "  return big_cate,samll_cate #리턴값으로 큰카테고리(이름,유사도),작은 카테고리(이름,유사도)\n",
        "\n",
        "def give_answer(input_question): #질문입력시 transfomer로 답변함\n",
        "  return convert_index_to_text(evaluate(make_predict_input(input_question)).numpy()[1:],index_to_word)\n",
        "\n",
        "def doc2_answer(input_question): #질문 입력시 doc2으로 답변함\n",
        "  token_test = tokenizer_kkma(input_question)\n",
        "  predict_vector = d2v_faqs.infer_vector(token_test)\n",
        "  result = d2v_faqs.docvecs.most_similar([predict_vector],topn=1)\n",
        "  return faqs[int(result[0][0])-1][2]\n",
        "\n",
        "def score_calcul(left_cate,right_cate):#카테고리를 두개를 입력하면 유사도를 계산함\n",
        "  result = 0\n",
        "  if left_cate[0]==right_cate[0]:\n",
        "    result += abs(left_cate[1]-right_cate[1])\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oOsaFW9RpBK",
        "outputId": "a2029d76-5358-4ca2-e3c3-26a87cc6c8db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_question = input()\n",
        "\n",
        "q_big_cate,q_samll_cate=give_cate(input_question)\n",
        "\n",
        "print(f\"{q_big_cate},{q_samll_cate}\")\n",
        "\n",
        "dm=doc2_answer(input_question)\n",
        "dm_big_cate,dm_small_cate=give_cate(dm)\n",
        "cm=give_answer(input_question)\n",
        "cm_big_cate,cm_small_cate=give_cate(cm)\n",
        "\n",
        "doc2_score=0\n",
        "tran_score=0\n",
        "\n",
        "doc2_score += score_calcul(q_big_cate,dm_big_cate)\n",
        "doc2_score += score_calcul(q_big_cate,dm_small_cate)\n",
        "tran_score += score_calcul(q_big_cate,cm_big_cate)\n",
        "tran_score += score_calcul(q_big_cate,dm_small_cate)\n",
        "\n",
        "if doc2_score>=tran_score:\n",
        "  print(f\"***doc2: {dm}\")\n",
        "else:\n",
        "  print(f\"***tran: {cm}\")\n",
        "\n",
        "print(\"==================================\")\n",
        "print(f\"doc2: {dm_big_cate},{dm_small_cate}\")\n",
        "print(dm)\n",
        "if doc2_score!=0:\n",
        "  print(doc2_score)\n",
        "else:\n",
        "  print(\"평가불가\")\n",
        "print(\"\")\n",
        "print(f\"tran: {cm_big_cate},{cm_small_cate}\")\n",
        "print(cm)\n",
        "if tran_score!=0:\n",
        "  print(tran_score)\n",
        "else:\n",
        "  print(\"평가불가\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "카운터에 있는 점원이 입고 있는 옷 맘에 드는데 어떤 제품인가요?\n",
            "('유사제품추천문의', 0.6587085),('신발', 0.9972078)\n",
            "***doc2: 네 피팅룸은 이쪽입니다\n",
            "==================================\n",
            "doc2: ('제품요청', 0.50416297),('의류', 0.999944)\n",
            "네 피팅룸은 이쪽입니다\n",
            "평가불가\n",
            "\n",
            "tran: ('제품별추천문의', 0.67691714),('의류', 0.88469416)\n",
            "고객 님 이 제품 은 어떠 신지 요 ? \n",
            "평가불가\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}