{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.3.1-cp38-cp38-win_amd64.whl (342.5 MB)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.13.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.33.1-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.22.1-py2.py3-none-any.whl (114 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n",
      "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=ebbd1f60a4bba8a58edd9dad4c1ebbb63316dfeb21ae02d81fe033842932eb9b\n",
      "  Stored in directory: c:\\users\\ehdrn\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: grpcio, absl-py, markdown, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, google-auth-oauthlib, protobuf, tensorboard-plugin-wit, tensorboard, opt-einsum, gast, termcolor, tensorflow-estimator, google-pasta, astunparse, keras-preprocessing, tensorflow\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.22.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.33.1 keras-preprocessing-1.1.2 markdown-3.3.3 opt-einsum-3.3.0 protobuf-3.13.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.6 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from keras) (1.5.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "Une6bYuSo1oW",
    "outputId": "9a6a4d23-a583-4ed6-de9e-657fed3a75e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from konlpy) (4.5.2)\n",
      "Collecting beautifulsoup4==4.6.0\n",
      "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
      "Collecting tweepy>=3.7.0\n",
      "  Downloading tweepy-3.9.0-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from konlpy) (1.18.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from konlpy) (0.4.3)\n",
      "Collecting JPype1>=0.7.0\n",
      "  Downloading JPype1-1.1.2-cp38-cp38-win_amd64.whl (1.6 MB)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from tweepy>=3.7.0->konlpy) (2.24.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in c:\\users\\ehdrn\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Installing collected packages: beautifulsoup4, oauthlib, requests-oauthlib, tweepy, JPype1, konlpy\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.9.1\n",
      "    Uninstalling beautifulsoup4-4.9.1:\n",
      "      Successfully uninstalled beautifulsoup4-4.9.1\n",
      "Successfully installed JPype1-1.1.2 beautifulsoup4-4.6.0 konlpy-0.5.2 oauthlib-3.1.0 requests-oauthlib-1.3.0 tweepy-3.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1DAFy5c7ydzC"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers, losses, metrics\n",
    "from keras import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC7BFWmDydzF"
   },
   "source": [
    "Seq2Seq에서의 임베딩이 이전 예제와 다른 점은 아래와 같이 태그를 사용한다는 것입니다. 임베딩의 0~3번째에 각각 PADDING, START, END, OOV 태그를 넣습니다. 사실 그냥 똑같은 단어라고 보시면 됩니다. 다만 이 단어들이 Seq2Seq의 동작을 제어합니다. \n",
    "\n",
    "예를 들어, 디코더 입력에 START가 들어가면 디코딩의 시작을 의미합니다. 반대로 디코더 출력에 END가 나오면 디코딩을 종료합니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "P9YUdE1OydzG"
   },
   "outputs": [],
   "source": [
    "# 태그 단어\n",
    "PAD = \"<PADDING>\"   # 패딩\n",
    "STA = \"<START>\"     # 시작\n",
    "END = \"<END>\"       # 끝\n",
    "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
    "\n",
    "# 태그 인덱스\n",
    "PAD_INDEX = 0\n",
    "STA_INDEX = 1\n",
    "END_INDEX = 2\n",
    "OOV_INDEX = 3\n",
    "\n",
    "# 데이터 타입\n",
    "ENCODER_INPUT  = 0\n",
    "DECODER_INPUT  = 1\n",
    "DECODER_TARGET = 2\n",
    "\n",
    "# 한 문장에서 단어 시퀀스의 최대 개수\n",
    "max_sequences = 30\n",
    "\n",
    "# 임베딩 벡터 차원\n",
    "embedding_dim = 100\n",
    "\n",
    "# LSTM 히든레이어 차원\n",
    "lstm_hidden_dim = 128\n",
    "\n",
    "# 정규 표현식 필터\n",
    "RE_FILTER = re.compile(\"[.,!?\\\"':;~()]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "80IauV0FpUv2",
    "outputId": "26860f61-1e94-4783-d3f5-60881507df64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "NEHDnPXNzZlM",
    "outputId": "8129af83-4838-4624-bcbd-eacd0c493bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15826, 20)\n",
      "(8381,) (7445,)\n"
     ]
    }
   ],
   "source": [
    "wear_data = pd.read_csv(\"/content/drive/My Drive/wear.csv\")\n",
    "print(wear_data.shape)\n",
    "customer = wear_data[wear_data.SPEAKER == \"고객\"].SENTENCE\n",
    "store = wear_data[wear_data.SPEAKER == \"점원\"].SENTENCE\n",
    "print(customer.shape, store.shape) # 질문의 개수와 답의 개수가 일치하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "FLNSiqcHM4WY",
    "outputId": "71897173-3b31-4f42-bb54-79efcd9ffd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7301\n",
      "7301\n",
      "요즘 파스텔 톤이 유행이에요\n",
      "요즘 유행하는 색깔이 뭐예요?\n"
     ]
    }
   ],
   "source": [
    "prev = \"고객\"\n",
    "store_arr = []\n",
    "customer_arr = []\n",
    "store_stc = \"\"\n",
    "customer_stc = \"\"\n",
    "\n",
    "for i in range(wear_data.shape[0]):\n",
    "    if (prev == wear_data.iloc[i].SPEAKER):\n",
    "        if prev == \"점원\":\n",
    "             store_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
    "        else : \n",
    "            customer_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
    "            \n",
    "    elif prev == \"점원\":\n",
    "        store_arr.append(store_stc)\n",
    "        customer_stc = wear_data.iloc[i].SENTENCE\n",
    "        prev = \"고객\"\n",
    "    else :\n",
    "        customer_arr.append(customer_stc)\n",
    "        store_stc = wear_data.iloc[i].SENTENCE\n",
    "        prev = \"점원\"\n",
    "\n",
    "print(len(store_arr))\n",
    "print(len(customer_arr))\n",
    "print(store_arr[-1])\n",
    "print(customer_arr[-1]) # 자료 상에서 이후에는 계속 고객의 물음만 계속된다. 코드 레벨에서 이 부분은 빼게 구현했다. (stc는 만들어지지만 arr에 append 안하게 된다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WNvig2FMzjXj"
   },
   "outputs": [],
   "source": [
    "question = []\n",
    "answer = []\n",
    "\n",
    "for Q in customer_arr:\n",
    "    question.append(Q.replace(\"[^\\w]\", \" \"))\n",
    "\n",
    "for A in store_arr:\n",
    "    answer.append(A.replace(\"[^\\w]\", \" \"))\n",
    "\n",
    "len(question), len(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90yyqX2NydzM"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "# 단어 사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qbivSckMydzN"
   },
   "outputs": [],
   "source": [
    "# 형태소분석 함수\n",
    "def pos_tag(sentences):\n",
    "    \n",
    "    # KoNLPy 형태소분석기 설정\n",
    "    tagger = Okt()\n",
    "    \n",
    "    # 문장 품사 변수 초기화\n",
    "    sentences_pos = []\n",
    "    \n",
    "    # 모든 문장 반복\n",
    "    for sentence in sentences:\n",
    "        # 특수기호 제거\n",
    "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
    "        \n",
    "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
    "        sentence = \" \".join(tagger.morphs(sentence))\n",
    "        sentences_pos.append(sentence)\n",
    "        \n",
    "    return sentences_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "4seqSNWcydzP",
    "outputId": "ce050105-bb79-4eab-f736-6bde55980478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 신발 은 여기 있는 게 다예 요\n",
      "A : 네 성인 이나 아동 다 있어요 발 사이즈 몇 신으세요\n",
      "\n",
      "Q : 230 이요\n",
      "A : 편하게 신 을 수 있는 거 찾으세요\n",
      "\n",
      "Q : 네 봄 이니까 편하게 신 을 수 있는 거\n",
      "A : 이런 건 어떠세요 이런 거도 신발 무척 편하거든요\n",
      "\n",
      "Q : 굽 좀 높은 거 없나요\n",
      "A : 봄 상품 은 아직 어른 제품 이 많이 안 나왔습니다\n",
      "\n",
      "Q : 언제 들어와요\n",
      "A : 이번 주 지나면 들어올 거 예요\n",
      "\n",
      "Q : 이 거 는 가죽 이에요\n",
      "A : 가죽 아니고 쎄 무예 요\n",
      "\n",
      "Q : 가죽 은 얼마 예요\n",
      "A : 2만 9천 원 입니다\n",
      "\n",
      "Q : 털 달린 거 저 거 는 사이즈 있어요\n",
      "A : 230 이 없어요 이 거 한 번 신어 보세요\n",
      "\n",
      "Q : 좀 크네 또 안 들어와요\n",
      "A : 네 이건 다 끝났어요\n",
      "\n",
      "Q : 가방 매는 거 보고 있어요\n",
      "A : 여기 있어요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 형태소분석 수행\n",
    "question = pos_tag(question)\n",
    "answer = pos_tag(answer)\n",
    "\n",
    "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
    "for i in range(5):\n",
    "    print('Q : ' + question[i])\n",
    "    print('A : ' + answer[i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Yrnct_nzydzR"
   },
   "outputs": [],
   "source": [
    "# 질문과 대답 문장들을 하나로 합침\n",
    "sentences = []\n",
    "sentences.extend(question)\n",
    "sentences.extend(answer)\n",
    "\n",
    "words = []\n",
    "\n",
    "# 단어들의 배열 생성\n",
    "for sentence in sentences:\n",
    "    for word in sentence.split():\n",
    "        words.append(word)\n",
    "\n",
    "# 길이가 0인 단어는 삭제\n",
    "words = [word for word in words if len(word) > 0]\n",
    "\n",
    "# 중복된 단어 삭제\n",
    "words = list(set(words))\n",
    "\n",
    "# 제일 앞에 태그 단어 삽입\n",
    "words[:0] = [PAD, STA, END, OOV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "fE9ZhJpEy_rT",
    "outputId": "c8755f62-cf70-4204-834a-4f9da61a000b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손님과 점원의 말에서 사용된 총 단어의 수 : 6403\n"
     ]
    }
   ],
   "source": [
    "print(\"손님과 점원의 말에서 사용된 총 단어의 수 :\",len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "i0jXcjybydzV",
    "outputId": "0a4a9003-75d2-44cc-c79c-c5ab15cc160f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PADDING>',\n",
       " '<START>',\n",
       " '<END>',\n",
       " '<OOV>',\n",
       " '나왔나요',\n",
       " '있죠',\n",
       " '적합한게',\n",
       " '금지',\n",
       " '가능해요',\n",
       " '된건데',\n",
       " '국제',\n",
       " '있어서요',\n",
       " '받을수있는건',\n",
       " '있다가',\n",
       " '되겠다',\n",
       " '파손',\n",
       " '아프나요',\n",
       " '파커',\n",
       " '나왔네요',\n",
       " '팔꿈치']"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 출력\n",
    "words[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AkvyOnSvydzX"
   },
   "outputs": [],
   "source": [
    "# 단어와 인덱스의 딕셔너리 생성\n",
    "word_to_index = {word: index for index, word in enumerate(words)}\n",
    "index_to_word = {index: word for index, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "92gmrtEz3l5R",
    "outputId": "b8cf6690-206a-451e-8cfe-1b056fb9f459"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PADDING>': 0,\n",
       " '<START>': 1,\n",
       " '<END>': 2,\n",
       " '<OOV>': 3,\n",
       " '다니기': 4,\n",
       " '그렇치요': 5,\n",
       " '나오긴': 6,\n",
       " '빠지면': 7,\n",
       " '솜': 8,\n",
       " '비슷하지': 9,\n",
       " '골고루': 10,\n",
       " '롱패딩': 11,\n",
       " '신다': 12,\n",
       " '튀는것': 13,\n",
       " '우리나라': 14,\n",
       " '클까': 15,\n",
       " '다른데요': 16,\n",
       " '둘러보겠습니다': 17,\n",
       " '행사': 18,\n",
       " '20000원': 19,\n",
       " '무역': 20,\n",
       " '브로': 21,\n",
       " '어둡나요': 22,\n",
       " '겨자': 23,\n",
       " '가요': 24,\n",
       " '않나요': 25,\n",
       " '화': 26,\n",
       " '하는데': 27,\n",
       " '무늬': 28,\n",
       " '하더라': 29,\n",
       " '봐야': 30,\n",
       " '따': 31,\n",
       " '두었습니다': 32,\n",
       " '껴': 33,\n",
       " '받이': 34,\n",
       " '맞추시려면은': 35,\n",
       " '도리': 36,\n",
       " '편': 37,\n",
       " '폭': 38,\n",
       " '나오는데': 39,\n",
       " '가위': 40,\n",
       " '잘나가거든요': 41,\n",
       " '입어주세요': 42,\n",
       " '닫으세요': 43,\n",
       " '개인': 44,\n",
       " '나서': 45,\n",
       " '창': 46,\n",
       " '나오는': 47,\n",
       " '심한데': 48,\n",
       " '곳': 49,\n",
       " '다니는데': 50,\n",
       " '어떡해요': 51,\n",
       " '조명': 52,\n",
       " '이왕이면': 53,\n",
       " '나오지요': 54,\n",
       " '있더라고요': 55,\n",
       " '옥': 56,\n",
       " '사십이': 57,\n",
       " '감사해요': 58,\n",
       " '낫긴': 59,\n",
       " '에다가': 60,\n",
       " '입기': 61,\n",
       " '어울리시네요': 62,\n",
       " '아이고': 63,\n",
       " '찍이가': 64,\n",
       " '신으려면': 65,\n",
       " '가능하시고요': 66,\n",
       " 'SS': 67,\n",
       " '98000원': 68,\n",
       " '큰': 69,\n",
       " '공기': 70,\n",
       " '흰': 71,\n",
       " '밑창': 72,\n",
       " '약간': 73,\n",
       " '하셨는데요': 74,\n",
       " '전자': 75,\n",
       " '들어가야겠다': 76,\n",
       " '반대편': 77,\n",
       " '일제': 78,\n",
       " '2만원': 79,\n",
       " '지워주세요': 80,\n",
       " '새거로': 81,\n",
       " '녹슬지': 82,\n",
       " '효도': 83,\n",
       " '아니라서': 84,\n",
       " '특별한': 85,\n",
       " '메고': 86,\n",
       " '아니다': 87,\n",
       " '놓은': 88,\n",
       " '무겁네요': 89,\n",
       " '넣어서': 90,\n",
       " '짧게': 91,\n",
       " '신는데요': 92,\n",
       " '낄': 93,\n",
       " '이윤': 94,\n",
       " '맞아서': 95,\n",
       " '15만': 96,\n",
       " '봅시다': 97,\n",
       " '베이지': 98,\n",
       " '있지만': 99,\n",
       " '널': 100,\n",
       " '보겠습니다': 101,\n",
       " '사도': 102,\n",
       " '덧신': 103,\n",
       " '드는데요': 104,\n",
       " '볼수있나요': 105,\n",
       " '피잖아요': 106,\n",
       " '여러': 107,\n",
       " '짜리예요': 108,\n",
       " '그렇죠': 109,\n",
       " '야할': 110,\n",
       " '보내주세요': 111,\n",
       " '상관': 112,\n",
       " '않고도': 113,\n",
       " '달려요': 114,\n",
       " '남여': 115,\n",
       " '해보겠습니다': 116,\n",
       " '덮습니다': 117,\n",
       " '무는': 118,\n",
       " '입어지실거예요': 119,\n",
       " '보여줄게요': 120,\n",
       " '핸드폰': 121,\n",
       " '가볍고요': 122,\n",
       " '가까운': 123,\n",
       " '흠집': 124,\n",
       " '다르게': 125,\n",
       " '장식': 126,\n",
       " '안됩니다': 127,\n",
       " '가가': 128,\n",
       " '거예': 129,\n",
       " '뚫을': 130,\n",
       " '인가': 131,\n",
       " '예쁜가': 132,\n",
       " '낡아': 133,\n",
       " '팔팔이': 134,\n",
       " '차이': 135,\n",
       " '메는거': 136,\n",
       " '담으시나요': 137,\n",
       " '사고': 138,\n",
       " '커플': 139,\n",
       " '삔': 140,\n",
       " '하구': 141,\n",
       " '사면': 142,\n",
       " '하고': 143,\n",
       " '가봐요': 144,\n",
       " '형': 145,\n",
       " '나왔네요': 146,\n",
       " '끼더라고요': 147,\n",
       " '브릭': 148,\n",
       " '신한': 149,\n",
       " '만에': 150,\n",
       " '가져오시면': 151,\n",
       " '안나나요': 152,\n",
       " '그러는데': 153,\n",
       " '사가나요': 154,\n",
       " '이비': 155,\n",
       " '공예': 156,\n",
       " '코르덴': 157,\n",
       " '스몰': 158,\n",
       " '나오는거죠': 159,\n",
       " '소멸': 160,\n",
       " '심한': 161,\n",
       " '통굽': 162,\n",
       " '하는거요': 163,\n",
       " '들한': 164,\n",
       " '빠져서': 165,\n",
       " '툭툭': 166,\n",
       " '잘나가': 167,\n",
       " '살랑': 168,\n",
       " '8천원': 169,\n",
       " '해드릴께요': 170,\n",
       " '7': 171,\n",
       " '기다리셔야': 172,\n",
       " '계속': 173,\n",
       " '고르기': 174,\n",
       " '나나': 175,\n",
       " '참빗': 176,\n",
       " '최대한': 177,\n",
       " '화사한': 178,\n",
       " '있으니까': 179,\n",
       " '들어간다': 180,\n",
       " '국숫': 181,\n",
       " '벗기에는': 182,\n",
       " '해드릴까': 183,\n",
       " '찍어주세요': 184,\n",
       " '가능할거예요': 185,\n",
       " '2400원': 186,\n",
       " '계신': 187,\n",
       " '보고': 188,\n",
       " '스완': 189,\n",
       " '견본': 190,\n",
       " '려고': 191,\n",
       " '떨어져요': 192,\n",
       " '보죠': 193,\n",
       " '빼고는': 194,\n",
       " '110': 195,\n",
       " '봤던': 196,\n",
       " '삼천': 197,\n",
       " '발행': 198,\n",
       " '돼있네요': 199,\n",
       " '성도': 200,\n",
       " '뿐이네요': 201,\n",
       " '넣어요': 202,\n",
       " '예쁜거': 203,\n",
       " '캡': 204,\n",
       " '갖다주세요': 205,\n",
       " '하라': 206,\n",
       " '3천': 207,\n",
       " '있어요': 208,\n",
       " '안되는데': 209,\n",
       " '나오고': 210,\n",
       " '문화': 211,\n",
       " '구경': 212,\n",
       " '보이시': 213,\n",
       " '보통': 214,\n",
       " '가': 215,\n",
       " '방도': 216,\n",
       " '10%': 217,\n",
       " '괜찮던데': 218,\n",
       " '올라가도': 219,\n",
       " '손등': 220,\n",
       " '있으실꺼에요': 221,\n",
       " '걸려': 222,\n",
       " '마땅한': 223,\n",
       " '가져가시면': 224,\n",
       " '결': 225,\n",
       " '+': 226,\n",
       " '쥐색': 227,\n",
       " '5일': 228,\n",
       " '전시': 229,\n",
       " '물론': 230,\n",
       " '이미': 231,\n",
       " '올': 232,\n",
       " '둘러보고요': 233,\n",
       " '일요일': 234,\n",
       " '좋아하는데': 235,\n",
       " '합쳐': 236,\n",
       " '부산': 237,\n",
       " '하시네요': 238,\n",
       " '입었던': 239,\n",
       " '쭉': 240,\n",
       " '3천원': 241,\n",
       " '나올': 242,\n",
       " '일반도': 243,\n",
       " '않으실거에요': 244,\n",
       " '하트': 245,\n",
       " '다운': 246,\n",
       " '타일': 247,\n",
       " '불가하다': 248,\n",
       " '달동': 249,\n",
       " '기비': 250,\n",
       " '봉투': 251,\n",
       " '가는데요': 252,\n",
       " '떨어져도': 253,\n",
       " '만들어요': 254,\n",
       " '원래': 255,\n",
       " '점퍼': 256,\n",
       " '똥': 257,\n",
       " '쓰기': 258,\n",
       " '차요': 259,\n",
       " '입력': 260,\n",
       " '브리프': 261,\n",
       " '이십팔': 262,\n",
       " '잇나요': 263,\n",
       " '빛나네': 264,\n",
       " '날씬해야지': 265,\n",
       " '한시': 266,\n",
       " '카키': 267,\n",
       " '만들었어요': 268,\n",
       " '그렇구요': 269,\n",
       " '보여줄': 270,\n",
       " '됐고': 271,\n",
       " '부터': 272,\n",
       " '좋구요': 273,\n",
       " '어울려서': 274,\n",
       " '할': 275,\n",
       " '필욘': 276,\n",
       " '차지': 277,\n",
       " '입으시거든요': 278,\n",
       " '잠금장치': 279,\n",
       " '샀는데요': 280,\n",
       " '미키': 281,\n",
       " '달려있는': 282,\n",
       " '단순': 283,\n",
       " '고요': 284,\n",
       " '부로': 285,\n",
       " '그러지': 286,\n",
       " '3만원': 287,\n",
       " '하셔서': 288,\n",
       " '건너면': 289,\n",
       " '편입': 290,\n",
       " '저렴한데': 291,\n",
       " '낚시': 292,\n",
       " '신상제': 293,\n",
       " '오면': 294,\n",
       " '같아요': 295,\n",
       " '있으니': 296,\n",
       " '들어갔으면': 297,\n",
       " '되시죠': 298,\n",
       " '않습니다': 299,\n",
       " '가디건': 300,\n",
       " '작은건': 301,\n",
       " '해줘야': 302,\n",
       " '칠천': 303,\n",
       " '옆쪽': 304,\n",
       " '신지': 305,\n",
       " '비싸서': 306,\n",
       " '아니면': 307,\n",
       " '네모': 308,\n",
       " '쉬시죠': 309,\n",
       " '나오나요': 310,\n",
       " '2등': 311,\n",
       " '남아있어요': 312,\n",
       " '지갑': 313,\n",
       " '단가': 314,\n",
       " '없었는데': 315,\n",
       " '안될': 316,\n",
       " '발사이즈': 317,\n",
       " '황당했어요': 318,\n",
       " '메는게': 319,\n",
       " '건조': 320,\n",
       " '테크노': 321,\n",
       " '7시': 322,\n",
       " '들어왔거든요': 323,\n",
       " '좋아하시면': 324,\n",
       " '245': 325,\n",
       " '좋아하세요': 326,\n",
       " '뚫는': 327,\n",
       " '신나요': 328,\n",
       " '갈아도': 329,\n",
       " '유상': 330,\n",
       " '색상': 331,\n",
       " '올려': 332,\n",
       " '들을': 333,\n",
       " '꺼예요': 334,\n",
       " '보다가는': 335,\n",
       " '만들어져서': 336,\n",
       " '기도': 337,\n",
       " '세척': 338,\n",
       " '척': 339,\n",
       " '입으시려고': 340,\n",
       " '근처': 341,\n",
       " '학생용': 342,\n",
       " '되면은': 343,\n",
       " '주시': 344,\n",
       " '없나요': 345,\n",
       " '팩': 346,\n",
       " '붙어있어요': 347,\n",
       " '나가는거': 348,\n",
       " '할께요': 349,\n",
       " '10000원': 350,\n",
       " '전국': 351,\n",
       " '하신지': 352,\n",
       " '둘러볼게요': 353,\n",
       " '이렇게요': 354,\n",
       " '붙어': 355,\n",
       " '분': 356,\n",
       " '매는': 357,\n",
       " '깔끔하게': 358,\n",
       " '두겠습니다': 359,\n",
       " '좀': 360,\n",
       " '편하긴': 361,\n",
       " '편리해요': 362,\n",
       " '하지': 363,\n",
       " '퍼인데': 364,\n",
       " '어머': 365,\n",
       " '카카오': 366,\n",
       " '굵어': 367,\n",
       " '주말': 368,\n",
       " '다이아몬드': 369,\n",
       " '빠져가지고요': 370,\n",
       " '시켜주이소': 371,\n",
       " '박해': 372,\n",
       " '좌측': 373,\n",
       " '학원': 374,\n",
       " '있었네요': 375,\n",
       " '갑니다': 376,\n",
       " '팬던트': 377,\n",
       " '수건': 378,\n",
       " '효과': 379,\n",
       " '19만원': 380,\n",
       " '지워요': 381,\n",
       " '들었습니까': 382,\n",
       " '돌리면': 383,\n",
       " '신었을': 384,\n",
       " '이만사천원': 385,\n",
       " '도까지요': 386,\n",
       " '하시나요': 387,\n",
       " '께서': 388,\n",
       " '갈': 389,\n",
       " '들었어요': 390,\n",
       " '이어서': 391,\n",
       " 'm': 392,\n",
       " '저렴하게': 393,\n",
       " '버스': 394,\n",
       " '걸이': 395,\n",
       " '펜': 396,\n",
       " '팔목': 397,\n",
       " '좋아하시겠어요': 398,\n",
       " '32만원': 399,\n",
       " '비춰': 400,\n",
       " '라고': 401,\n",
       " '찹니다': 402,\n",
       " '11시': 403,\n",
       " '보셔야되': 404,\n",
       " '엘레': 405,\n",
       " '좁아요': 406,\n",
       " '어플': 407,\n",
       " '거구': 408,\n",
       " '드시면': 409,\n",
       " '어렵습니다': 410,\n",
       " '뒤쪽': 411,\n",
       " '열도': 412,\n",
       " '해야겠어요': 413,\n",
       " '스럽죠': 414,\n",
       " '나일론': 415,\n",
       " '러닝': 416,\n",
       " '견고하게': 417,\n",
       " '걸어도': 418,\n",
       " '연령': 419,\n",
       " '바꿔서': 420,\n",
       " '50분': 421,\n",
       " '사장': 422,\n",
       " '박색': 423,\n",
       " '젤': 424,\n",
       " '버클': 425,\n",
       " '예약': 426,\n",
       " '동글동글': 427,\n",
       " '알레르기': 428,\n",
       " '축': 429,\n",
       " '꽉': 430,\n",
       " '찾으시나요': 431,\n",
       " '13000원': 432,\n",
       " '많았는데': 433,\n",
       " '여나요': 434,\n",
       " '구천칠백이십': 435,\n",
       " '깎아주이소': 436,\n",
       " '수가': 437,\n",
       " '장례식': 438,\n",
       " '둘러보시고': 439,\n",
       " '쭈글쭈글해요': 440,\n",
       " '외부': 441,\n",
       " '-': 442,\n",
       " '스카프': 443,\n",
       " '28': 444,\n",
       " '제해': 445,\n",
       " '빈': 446,\n",
       " '캐시': 447,\n",
       " '세네요': 448,\n",
       " '만들어놓은': 449,\n",
       " '또': 450,\n",
       " '어머님께': 451,\n",
       " '사갈게요': 452,\n",
       " '남는': 453,\n",
       " '삼만삼천원': 454,\n",
       " '틀리고': 455,\n",
       " '따지면은': 456,\n",
       " '십이만': 457,\n",
       " '줄무': 458,\n",
       " '스웨이드': 459,\n",
       " '적용': 460,\n",
       " '작을까요': 461,\n",
       " '켤레': 462,\n",
       " '열어나요': 463,\n",
       " '미끄러지지': 464,\n",
       " '남성': 465,\n",
       " '펄': 466,\n",
       " '덮는': 467,\n",
       " '50만원': 468,\n",
       " '묻거나': 469,\n",
       " '75': 470,\n",
       " '늘릴': 471,\n",
       " '잘나가고': 472,\n",
       " '매장': 473,\n",
       " '티머니': 474,\n",
       " '괜찮겠네요': 475,\n",
       " '편해': 476,\n",
       " '어떨까': 477,\n",
       " '재질': 478,\n",
       " '다다': 479,\n",
       " '찾아보니': 480,\n",
       " '팔리는': 481,\n",
       " '징': 482,\n",
       " '접지': 483,\n",
       " '편하네요': 484,\n",
       " '올해': 485,\n",
       " '비번': 486,\n",
       " '뿐이예요': 487,\n",
       " '제품': 488,\n",
       " '돼있나요': 489,\n",
       " '함': 490,\n",
       " '다니려고요': 491,\n",
       " '허리': 492,\n",
       " '육만이': 493,\n",
       " '실내': 494,\n",
       " '가벼운': 495,\n",
       " '주니어': 496,\n",
       " '했죠': 497,\n",
       " '나가요': 498,\n",
       " '커서': 499,\n",
       " '동일': 500,\n",
       " '악세서리': 501,\n",
       " '이백삼십오': 502,\n",
       " '친정엄마': 503,\n",
       " '돼있는지': 504,\n",
       " '내셔': 505,\n",
       " '15만원': 506,\n",
       " '신으시려면': 507,\n",
       " '찌는': 508,\n",
       " '있을거에요': 509,\n",
       " '불편하나요': 510,\n",
       " '상자': 511,\n",
       " '월': 512,\n",
       " '물질': 513,\n",
       " '삼성': 514,\n",
       " '낄만': 515,\n",
       " '부작용': 516,\n",
       " '29만': 517,\n",
       " '더': 518,\n",
       " '앉으시면': 519,\n",
       " '뭔': 520,\n",
       " '비싸면': 521,\n",
       " '쥐색옷': 522,\n",
       " '들어왔습니다': 523,\n",
       " '아무리': 524,\n",
       " '타면': 525,\n",
       " '아무래도': 526,\n",
       " '이상한데요': 527,\n",
       " '향수': 528,\n",
       " '으로만': 529,\n",
       " '주얼': 530,\n",
       " '들려주세요': 531,\n",
       " '불가능': 532,\n",
       " '기다려주세요': 533,\n",
       " '볼래요': 534,\n",
       " '성은': 535,\n",
       " '해드릴게요': 536,\n",
       " '패딩': 537,\n",
       " '다섯': 538,\n",
       " '신어야겠네요': 539,\n",
       " '선택': 540,\n",
       " '기다리시는': 541,\n",
       " '정확하진': 542,\n",
       " '병원': 543,\n",
       " '흠': 544,\n",
       " '프로요': 545,\n",
       " '변': 546,\n",
       " '좋겠는데': 547,\n",
       " '이삼만': 548,\n",
       " '맞추면은': 549,\n",
       " '금지': 550,\n",
       " '고런': 551,\n",
       " '가져오겠습니다': 552,\n",
       " '어떡하나요': 553,\n",
       " '요렇게': 554,\n",
       " '링': 555,\n",
       " '선반': 556,\n",
       " '배드민턴': 557,\n",
       " '많았어요': 558,\n",
       " '들어간게': 559,\n",
       " '있는거로': 560,\n",
       " '별도': 561,\n",
       " '보세요': 562,\n",
       " '드롭형': 563,\n",
       " '신으셔도': 564,\n",
       " '보관': 565,\n",
       " '찾으십니다': 566,\n",
       " '같나요': 567,\n",
       " '그렇습니다': 568,\n",
       " '입으시죠': 569,\n",
       " '셋트': 570,\n",
       " '넣을': 571,\n",
       " '탄': 572,\n",
       " '유지비': 573,\n",
       " '알려주세요': 574,\n",
       " '간답니다': 575,\n",
       " '어울려': 576,\n",
       " '바깥쪽': 577,\n",
       " '오트밀': 578,\n",
       " '이던데': 579,\n",
       " '화장품': 580,\n",
       " '빠지면요': 581,\n",
       " '드라이클리닝': 582,\n",
       " '키': 583,\n",
       " '아닌가요': 584,\n",
       " '지우개': 585,\n",
       " '안타': 586,\n",
       " '12만': 587,\n",
       " '바세린': 588,\n",
       " '현대': 589,\n",
       " '좋으시겠는데요': 590,\n",
       " '점원': 591,\n",
       " '아프나요': 592,\n",
       " '이중': 593,\n",
       " '겸용': 594,\n",
       " '미끄럽지': 595,\n",
       " '비었어요': 596,\n",
       " '브로치': 597,\n",
       " '돼서': 598,\n",
       " '않아': 599,\n",
       " '나은가요': 600,\n",
       " '발끈': 601,\n",
       " '말랐는데': 602,\n",
       " '캔버스': 603,\n",
       " '브랜드': 604,\n",
       " '가거나': 605,\n",
       " '리엑트': 606,\n",
       " '여름': 607,\n",
       " '짜리입니다': 608,\n",
       " '찾고있어요': 609,\n",
       " '볼수': 610,\n",
       " '보신것과': 611,\n",
       " '비슷해요': 612,\n",
       " '움직이죠': 613,\n",
       " '받으실': 614,\n",
       " '고르시고': 615,\n",
       " '2019': 616,\n",
       " '일어나겠다': 617,\n",
       " '담수': 618,\n",
       " '빨아도': 619,\n",
       " '제외': 620,\n",
       " '다녀오세요': 621,\n",
       " '홍보': 622,\n",
       " '괜찮으세요': 623,\n",
       " '조잡': 624,\n",
       " '되어있는': 625,\n",
       " '그러나요': 626,\n",
       " '날씬해': 627,\n",
       " '적어놨던데요': 628,\n",
       " '모직': 629,\n",
       " '입어볼게요': 630,\n",
       " '쫄바지': 631,\n",
       " '좋아하겠죠': 632,\n",
       " '16만원': 633,\n",
       " '모르겠는데': 634,\n",
       " '제일': 635,\n",
       " '삼십사': 636,\n",
       " '순은': 637,\n",
       " '변하지는': 638,\n",
       " '왜소하신': 639,\n",
       " '로마': 640,\n",
       " '같습니다': 641,\n",
       " '이었으면': 642,\n",
       " '4만원': 643,\n",
       " '나가서': 644,\n",
       " '없거든요': 645,\n",
       " '십사만원': 646,\n",
       " '파커': 647,\n",
       " '해드려서': 648,\n",
       " '쓸': 649,\n",
       " '나갔습니다': 650,\n",
       " '그냥': 651,\n",
       " '아가씨': 652,\n",
       " '이니': 653,\n",
       " '있으신': 654,\n",
       " '용지': 655,\n",
       " '안되고요': 656,\n",
       " 'mm': 657,\n",
       " '710': 658,\n",
       " '두꺼울까': 659,\n",
       " '17만': 660,\n",
       " '달라져요': 661,\n",
       " '캐리어': 662,\n",
       " '바뀌어서요': 663,\n",
       " '닦으면': 664,\n",
       " '머리핀': 665,\n",
       " '대박': 666,\n",
       " '난': 667,\n",
       " '전문': 668,\n",
       " '들어가지는': 669,\n",
       " '62000원': 670,\n",
       " '오나요': 671,\n",
       " '입었을': 672,\n",
       " '월요일': 673,\n",
       " '290': 674,\n",
       " '순': 675,\n",
       " '밖에': 676,\n",
       " '재료': 677,\n",
       " '되자마자': 678,\n",
       " '작아서': 679,\n",
       " '쓰실': 680,\n",
       " '거세': 681,\n",
       " '불편': 682,\n",
       " 'XXL': 683,\n",
       " '얼마나': 684,\n",
       " '용도': 685,\n",
       " '25000원': 686,\n",
       " '신용카드': 687,\n",
       " '찾아주실': 688,\n",
       " '되실거에요': 689,\n",
       " '나가고': 690,\n",
       " '십': 691,\n",
       " '브': 692,\n",
       " '하려는데': 693,\n",
       " '변질': 694,\n",
       " '부탁드려요': 695,\n",
       " '200': 696,\n",
       " '되어있고': 697,\n",
       " '가보시': 698,\n",
       " '필요한데요': 699,\n",
       " '검은거': 700,\n",
       " '들어': 701,\n",
       " '플레티넘': 702,\n",
       " '보려고요': 703,\n",
       " '차이는': 704,\n",
       " '싶어서요': 705,\n",
       " '괜찮네요': 706,\n",
       " '맡겨도': 707,\n",
       " '살색': 708,\n",
       " '구김': 709,\n",
       " '눈': 710,\n",
       " '계통': 711,\n",
       " '기선': 712,\n",
       " '5천원': 713,\n",
       " '방울': 714,\n",
       " '분리': 715,\n",
       " '인디': 716,\n",
       " '그러나': 717,\n",
       " '나가네요': 718,\n",
       " '만큼만': 719,\n",
       " '뾰족': 720,\n",
       " '온도': 721,\n",
       " '무거운데': 722,\n",
       " '십칠만': 723,\n",
       " '보드랍고': 724,\n",
       " '빼어': 725,\n",
       " '최소': 726,\n",
       " '않겠네요': 727,\n",
       " '돌잔치': 728,\n",
       " '허벅지': 729,\n",
       " '균형': 730,\n",
       " '빼가지고': 731,\n",
       " '모르겠어서요': 732,\n",
       " '이렇다': 733,\n",
       " '업': 734,\n",
       " '주차장': 735,\n",
       " '수수료': 736,\n",
       " '되는가요': 737,\n",
       " '않지': 738,\n",
       " '거': 739,\n",
       " '보여주시겠요': 740,\n",
       " '되지요': 741,\n",
       " '조직': 742,\n",
       " '사십': 743,\n",
       " '드릴거에요': 744,\n",
       " '보기': 745,\n",
       " '테두리': 746,\n",
       " '기둥': 747,\n",
       " '오세요': 748,\n",
       " '적어놨습니다': 749,\n",
       " '노트북': 750,\n",
       " '이십사일': 751,\n",
       " '입어볼': 752,\n",
       " '값': 753,\n",
       " '다니세요': 754,\n",
       " '모티브': 755,\n",
       " '밖': 756,\n",
       " '378000원': 757,\n",
       " '올이': 758,\n",
       " '정전기': 759,\n",
       " '발도': 760,\n",
       " '가릴': 761,\n",
       " '선호': 762,\n",
       " '90': 763,\n",
       " '봐': 764,\n",
       " '원하는': 765,\n",
       " '뒤꿈치': 766,\n",
       " '이쁜데': 767,\n",
       " '선비': 768,\n",
       " '어제': 769,\n",
       " '돌리는': 770,\n",
       " '사각': 771,\n",
       " '높은가요': 772,\n",
       " '매치': 773,\n",
       " '이기': 774,\n",
       " '낮고': 775,\n",
       " '1000원': 776,\n",
       " '사실': 777,\n",
       " '도': 778,\n",
       " '들어가서': 779,\n",
       " '뭘': 780,\n",
       " '이래요': 781,\n",
       " '이백사십이': 782,\n",
       " '반': 783,\n",
       " '많으니까': 784,\n",
       " '십년': 785,\n",
       " '걸': 786,\n",
       " '가짜': 787,\n",
       " '민트': 788,\n",
       " '표': 789,\n",
       " '깔창': 790,\n",
       " '닳지는': 791,\n",
       " '만드시나요': 792,\n",
       " '굽갈이': 793,\n",
       " '청바지': 794,\n",
       " '11': 795,\n",
       " '의': 796,\n",
       " '자개': 797,\n",
       " '마음': 798,\n",
       " '아보': 799,\n",
       " '쉬나요': 800,\n",
       " '국내': 801,\n",
       " '72': 802,\n",
       " '고상하네': 803,\n",
       " '데일': 804,\n",
       " '애도': 805,\n",
       " '품절': 806,\n",
       " '붙어있는': 807,\n",
       " '진열': 808,\n",
       " '둘러보고있을게요': 809,\n",
       " '쪽': 810,\n",
       " '이만오천원': 811,\n",
       " '수출': 812,\n",
       " '어린': 813,\n",
       " '인한': 814,\n",
       " '200만원': 815,\n",
       " '같고': 816,\n",
       " '들어올거에요': 817,\n",
       " '신으면은': 818,\n",
       " '야외': 819,\n",
       " '구정': 820,\n",
       " '권': 821,\n",
       " '작지': 822,\n",
       " '끝': 823,\n",
       " '88000원': 824,\n",
       " '되시는데요': 825,\n",
       " '기다리세요': 826,\n",
       " '무겁지도': 827,\n",
       " '소풍': 828,\n",
       " '들었는데': 829,\n",
       " '레이스': 830,\n",
       " '잘나요': 831,\n",
       " '되는데': 832,\n",
       " '크지는': 833,\n",
       " '간호사': 834,\n",
       " '써놨는데': 835,\n",
       " '말아놓은': 836,\n",
       " '딱인': 837,\n",
       " '충분할': 838,\n",
       " '가지': 839,\n",
       " '좋아': 840,\n",
       " '지났어요': 841,\n",
       " '관리': 842,\n",
       " '데요': 843,\n",
       " '33000원': 844,\n",
       " '돌리셔도': 845,\n",
       " '만든건': 846,\n",
       " '벽': 847,\n",
       " '은침': 848,\n",
       " '해가지고': 849,\n",
       " '체인점': 850,\n",
       " '갈아': 851,\n",
       " '봄': 852,\n",
       " '구천구백': 853,\n",
       " '뺄': 854,\n",
       " '배터리': 855,\n",
       " '부분': 856,\n",
       " '화려한': 857,\n",
       " '높은데요': 858,\n",
       " '개': 859,\n",
       " '이예요': 860,\n",
       " '똑같아요': 861,\n",
       " '해서요': 862,\n",
       " '삼': 863,\n",
       " '275': 864,\n",
       " '유행': 865,\n",
       " '요청': 866,\n",
       " '쿨톤': 867,\n",
       " '루이비똥': 868,\n",
       " '커버': 869,\n",
       " '대부터': 870,\n",
       " '없는데': 871,\n",
       " '꽂아': 872,\n",
       " '나을까요': 873,\n",
       " '육천오백': 874,\n",
       " '조이시면': 875,\n",
       " '패딩입니': 876,\n",
       " '버버리': 877,\n",
       " '연': 878,\n",
       " '어떻': 879,\n",
       " '주름': 880,\n",
       " '걸리실': 881,\n",
       " '특성': 882,\n",
       " '입으시는': 883,\n",
       " '않고': 884,\n",
       " '가볍고': 885,\n",
       " '에도': 886,\n",
       " '편한가요': 887,\n",
       " '이나': 888,\n",
       " '되거든요': 889,\n",
       " '남녀': 890,\n",
       " '신': 891,\n",
       " '담고': 892,\n",
       " '어떤거': 893,\n",
       " '턱': 894,\n",
       " '하겠다': 895,\n",
       " '따님': 896,\n",
       " '하실건데': 897,\n",
       " '영업': 898,\n",
       " '무예': 899,\n",
       " '불편하신': 900,\n",
       " '천천히': 901,\n",
       " '심심해서': 902,\n",
       " '약품': 903,\n",
       " '보시고요': 904,\n",
       " '유명해요': 905,\n",
       " '잡다하게': 906,\n",
       " '보석': 907,\n",
       " '하체': 908,\n",
       " '지나서': 909,\n",
       " '하시겠어요': 910,\n",
       " '가벼우면': 911,\n",
       " '6시': 912,\n",
       " '추가': 913,\n",
       " '있을시': 914,\n",
       " '아프네': 915,\n",
       " '될거': 916,\n",
       " '다음주': 917,\n",
       " '여부': 918,\n",
       " '으로는': 919,\n",
       " '봄이면은': 920,\n",
       " '쎄네': 921,\n",
       " '공휴일': 922,\n",
       " '사계절': 923,\n",
       " '안나': 924,\n",
       " '노란': 925,\n",
       " '비슷한데': 926,\n",
       " '그러세요': 927,\n",
       " '불가능하세요': 928,\n",
       " '폴리우레탄': 929,\n",
       " '깎아줘요': 930,\n",
       " '원목': 931,\n",
       " '얼마': 932,\n",
       " '앵': 933,\n",
       " '봐주세요': 934,\n",
       " '화가': 935,\n",
       " '북유럽': 936,\n",
       " '기재': 937,\n",
       " '발피': 938,\n",
       " '배출': 939,\n",
       " '들고': 940,\n",
       " '95만원': 941,\n",
       " '필요': 942,\n",
       " '들이': 943,\n",
       " '나아서': 944,\n",
       " '그걸': 945,\n",
       " '눌러주세요': 946,\n",
       " '목걸이': 947,\n",
       " '꺼는': 948,\n",
       " '예쁘긴': 949,\n",
       " '열시': 950,\n",
       " '79000원': 951,\n",
       " '구제': 952,\n",
       " '제휴': 953,\n",
       " '브라운': 954,\n",
       " '가까이': 955,\n",
       " '어디가': 956,\n",
       " '도와주실': 957,\n",
       " '/': 958,\n",
       " '뭐': 959,\n",
       " '기간': 960,\n",
       " '넓어서': 961,\n",
       " '수선하면': 962,\n",
       " '좁게': 963,\n",
       " '된건': 964,\n",
       " '백도': 965,\n",
       " '다신': 966,\n",
       " '이제': 967,\n",
       " '청동': 968,\n",
       " '가도': 969,\n",
       " '코랄': 970,\n",
       " '갈게요': 971,\n",
       " '꺼': 972,\n",
       " '다양하네요': 973,\n",
       " '해놓겠습니다': 974,\n",
       " '현찰': 975,\n",
       " '있잖아': 976,\n",
       " '걱정': 977,\n",
       " '쓰려고요': 978,\n",
       " '100만원': 979,\n",
       " '푸세요': 980,\n",
       " '커라고': 981,\n",
       " '틀리던데': 982,\n",
       " '호로': 983,\n",
       " '가격': 984,\n",
       " '고리': 985,\n",
       " '괜찮아서': 986,\n",
       " '들어오는데': 987,\n",
       " '작게': 988,\n",
       " '자녀': 989,\n",
       " '마': 990,\n",
       " '용은요': 991,\n",
       " '태그': 992,\n",
       " '차는': 993,\n",
       " '하려는': 994,\n",
       " '아마': 995,\n",
       " '후에': 996,\n",
       " '캉골': 997,\n",
       " '밝': 998,\n",
       " '합성': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rfoTztrvydzc"
   },
   "outputs": [],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "def convert_text_to_index(sentences, vocabulary, type): \n",
    "    \n",
    "    sentences_index = []\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for sentence in sentences:\n",
    "        sentence_index = []\n",
    "        \n",
    "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
    "        if type == DECODER_INPUT:\n",
    "            sentence_index.extend([vocabulary[STA]])\n",
    "        \n",
    "        # 문장의 단어들을 띄어쓰기로 분리\n",
    "        for word in sentence.split():\n",
    "            if vocabulary.get(word) is not None:\n",
    "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
    "                sentence_index.extend([vocabulary[word]])\n",
    "            else:\n",
    "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
    "                sentence_index.extend([vocabulary[OOV]])\n",
    "\n",
    "        # 최대 길이 검사\n",
    "        if type == DECODER_TARGET:\n",
    "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
    "            if len(sentence_index) >= max_sequences:\n",
    "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
    "            else:\n",
    "                sentence_index += [vocabulary[END]]\n",
    "        else:\n",
    "            if len(sentence_index) > max_sequences:\n",
    "                sentence_index = sentence_index[:max_sequences]\n",
    "            \n",
    "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
    "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
    "        \n",
    "        # 문장의 인덱스 배열을 추가\n",
    "        sentences_index.append(sentence_index)\n",
    "\n",
    "    return np.asarray(sentences_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "zezFPTvcydzf",
    "outputId": "71e5cf1b-2d3b-441a-eb72-b91bfe28197c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신발 은 여기 있는 게 다예 요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 701, 5039, 2081,  624, 2131, 1000, 4077,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인코더 입력 인덱스 변환\n",
    "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
    "\n",
    "# 첫 번째 인코더 입력 출력 (신발 은 여기 있는 게 다예 요)\n",
    "print(question[0])\n",
    "x_encoder[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "fmql1Lf_ydzh",
    "outputId": "c37ed86e-0792-48f4-b94f-0b6e5d93591f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신발 은 여기 있는 게 다예 요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   1, 3245, 4807, 4067, 4514, 1695, 2416, 1888, 1754, 4427, 2946,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디코더 입력 인덱스 변환\n",
    "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
    "\n",
    "# 첫 번째 디코더 입력 출력 (<START> 신발 은 여기 있는 게 다예 요)\n",
    "print(question[0])\n",
    "x_decoder[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "-qIhDbaLydzk",
    "outputId": "02597418-31ec-4756-efbe-9c67a7e2bbc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신발 은 여기 있는 게 다예 요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3245, 4807, 4067, 4514, 1695, 2416, 1888, 1754, 4427, 2946,    2,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디코더 목표 인덱스 변환\n",
    "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
    "\n",
    "# 첫 번째 디코더 입력 출력 (신발 은 여기 있는 게 다예 요 <END>)\n",
    "print(question[0])\n",
    "y_decoder[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "j5wrgGhCydzm",
    "outputId": "c257bbe5-0c98-4888-8fc9-dff8905abf75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원핫인코딩 초기화\n",
    "one_hot_data = np.zeros((len(y_decoder), max_sequences, len(words)))\n",
    "\n",
    "# 디코더 목표를 원핫인코딩으로 변환\n",
    "# 학습시 입력은 인덱스이지만, 출력은 원핫인코딩 형식임\n",
    "for i, sequence in enumerate(y_decoder):\n",
    "    for j, index in enumerate(sequence):\n",
    "        one_hot_data[i, j, index] = 1\n",
    "\n",
    "# 디코더 목표 설정\n",
    "y_decoder = one_hot_data\n",
    "\n",
    "# 첫 번째 디코더 목표 출력\n",
    "y_decoder[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0latL62ydzo"
   },
   "source": [
    "인코더 입력과 디코더 입력은 임베딩 레이어에 들어가는 인덱스 배열입니다. 반면에 디코더 출력은 원핫인코딩 형식이 되어야 합니다. 디코더의 마지막 Dense 레이어에서 softmax로 나오기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pav-8Jd3ydzp"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "I8y-mjWtydzp"
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# 훈련 모델 인코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 입력 문장의 인덱스 시퀀스를 입력으로 받음\n",
    "encoder_inputs = layers.Input(shape=(None,))\n",
    "\n",
    "# 임베딩 레이어\n",
    "encoder_outputs = layers.Embedding(len(words), embedding_dim)(encoder_inputs)\n",
    "\n",
    "# return_state가 True면 상태값 리턴\n",
    "# LSTM은 state_h(hidden state)와 state_c(cell state) 2개의 상태 존재\n",
    "encoder_outputs, state_h, state_c = layers.LSTM(lstm_hidden_dim,\n",
    "                                                return_state=True)(encoder_outputs)\n",
    "\n",
    "# 히든 상태와 셀 상태를 하나로 묶음\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#--------------------------------------------\n",
    "# 훈련 모델 디코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 목표 문장의 인덱스 시퀀스를 입력으로 받음\n",
    "decoder_inputs = layers.Input(shape=(None,))\n",
    "\n",
    "# 임베딩 레이어\n",
    "decoder_embedding = layers.Embedding(len(words), embedding_dim)\n",
    "decoder_outputs = decoder_embedding(decoder_inputs)\n",
    "\n",
    "# 인코더와 달리 return_sequences를 True로 설정하여 모든 타임 스텝 출력값 리턴\n",
    "# 모든 타임 스텝의 출력값들을 다음 레이어의 Dense()로 처리하기 위함\n",
    "decoder_lstm = layers.LSTM(lstm_hidden_dim,\n",
    "                           return_state=True,\n",
    "                           return_sequences=True)\n",
    "\n",
    "# initial_state를 인코더의 상태로 초기화\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_outputs,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 단어의 개수만큼 노드의 개수를 설정하여 원핫 형식으로 각 단어 인덱스를 출력\n",
    "decoder_dense = layers.Dense(len(words), activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# 훈련 모델 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 입력과 출력으로 함수형 API 모델 생성\n",
    "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# 학습 방법 설정\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "N1bkvRU0ydzr"
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "#  예측 모델 인코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 훈련 모델의 인코더 상태를 사용하여 예측 모델 인코더 설정\n",
    "encoder_model = models.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "#--------------------------------------------\n",
    "# 예측 모델 디코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 예측시에는 훈련시와 달리 타임 스텝을 한 단계씩 수행\n",
    "# 매번 이전 디코더 상태를 입력으로 받아서 새로 설정\n",
    "decoder_state_input_h = layers.Input(shape=(lstm_hidden_dim,))\n",
    "decoder_state_input_c = layers.Input(shape=(lstm_hidden_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]    \n",
    "\n",
    "# 임베딩 레이어\n",
    "decoder_outputs = decoder_embedding(decoder_inputs)\n",
    "\n",
    "# LSTM 레이어\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_outputs,\n",
    "                                                 initial_state=decoder_states_inputs)\n",
    "\n",
    "# 히든 상태와 셀 상태를 하나로 묶음\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "# Dense 레이어를 통해 원핫 형식으로 각 단어 인덱스를 출력\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# 예측 모델 디코더 설정\n",
    "decoder_model = models.Model([decoder_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubnZvGdnydzs"
   },
   "source": [
    "예측 모델은 이미 학습된 훈련 모델의 레이어들을 그대로 재사용합니다. 예측 모델 인코더는 훈련 모델 인코더과 동일합니다. 그러나 예측 모델 디코더는 매번 LSTM 상태값을 입력으로 받습니다. 또한 디코더의 LSTM 상태를 출력값과 같이 내보내서, 다음 번 입력에 넣습니다. \n",
    "\n",
    "이렇게 하는 이유는 LSTM을 딱 한번의 타임 스텝만 실행하기 때문입니다. 그래서 매번 상태값을 새로 초기화 해야 합니다. 이와 반대로 훈련할때는 문장 전체를 계속 LSTM으로 돌리기 때문에 자동으로 상태값이 전달됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOEiyOizydzt"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "# 훈련 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Gxi2B-vjydzt"
   },
   "outputs": [],
   "source": [
    "# 인덱스를 문장으로 변환\n",
    "def convert_index_to_text(indexs, vocabulary): \n",
    "    \n",
    "    sentence = ''\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for index in indexs:\n",
    "        if index == END_INDEX:\n",
    "            # 종료 인덱스면 중지\n",
    "            break;\n",
    "        if vocabulary.get(index) is not None:\n",
    "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
    "            sentence += vocabulary[index]\n",
    "        else:\n",
    "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
    "            sentence.extend([vocabulary[OOV_INDEX]])\n",
    "            \n",
    "        # 빈칸 추가\n",
    "        sentence += ' '\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "hHjf2nmyB3Pf",
    "outputId": "ece4336b-7ef7-4787-d52a-d44752188248"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3245, 1886, 6060, 4767, 1496, 5142, 6206,  624, 3873,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_encoder[2].reshape(1, x_encoder[2].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DeEaQyYRydzv",
    "outputId": "ac5d1101-601c-4ea3-9322-e3903b8a013a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Epoch : 1\n",
      "115/115 [==============================] - 4s 38ms/step - loss: 1.2817 - accuracy: 0.8150\n",
      "네 이 은 \n",
      "\n",
      "Total Epoch : 2\n",
      "115/115 [==============================] - 4s 38ms/step - loss: 1.2170 - accuracy: 0.8186\n",
      "네 이 이 \n",
      "\n",
      "Total Epoch : 3\n",
      "115/115 [==============================] - 5s 39ms/step - loss: 1.1802 - accuracy: 0.8212\n",
      "네 은 이 \n",
      "\n",
      "Total Epoch : 4\n",
      "115/115 [==============================] - 5s 40ms/step - loss: 1.1474 - accuracy: 0.8248\n",
      "네 거 거 \n",
      "\n",
      "Total Epoch : 5\n",
      "115/115 [==============================] - 5s 39ms/step - loss: 1.1163 - accuracy: 0.8284\n",
      "네 옷 이 \n",
      "\n",
      "Total Epoch : 6\n",
      "115/115 [==============================] - 4s 39ms/step - loss: 1.0841 - accuracy: 0.8329\n",
      "네 거 어떻게 \n",
      "\n",
      "Total Epoch : 7\n",
      "115/115 [==============================] - 5s 40ms/step - loss: 1.0540 - accuracy: 0.8368\n",
      "네 거 어떻게 \n",
      "\n",
      "Total Epoch : 8\n",
      "115/115 [==============================] - 4s 38ms/step - loss: 1.0256 - accuracy: 0.8398\n",
      "네 제품 어떻게 \n",
      "\n",
      "Total Epoch : 9\n",
      "115/115 [==============================] - 4s 39ms/step - loss: 1.0007 - accuracy: 0.8424\n",
      "네 거 없어요 \n",
      "\n",
      "Total Epoch : 10\n",
      "115/115 [==============================] - 4s 38ms/step - loss: 0.9791 - accuracy: 0.8442\n",
      "네 거 어떻게 \n",
      "\n",
      "Total Epoch : 11\n",
      "115/115 [==============================] - 5s 41ms/step - loss: 0.9598 - accuracy: 0.8461\n",
      "네 거 없어요 \n",
      "\n",
      "Total Epoch : 12\n",
      "115/115 [==============================] - 4s 38ms/step - loss: 0.9415 - accuracy: 0.8479\n",
      "네 거 잘 \n",
      "\n",
      "Total Epoch : 13\n",
      "115/115 [==============================] - 5s 42ms/step - loss: 0.9242 - accuracy: 0.8494\n",
      "네 거 어떠세요 \n",
      "\n",
      "Total Epoch : 14\n",
      "115/115 [==============================] - 4s 38ms/step - loss: 0.9078 - accuracy: 0.8511\n",
      "이 쪽 어떠세요 \n",
      "\n",
      "Total Epoch : 15\n",
      "115/115 [==============================] - 5s 39ms/step - loss: 0.8918 - accuracy: 0.8525\n",
      "네 거 어떠세요 \n",
      "\n",
      "Total Epoch : 16\n",
      "115/115 [==============================] - 4s 38ms/step - loss: 0.8763 - accuracy: 0.8540\n",
      "네 거 어떠세요 \n",
      "\n",
      "Total Epoch : 17\n",
      "115/115 [==============================] - 5s 39ms/step - loss: 0.8615 - accuracy: 0.8554\n",
      "네 거 어떠세요 \n",
      "\n",
      "Total Epoch : 18\n",
      "115/115 [==============================] - 4s 38ms/step - loss: 0.8475 - accuracy: 0.8565\n",
      "네 거 어떠세요 \n",
      "\n",
      "Total Epoch : 19\n",
      "115/115 [==============================] - 5s 39ms/step - loss: 0.8339 - accuracy: 0.8578\n",
      "이 거 어떠세요 \n",
      "\n",
      "Total Epoch : 20\n",
      "115/115 [==============================] - 4s 38ms/step - loss: 0.8212 - accuracy: 0.8589\n",
      "네 거 어떠세요 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 에폭 반복\n",
    "for epoch in range(20):\n",
    "    print('Total Epoch :', epoch + 1)\n",
    "\n",
    "    # 훈련 시작\n",
    "    history = model.fit([x_encoder, x_decoder],\n",
    "                        y_decoder,\n",
    "                        epochs=1,\n",
    "                        batch_size=64,\n",
    "                        verbose=1)\n",
    "    # '네 봄 이니까 편하게 신 을 수 있는 거'에 대한 대답\n",
    "    input_encoder = x_encoder[2].reshape(1, x_encoder[2].shape[0])\n",
    "    input_decoder = x_decoder[2].reshape(1, x_decoder[2].shape[0])\n",
    "    results = model.predict([input_encoder, input_decoder])\n",
    "    \n",
    "    # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
    "    # 1축을 기준으로 가장 높은 값의 위치를 구함\n",
    "    indexs = np.argmax(results[0], 1) \n",
    "    \n",
    "    # 인덱스를 문장으로 변환\n",
    "    sentence = convert_index_to_text(indexs, index_to_word)\n",
    "    print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTaUvGrqydzy"
   },
   "source": [
    "학습이 진행될수록 예측 문장이 제대로 생성되는 것을 볼 수 있습니다. 다만 여기서의 예측은 단순히 테스트를 위한 것이라, 인코더 입력과 디코더 입력 데이터가 동시에 사용됩니다. 아래 문장 생성에서는 예측 모델을 적용하기 때문에, 오직 인코더 입력 데이터만 집어 넣습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3wHpkRaydzy"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "# 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "2E66RpbXydzy"
   },
   "outputs": [],
   "source": [
    "# 예측을 위한 입력 생성\n",
    "def make_predict_input(sentence):\n",
    "\n",
    "    sentences = []\n",
    "    sentences.append(sentence)\n",
    "    sentences = pos_tag(sentences)\n",
    "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
    "    \n",
    "    return input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "nUV-fKE0ydz0"
   },
   "outputs": [],
   "source": [
    "# 텍스트 생성\n",
    "def generate_text(input_seq):\n",
    "    \n",
    "    # 입력을 인코더에 넣어 마지막 상태 구함\n",
    "    states = encoder_model.predict(input_seq)\n",
    "\n",
    "    # 목표 시퀀스 초기화\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    # 목표 시퀀스의 첫 번째에 <START> 태그 추가\n",
    "    target_seq[0, 0] = STA_INDEX\n",
    "    \n",
    "    # 인덱스 초기화\n",
    "    indexs = []\n",
    "    \n",
    "    # 디코더 타임 스텝 반복\n",
    "    while 1:\n",
    "        # 디코더로 현재 타임 스텝 출력 구함\n",
    "        # 처음에는 인코더 상태를, 다음부터 이전 디코더 상태로 초기화\n",
    "        decoder_outputs, state_h, state_c = decoder_model.predict(\n",
    "                                                [target_seq] + states)\n",
    "\n",
    "        # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
    "        index = np.argmax(decoder_outputs[0, 0, :])\n",
    "        indexs.append(index)\n",
    "        \n",
    "        # 종료 검사\n",
    "        if index == END_INDEX or len(indexs) >= max_sequences:\n",
    "            break\n",
    "\n",
    "        # 목표 시퀀스를 바로 이전의 출력으로 설정\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = index\n",
    "        \n",
    "        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n",
    "        states = [state_h, state_c]\n",
    "\n",
    "    # 인덱스를 문장으로 변환\n",
    "    sentence = convert_index_to_text(indexs, index_to_word)\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "xghcWc8Gydz2",
    "outputId": "83dbc472-54cf-4781-9333-0540560eac35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1541,  307, 1754, 1072,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('이 티셔츠 사이즈 있나요')\n",
    "input_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "SAVCqw5kydz4",
    "outputId": "f89a1daf-0daf-451b-b3a1-ac6d340c66fb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'네 잠시 만 기다려주세요 '"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTJaDU2Oydz9"
   },
   "source": [
    "데이터셋 문장에서는 없던 '같이'라는 단어를 추가해 보았습니다. 그래도 비슷한 의미란 것을 파악하여 동일한 답변이 나왔습니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "0nfzs40Jydz9",
    "outputId": "c14560de-e79a-4e5b-990e-99d1ffd90106"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2393, 5592,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('교환 가능한가요?')\n",
    "input_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "CfAuRhDwydz_",
    "outputId": "d7ada4a4-b142-47a7-d9dc-94b296b8d301"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'네 가능합니다 '"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "z3YqOZ-MEOVW",
    "outputId": "16e4dc25-59d5-41d1-cba9-5adce2067109"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고객 :  신발 은 여기 있는 게 다예 요\n",
      "정답점원 : 네 성인 이나 아동 다 있어요 발 사이즈 몇 신으세요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  230 이요\n",
      "정답점원 : 편하게 신 을 수 있는 거 찾으세요\n",
      "AI점원 : 네 그럼요 \n",
      "\n",
      "\n",
      "고객 :  네 봄 이니까 편하게 신 을 수 있는 거\n",
      "정답점원 : 이런 건 어떠세요 이런 거도 신발 무척 편하거든요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  굽 좀 높은 거 없나요\n",
      "정답점원 : 봄 상품 은 아직 어른 제품 이 많이 안 나왔습니다\n",
      "AI점원 : 네 이 쪽 에 있습니다 \n",
      "\n",
      "\n",
      "고객 :  언제 들어와요\n",
      "정답점원 : 이번 주 지나면 들어올 거 예요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이 거 는 가죽 이에요\n",
      "정답점원 : 가죽 아니고 쎄 무예 요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  가죽 은 얼마 예요\n",
      "정답점원 : 2만 9천 원 입니다\n",
      "AI점원 : 그 옷 은 이만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  털 달린 거 저 거 는 사이즈 있어요\n",
      "정답점원 : 230 이 없어요 이 거 한 번 신어 보세요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  좀 크네 또 안 들어와요\n",
      "정답점원 : 네 이건 다 끝났어요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  가방 매는 거 보고 있어요\n",
      "정답점원 : 여기 있어요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  가격 이 얼마 예요\n",
      "정답점원 : 이 종류 는 2만 원 이고 이 종류 는 3만 8천 원 이에요\n",
      "AI점원 : 이 거 는 삼만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  가죽 으로 된 거 는 없어요\n",
      "정답점원 : 가죽 은 없고 레자 만 있어요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  레자 는 얼마 예요\n",
      "정답점원 : 5만 5천 원요\n",
      "AI점원 : 그 가방 은 이만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  이 거 는 천이 죠\n",
      "정답점원 : 네 맞아요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이건 얼마 예요\n",
      "정답점원 : 그것 도 5만 5천 원요\n",
      "AI점원 : 그 가방 은 이만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  이 거 끈 은 따로 없어요\n",
      "정답점원 : 안 에 있어요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  내일 은 문 열어요\n",
      "정답점원 : 휴무 입니다\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  며칠 까지 휴무 예요\n",
      "정답점원 : 설 까지 쉬 고 다음 날 열 거 같아요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  여기 마스크 는 얼마 예요\n",
      "정답점원 : 5천 원요\n",
      "AI점원 : 이 거 는 삼만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  이 거 나무 예요 다 돌 인가요\n",
      "정답점원 : 나무 도 있고 도자기 도 있어요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이런 건 세트 로 팔아요\n",
      "정답점원 : 네 세트 로만 팔아요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이건 뭐 예요\n",
      "정답점원 : 마블 이라고 종이 를 말아가지고 하는 거 예요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  제일 큰 거 는 얼마 인데 요\n",
      "정답점원 : 세트 에 7만 원 이요\n",
      "AI점원 : 이 거 는 삼만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  스카프 좀 보려구요\n",
      "정답점원 : 네 천천히 보세요\n",
      "AI점원 : 네 잠시 만 기다려주세요 \n",
      "\n",
      "\n",
      "고객 :  실크 스카프 도 봄 에 하나요\n",
      "정답점원 : 실크 봄 가을 에 하죠\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이 거 는 뭐 예요\n",
      "정답점원 : 토시 예요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  여기 가격 은 그대로 파시 는 거 예요\n",
      "정답점원 : 네 핸드 메이드 로 해가지고 그 가격 으로 팔아요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  착용 해볼 수 있어요\n",
      "정답점원 : 네 가능하세요\n",
      "AI점원 : 네 알겠습니다 \n",
      "\n",
      "\n",
      "고객 :  이 거 는 요즘 들어온 거 예요\n",
      "정답점원 : 네 어제 들어왔어요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  세탁 은 물 세탁 되죠\n",
      "정답점원 : 끝 부분 이 가죽 이라서 조심해야 해 요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  지금 여기 있는 게 다예 요\n",
      "정답점원 : 네 다예 요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  몇 시 에 문 닫아요\n",
      "정답점원 : 8시 까지 합니다\n",
      "AI점원 : 그거 는 삼만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  일요일 도 하세요\n",
      "정답점원 : 아뇨 닫아요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  스카프 있어요\n",
      "정답점원 : 네 여기는 2 단 이 거 는 3 단 제품 있어요\n",
      "AI점원 : 네 이 쪽 에 있습니다 \n",
      "\n",
      "\n",
      "고객 :  이런 건 세탁 을 어떻게 해 요\n",
      "정답점원 : 울 샴푸 를 물 에 몇 방울 떨어뜨려서 조물조물 하면 됩니다\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  원단 은 뭐 예요\n",
      "정답점원 : 원단 이 구김 안 가고 참 괜찮아요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  얼마 인데 요\n",
      "정답점원 : 2만 원 입니다\n",
      "AI점원 : 그 가방 은 이만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  브로치 같은 건 어디 있나요\n",
      "정답점원 : 여기 있는 거 밖에 없어요\n",
      "AI점원 : 이 거 는 어떠세요 \n",
      "\n",
      "\n",
      "고객 :  이런 거도 2만 원 이예 요\n",
      "정답점원 : 헤르메스 인데 이 것 도 괜찮아요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  명품 이랑 똑같이 한 거 예요\n",
      "정답점원 : 네 원단 만 다르고 디자인 을 똑같이 만든 거 예요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  온누리 상품권 도 되죠\n",
      "정답점원 : 네 됩니다\n",
      "AI점원 : 네 가능합니다 \n",
      "\n",
      "\n",
      "고객 :  브로치 하고 머리핀 하고 보려고요\n",
      "정답점원 : 머리핀 은 밖에 있고 브로치 는 안 에 있습니다\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  도자기 같은 거 말고 구슬 이나 진주 같은 거 는 없어요\n",
      "정답점원 : 지금 옷 에 가볍게 하려면 진주 도 예쁘지만 이 것 도 깔끔합니다 보석 은 싫으세요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  그건 흥미 없고 안 에 하면 안 떨어져요\n",
      "정답점원 : 안 떨어져요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  얼마 예요\n",
      "정답점원 : 핀 꼽는 거 는 좀 싼 거고 이 거 는 3만 원대 예요\n",
      "AI점원 : 그 가방 은 이만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  이 우산 은 얼마 인데 요\n",
      "정답점원 : 4만 2천 원 이요\n",
      "AI점원 : 이 거 는 삼만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  무겁지 않아요\n",
      "정답점원 : 좋은 재료 를 쓰기 때문 에 무겁지 않아요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이렇게 다는 거 맞아요\n",
      "정답점원 : 그렇게 달 면 안되고 이렇게 달아야 해 요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  자석 은 다 3만 원\n",
      "정답점원 : 3만 원 짜 리도 있고 2만 원 짜 리도 있어요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  머리핀 종류 도 한 번 보여주세요 곱창 은 요새 안 나와요\n",
      "정답점원 : 곱창 밴드 는 안 나와요 촌스러워서 유행 다 지났어요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  브로치 종류 도 있어요\n",
      "정답점원 : 아뇨 없어요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  스카프 도 없어요\n",
      "정답점원 : 스카프 는 이 쪽 에 종류 가 있어요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이런 거 실크 입 니까\n",
      "정답점원 : 실크 아니예요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이런 거 는 뭐라 그래요\n",
      "정답점원 : 실캣 으로 만든 거 죠\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이런 거 는 얼마 예요\n",
      "정답점원 : 대충 2만 원 내외 요\n",
      "AI점원 : 이 거 는 삼만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  이런 거 는 물 세탁 됩니까\n",
      "정답점원 : 물 세탁 조금 해도 상관 은 없으세요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  근데 이 거 제 가 한 거 아닌데 약간 올이 나갔네요\n",
      "정답점원 : 이 거 원하시면 주문 가능하세요\n",
      "AI점원 : 네 그럼요 \n",
      "\n",
      "\n",
      "고객 :  또 언제 들어와요\n",
      "정답점원 : 스카프 는 많이 들어오지 않아서 주문 하시는 게 좋아요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이 거 는 목걸이 링 이에요\n",
      "정답점원 : 아뇨 반지 예요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  금 이에요\n",
      "정답점원 : 액세서리 예요 금 아니예요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이 거 한 번 해봐도 돼요\n",
      "정답점원 : 네 가능합니다\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  신 상품 더 들어오죠\n",
      "정답점원 : 네 들어올 거 예요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이 모양 으로 목걸이 팔찌 세트 구입 할까 하는데\n",
      "정답점원 : 똑같은 모양 은 주문 을 넣어야 할 거 같은데요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  가격 은 어떻게 돼요\n",
      "정답점원 : 모양 을 보고 견적 을 내 봐야 해 요\n",
      "AI점원 : 이 거 는 없어요 \n",
      "\n",
      "\n",
      "고객 :  이 금 팔찌 는 무게 가 얼마 정도 인지 확인 할 수 있어요\n",
      "정답점원 : 세 돈 이 조금 넘네요\n",
      "AI점원 : 그거 는 만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  견본 인 팔찌 가 있어요\n",
      "정답점원 : 여기 있습니다\n",
      "AI점원 : 네 잠시 만 기다려주세요 \n",
      "\n",
      "\n",
      "고객 :  여기는 금 매입 도 해 요\n",
      "정답점원 : 네 해 요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이 거 판다 고 얼마 정도 받을 수 있어요\n",
      "정답점원 : 대충 39만 3천 원 정도 나오네요\n",
      "AI점원 : 그 가방 은 이만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  팔찌 두 돈 짜 리도 한 번 보여주시고 다른 거도 보여주세요\n",
      "정답점원 : 유행 하는 로 즈 골드 하셔도 되고 골드 하셔도 돼요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  가격 이 구입 하려면 얼마 인데 요\n",
      "정답점원 : 현금 가격 기준 으로 62만 9천 원 이요\n",
      "AI점원 : 이 거 는 삼만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  이 거 18 케이 예요\n",
      "정답점원 : 네 18 케이 예요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  시내 에 있는 금 도매 상 하고 여기 랑 가격 차이 가 많이 나 요\n",
      "정답점원 : 그 쪽 은 유지비 가 많이 나가니까 아무래도 여기 가 더 싸죠\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  액세서리 세 일 제품 이 있나요\n",
      "정답점원 : 악세서리 어떤 거 찾으세요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  스카프 같은 거\n",
      "정답점원 : 이 거 괜찮아요\n",
      "AI점원 : 네 잠시 만 기다려주세요 \n",
      "\n",
      "\n",
      "고객 :  이건 소재 가 뭐 예요\n",
      "정답점원 : 폴리에스테르 라고 적혀 있네요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  색상 은 이 거 하나 뿐 이고\n",
      "정답점원 : 네 다 빠지고 이 거 하나 예요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  빨 면 좀 그렇지 않을까\n",
      "정답점원 : 조심해야 하는데 면 이 아니니까 집 에서 손 드라이 해도 돼요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이 거 는 가격 이 얼마 예요\n",
      "정답점원 : 16000원 인데 몇 천 원 빼 드릴게요\n",
      "AI점원 : 이 거 는 삼만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  이건 얼마 예요\n",
      "정답점원 : 13000원 입니다\n",
      "AI점원 : 그 가방 은 이만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  이 핑크색 모자 는 애기 들 꺼예요\n",
      "정답점원 : 애기 용 입니다\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  어른 들 꺼는 없어요\n",
      "정답점원 : 다 빠졌어요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  팔찌 제품 따로 있나요\n",
      "정답점원 : 고객 님 이 하실 거 예요\n",
      "AI점원 : 네 이 쪽 에 있습니다 \n",
      "\n",
      "\n",
      "고객 :  네 지금 세 일 기간 이에요\n",
      "정답점원 : 네 당분간 은 할 거 같아요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  한 몇 프로 하는데요\n",
      "정답점원 : 정가 에서 한 40 프로 합니다\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이 거 는 가격 대가 얼마 예요\n",
      "정답점원 : 이 거 샘플 이 14 케이 인데 뭘 로 봐 드릴 까요\n",
      "AI점원 : 이 거 는 삼만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  18 케이 로\n",
      "정답점원 : 18 케이 로 하시면 49만 원 이요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  팔찌 좀 핫 한 제품 뭐 가 있어요\n",
      "정답점원 : 깔끔하게 이런 거 잘나가요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  18 케이 예요\n",
      "정답점원 : 네 맞아요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  돈 수로 따지면 몇 돈 이에요\n",
      "정답점원 : 두 돈반 조금 안 돼요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  얼마 예요\n",
      "정답점원 : 48만 원 정도 요\n",
      "AI점원 : 그 가방 은 이만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  굵은 게 이 거 다예 요\n",
      "정답점원 : 5 돈 6 돈 짜 리도 있어요 굵은 거 찾으시면 이런 건 어떠세요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  너무 사치스러운데 핸드폰 케이스 파는 거 예요\n",
      "정답점원 : 네 맞습니다\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  여기는 가격 이 어떤 게 있어요\n",
      "정답점원 : 기 종이 어떻게 되죠\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  엘지 인데\n",
      "정답점원 : 만 오천 원대 부터 시작 해서 이만 오천 원 까지 있습니다\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  그건 얼마 예요\n",
      "정답점원 : 3만 원 정도 해 요\n",
      "AI점원 : 그 가방 은 이만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  색상 은 이 게 전부 예요\n",
      "정답점원 : 레드 색 인데 핑크 도 있고 보랏빛 퍼플 색도 있고 색상 종류 가 다양해요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  엘지 지 식스 케이스 로 좀 보여주세요\n",
      "정답점원 : 그 기종은 여기 있어요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  이건 얼마 예요\n",
      "정답점원 : 3만 5천 원 입니다\n",
      "AI점원 : 그 가방 은 이만 원 이에요 \n",
      "\n",
      "\n",
      "고객 :  현금 으로 사면 할인 이 된다거나 그런 게 있나요\n",
      "정답점원 : 현금 으로 하면 좀 디씨 해드려요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n",
      "고객 :  반지 이 거 세척 가능해요\n",
      "정답점원 : 월요일 에 해야 해 요\n",
      "AI점원 : 네 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for train data predict\n",
    "for seq_index in range(0,100):\n",
    "\n",
    "  print(\"고객 : \",question[seq_index])\n",
    "  print(\"정답점원 :\",answer[seq_index])\n",
    "  print(\"AI점원 :\",generate_text(make_predict_input(question[seq_index])))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOBDpAVqFOW_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Seq2Seq_Chatbot_의류.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
