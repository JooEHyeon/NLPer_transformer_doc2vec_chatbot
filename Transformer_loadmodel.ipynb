{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Transformer_loadmodel.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ioT3c4eLEKon",
        "jx-jxXncYmlp",
        "e6EDnEOwI_G7"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ideablast/NLPer_transformer_doc2vec_chatbot/blob/kdg/Transformer_loadmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsiilWsMNHHL",
        "outputId": "f6010c79-6e9b-485f-d720-21adcef7f939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install konlpy\n",
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 11.3MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/96/1030895dea70855a2e1078e3fe0d6a63dcb7c212309e07dc9ee39d33af54/JPype1-1.1.2-cp36-cp36m-manylinux2010_x86_64.whl (450kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 53.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: colorama, beautifulsoup4, tweepy, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.1.2 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n",
            "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
            "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-52ce62dz\n",
            "  Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-52ce62dz\n",
            "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.3.0)\n",
            "Requirement already satisfied: keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.4.3)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.10.0)\n",
            "Collecting argparse>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (3.3.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.18.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.33.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (2.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.3.3)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.35.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.4.3->pykospacing==0.3) (3.13)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.10)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.0.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.4.0)\n",
            "Building wheels for collected packages: pykospacing\n",
            "  Building wheel for pykospacing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykospacing: filename=pykospacing-0.3-cp36-none-any.whl size=2255638 sha256=5bf2bc66a27fde64d295758b287dee19bd1aa0067d6bf039b0ffe11ada712282\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0qsie523/wheels/4d/45/58/e26cb2b7f6a063d234158c6fd1e5700f6e15b99d67154340ba\n",
            "Successfully built pykospacing\n",
            "Installing collected packages: argparse, pykospacing\n",
            "Successfully installed argparse-1.4.0 pykospacing-0.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ssut/py-hanspell.git\n",
            "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-8ywsr9j5\n",
            "  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-8ywsr9j5\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from py-hanspell==1.1) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n",
            "Building wheels for collected packages: py-hanspell\n",
            "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-hanspell: filename=py_hanspell-1.1-cp36-none-any.whl size=4854 sha256=6546f3df7c53d71c5391aca5f5d3418f0dfeede005ba671e1089acfdbbd90963\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2ntcudqm/wheels/0a/25/d1/e5e96476dbb1c318cc26c992dd493394fe42b0c204b3e65588\n",
            "Successfully built py-hanspell\n",
            "Installing collected packages: py-hanspell\n",
            "Successfully installed py-hanspell-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UA-8fQ2EDnp"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DAFy5c7ydzC"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers, losses, metrics\n",
        "from keras import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from hanspell import spell_checker\n",
        "from pykospacing import spacing\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioT3c4eLEKon"
      },
      "source": [
        "## Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9YUdE1OydzG"
      },
      "source": [
        "# 태그 단어\n",
        "PAD = \"<PADDING>\"   # 패딩\n",
        "STA = \"<START>\"     # 시작\n",
        "END = \"<END>\"       # 끝\n",
        "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
        "\n",
        "# 태그 인덱스\n",
        "PAD_INDEX = 0\n",
        "STA_INDEX = 1\n",
        "END_INDEX = 2\n",
        "OOV_INDEX = 3\n",
        "\n",
        "# 데이터 타입\n",
        "ENCODER_INPUT  = 0\n",
        "DECODER_INPUT  = 1\n",
        "DECODER_TARGET = 2\n",
        "\n",
        "# Hyper-parameters for Transformer\n",
        "NUM_LAYERS = 2 # Encdoer, Decoder layer수(각각)\n",
        "D_MODEL = 256 # word embedding dimension\n",
        "NUM_HEADS = 8 # attention 헤드 수. D_Model % NUM_HEADS == 0이 되야 함!\n",
        "UNITS = 512 # FFNN 유닛수\n",
        "DROPOUT = 0.1 #dropout rate\n",
        "EPOCHS = 50 ## Transformer, C,M Classification 에폭(에너르기폭발)\n",
        "# for Transformer data pipelining\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "# VOCAB_SIZE = 0 # 단어사전이 보유한 단어의 개수. 후에 len(words) 로 바뀜.\n",
        "# 한 문장에서 단어의 최대 개수\n",
        "max_sequences = 30\n",
        "# 정규 표현식 필터\n",
        "RE_FILTER = re.compile(\"[\\\"':;~()]\")"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhVVnW_uEWT1"
      },
      "source": [
        "## Data Load & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80IauV0FpUv2",
        "outputId": "d586bb8f-8980-45cb-aac7-eb9ed1e9e0d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEHDnPXNzZlM",
        "outputId": "ab79acda-c78d-4c15-a87a-d583a30214dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wear_data = pd.read_csv(\"/content/drive/My Drive/wear_MAIN_edited.csv\")\n",
        "print(wear_data.shape)\n",
        "customer = wear_data[wear_data.SPEAKER == \"고객\"].SENTENCE\n",
        "store = wear_data[wear_data.SPEAKER == \"점원\"].SENTENCE\n",
        "print(customer.shape, store.shape) # 질문의 개수와 답의 개수가 일치하지 않는다."
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15826, 20)\n",
            "(8381,) (7445,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLNSiqcHM4WY"
      },
      "source": [
        "prev = \"고객\"\n",
        "store_arr = []\n",
        "customer_arr = []\n",
        "store_stc = \"\"\n",
        "customer_stc = \"\"\n",
        "customer_C = \"\" #고객의 마지막 문장의 CATEGORY\n",
        "customer_M = \"\" #고객의 마지막 문장의 의도\n",
        "\n",
        "c_m = []\n",
        "for i in range(wear_data.shape[0]):\n",
        "    customer_C = wear_data.iloc[i].CATEGORY\n",
        "    customer_M = wear_data.iloc[i].MAIN\n",
        "    if (prev == wear_data.iloc[i].SPEAKER):\n",
        "        if prev == \"점원\":\n",
        "             store_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "        else : \n",
        "             customer_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "            \n",
        "    elif prev == \"점원\": # 점원 -> 고객\n",
        "        store_arr.append(store_stc)\n",
        "        customer_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"고객\"\n",
        "    else : # 고객 -> 점원\n",
        "        customer_arr.append(customer_stc)\n",
        "        c_m.append([customer_C,customer_M])\n",
        "        store_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"점원\"\n",
        "\n",
        "# print(len(store_arr))\n",
        "# print(len(customer_arr))\n",
        "# print(store_arr[-1])\n",
        "# print(customer_arr[-1]) # 자료 상에서 이후에는 계속 고객의 물음만 계속된다. 코드 레벨에서 이 부분은 빼게 구현했다. (stc는 만들어지지만 arr에 append 안하게 된다.)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByO6b_S10b6m"
      },
      "source": [
        "faqs = []\n",
        "for i in range(len(store_arr)):\n",
        "    faqs_tmp =[]\n",
        "    faqs_tmp.append(str(i+1))\n",
        "    faqs_tmp.append(customer_arr[i])\n",
        "    faqs_tmp.append(store_arr[i])\n",
        "\n",
        "    faqs.append(faqs_tmp)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSC-cPrN7Sen"
      },
      "source": [
        "for i in range(len(faqs)):\n",
        "  faqs[i].extend(c_m[i])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUOvBciM4G2g"
      },
      "source": [
        "category_arr = []\n",
        "main_arr = []\n",
        "for i in faqs:\n",
        "  category_arr.append(i[3])\n",
        "  main_arr.append(i[4])\n",
        "\n",
        "category_set = set(category_arr)\n",
        "main_set = set(main_arr)\n",
        "\n",
        "category_to_index = {word: index for index, word in enumerate(category_set)}\n",
        "main_to_index = {word: index for index, word in enumerate(main_set)} #질문의 의도만 가져오다보니 405개에서 387개로 줄어들음\n",
        "\n",
        "index_to_category = {index: word for index, word in enumerate(category_set)}\n",
        "index_to_main = {index: word for index, word in enumerate(main_set)}"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IBBlpka5yNP"
      },
      "source": [
        "for i,item in enumerate(faqs):\n",
        "  faqs[i][3] = category_to_index[item[3]]\n",
        "  faqs[i][4] = main_to_index[item[4]]"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNvig2FMzjXj",
        "outputId": "296224c9-6584-4d94-eb05-942f6bc68b9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "question = []\n",
        "answer = []\n",
        "\n",
        "for Q in customer_arr:\n",
        "    question.append(Q.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "for A in store_arr:\n",
        "    answer.append(A.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "len(question), len(answer)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7301, 7301)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbivSckMydzN"
      },
      "source": [
        "# 형태소분석 함수\n",
        "def pos_tag(sentences):\n",
        "    \n",
        "    # KoNLPy 형태소분석기 설정\n",
        "    tagger = Okt()\n",
        "    \n",
        "    # 문장 품사 변수 초기화\n",
        "    sentences_pos = []\n",
        "    \n",
        "    # 모든 문장 반복\n",
        "    for sentence in sentences:\n",
        "        # [\\\"':;~()] 특수기호 제거\n",
        "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
        "        \n",
        "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
        "        sentence = \" \".join(tagger.morphs(sentence))\n",
        "        sentences_pos.append(sentence)\n",
        "        \n",
        "    return sentences_pos"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seqSNWcydzP",
        "outputId": "7fc5893d-0fca-464d-aacc-60d0b185ced3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 형태소분석 수행\n",
        "question = pos_tag(question)\n",
        "answer = pos_tag(answer)\n",
        "\n",
        "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
        "for i in range(5):\n",
        "    print('Q : ' + question[i])\n",
        "    print('A : ' + answer[i])\n",
        "    print()\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q : 신발 은 여기 있는 게 다예 요 ?\n",
            "A : 네 성인 이나 아동 다 있어요 발 사이즈 몇 신으세요 ?\n",
            "\n",
            "Q : 230 이요\n",
            "A : 편하게 신 을 수 있는 거 찾으세요 ?\n",
            "\n",
            "Q : 네 봄 이니까 편하게 신 을 수 있는 거\n",
            "A : 이런 건 어떠세요 ? 이런 거도 신발 무척 편하거든요\n",
            "\n",
            "Q : 굽 좀 높은 거 없나요 ?\n",
            "A : 봄 상품 은 아직 어른 제품 이 많이 안 나왔습니다\n",
            "\n",
            "Q : 언제 들어와요 ?\n",
            "A : 이번 주 지나면 들어올 거 예요\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrnct_nzydzR"
      },
      "source": [
        "# 질문과 대답 문장들을 하나로 합침\n",
        "sentences = []\n",
        "sentences.extend(question)\n",
        "sentences.extend(answer)\n",
        "\n",
        "words = [] # 단어사전\n",
        "\n",
        "# 단어들의 배열 생성\n",
        "for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "        words.append(word)\n",
        "\n",
        "# 길이가 0인 단어는 삭제\n",
        "words = [word for word in words if len(word) > 0]\n",
        "\n",
        "# 중복된 단어 삭제\n",
        "words = list(set(words))\n",
        "\n",
        "# 제일 앞에 태그 단어 삽입\n",
        "words[:0] = [PAD, STA, END, OOV]"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE9ZhJpEy_rT",
        "outputId": "57ac0b8d-7fd4-4cd2-b095-73f9fcb125f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "VOCAB_SIZE = len(words)\n",
        "print(\"손님과 점원의 말에서 사용된 총 단어의 수 :\",len(words))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "손님과 점원의 말에서 사용된 총 단어의 수 : 6409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN-hToCq2QL3",
        "outputId": "ee142b31-cc81-42fd-95eb-b7e38ee52f70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "words[:10]"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<PADDING>',\n",
              " '<START>',\n",
              " '<END>',\n",
              " '<OOV>',\n",
              " '봤을',\n",
              " '묻어요',\n",
              " '부드러워',\n",
              " '돼가고',\n",
              " '요렇게',\n",
              " '와이셔츠']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkvyOnSvydzX"
      },
      "source": [
        "# 단어와 인덱스의 딕셔너리 생성\n",
        "word_to_index = {word: index for index, word in enumerate(words)}\n",
        "index_to_word = {index: word for index, word in enumerate(words)}"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfoTztrvydzc"
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "def convert_text_to_index(sentences, vocabulary, type): \n",
        "    \n",
        "    sentences_index = []\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for sentence in sentences:\n",
        "        sentence_index = []\n",
        "        \n",
        "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
        "        if type == DECODER_INPUT:\n",
        "            sentence_index.extend([vocabulary[STA]])\n",
        "        \n",
        "        # 문장의 단어들을 띄어쓰기로 분리\n",
        "        for word in sentence.split():\n",
        "            if vocabulary.get(word) is not None:\n",
        "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[word]])\n",
        "            else:\n",
        "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "        # 최대 길이 검사\n",
        "        if type == DECODER_TARGET:\n",
        "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
        "            if len(sentence_index) >= max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
        "            else:\n",
        "                sentence_index += [vocabulary[END]]\n",
        "        else:\n",
        "            if len(sentence_index) > max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences]\n",
        "            \n",
        "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "        \n",
        "        # 문장의 인덱스 배열을 추가\n",
        "        sentences_index.append(sentence_index)\n",
        "\n",
        "    return np.asarray(sentences_index)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zezFPTvcydzf",
        "outputId": "79151034-eafa-4e1d-c8a2-57128eea305a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 인코더 입력 인덱스 변환\n",
        "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
        "\n",
        "# 첫 번째 인코더 입력 출력 (신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_encoder[0]\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5710, 4500, 1797, 1637, 1033, 1366, 5280, 4566,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmql1Lf_ydzh",
        "outputId": "825366f2-a3d1-4c02-dda7-d4ebc074f8a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 입력 인덱스 변환\n",
        "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (<START> 신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_decoder[0]\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1, 3991, 6319, 1725, 1827, 2017,  441,  676, 1785, 3351, 3883,\n",
              "       4566,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIhDbaLydzk",
        "outputId": "00f202b0-c12c-4a84-fd89-25d120161bb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 목표 인덱스 변환\n",
        "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (신발 은 여기 있는 게 다예 요 <END>)\n",
        "print(question[0])\n",
        "y_decoder[0]\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3991, 6319, 1725, 1827, 2017,  441,  676, 1785, 3351, 3883, 4566,\n",
              "          2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsf4tJl61Xi9"
      },
      "source": [
        "## Transformer 설계\n",
        " - data pipelining\n",
        " - Encoder layer * 2 => Encoder\n",
        " - Decoder layer * 2 => Decoder\n",
        " - Encoder + Decoder => Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsxmXWS41XVd"
      },
      "source": [
        "# decoder inputs use the previous target as input\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': x_encoder,\n",
        "        'dec_inputs': x_decoder\n",
        "    },\n",
        "    {\n",
        "        'outputs': y_decoder\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxXCQWvw2jwx"
      },
      "source": [
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH-k-kk_1_Vu"
      },
      "source": [
        "## scaled dot product Attention\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True) # QK^T\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth) #  QK^T / sqrt(d_k)\n",
        "\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9) # zero padding token softmax 결과가 0이 나오도록\n",
        "  \n",
        "  attention_weights = tf.nn.softmax(logits, axis = -1) # softmax(QK^T / sqrt(d_k))\n",
        "\n",
        "  output = tf.matmul(attention_weights, value) # softmax(QK^T / sqrt(d_k)) * V\n",
        "\n",
        "  return output"
      ],
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7orcKMr13xY8"
      },
      "source": [
        "## multi-head attention\n",
        "## each head need (scaled_dot_product_attention)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\", **kwargs):\n",
        "    super(MultiHeadAttention, self).__init__(name=name, **kwargs)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert self.d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = 32\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "  \n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    config.update({\n",
        "        'num_heads' : self.num_heads,\n",
        "        'd_model': self.d_model,\n",
        "        'depth' : self.depth\n",
        "    })\n",
        "    return config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(inputs, shape=(batch_size,-1,self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3]) ##????\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    #linear\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    #split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    #scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    #concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "\n",
        "    #final linear\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 394,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmlW0oi89nEC"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W7ld50z3vT2"
      },
      "source": [
        "# it handle mask future tokens in a sequence used decoder. and mask pad tokens\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 396,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLhXEIJgASo3"
      },
      "source": [
        "Positional encoding\n",
        "\n",
        "since we don't use any rnn, cnn, positional encoding give model position information of words in sentence.\n",
        "\n",
        "positional encoding vector is added to embedding vector\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7s19-x3_Hpq"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model, **kwargs):\n",
        "    super(PositionalEncoding, self).__init__(**kwargs)\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "    self.position = position\n",
        "    self.d_model = d_model\n",
        "\n",
        "  def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'position': self.position,\n",
        "            'd_model': self.d_model,\n",
        "        })\n",
        "        return config\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)\n",
        "\n",
        "  \n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles #pos/10000^(2i/d_model)\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position = tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model = d_model)\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLiumNZZDZGY"
      },
      "source": [
        "### Encoder Layer\n",
        "1. Multi-head attention (with padding mask)\n",
        "2. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oarRWUMLDYnC"
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query':inputs,\n",
        "          'key':inputs,\n",
        "          'value':inputs,\n",
        "          'mask':padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3rO9IcDHGE5"
      },
      "source": [
        "### Encoder\n",
        "1. Input Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` encoder layers\n",
        "\n",
        "Embedding + positional encoding : input\n",
        "\n",
        "going encoder layers.\n",
        "\n",
        "output going decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOwoi2_jHvbA"
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)#??왜 vocab_size가 들어가지?\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, padding_mask], outputs = outputs, name=name)"
      ],
      "execution_count": 399,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8XHH5dpJr-G"
      },
      "source": [
        "### Decoder Layer\n",
        "1. Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2. Multi-head attention (with padding mask). `value` and `key` is from encoder output. `query` is from Multi-head attention layer output\n",
        "3. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtAfKdk-JrxK"
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name=\"padding_mask\")\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query' : inputs,\n",
        "          'key' : inputs,\n",
        "          'value' : inputs,\n",
        "          'mask' : look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query' : attention1,\n",
        "          'key' : enc_outputs,\n",
        "          'value' : enc_outputs,\n",
        "          'mask' : padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnBSBcm1NAYv"
      },
      "source": [
        "### Decoder\n",
        "1. output Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` decoder layers\n",
        "\n",
        "Embedding + positional encoding : input (target)\n",
        "\n",
        "going decoder layers.\n",
        "\n",
        "output going final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnA-8FEAOT4F"
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"decoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name='padding_mask')\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"decoder_layer_{}\".format(i),\n",
        "    )(inputs = [outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-vmtqKQjhf"
      },
      "source": [
        "### Transformer\n",
        "1. encoder\n",
        "2. decoder\n",
        "3. final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEMfL5SFQqr4"
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"enc_padding_mask\")(inputs)\n",
        "  \n",
        "  #mask future tokens for decoder inputs at 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1,None,None),\n",
        "      name=\"look_ahead_mask\")(dec_inputs)\n",
        "  \n",
        "  #mask encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"dec_padding_mask\")(inputs)\n",
        "  \n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pav-8Jd3ydzp"
      },
      "source": [
        "## Transformer 생성\n",
        " - custom loss\n",
        " - custom learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8y-mjWtydzp"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK3IwtA4TOnN"
      },
      "source": [
        "### Loss function\n",
        "since target sequences are padded, deal this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi7YnqpVTYn2"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "  \n",
        "  mask = tf.cast(tf.not_equal(y_true,0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzHEmCzUVhTu"
      },
      "source": [
        "### Custom learning rate\n",
        "use Adam optimizer with custom learning rate\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkFm9m_LVt8c"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        'd_model':256,\n",
        "        'warmup_steps':self.warmup_steps\n",
        "    }\n",
        "    return config\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "      return cls(**config)\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 405,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb8PGbKgWAbP"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vql4FYFUV_3_"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTXbb1Z2I4IM"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl3V7BllWWFG",
        "outputId": "64c4866b-33bb-4ff6-f76d-78b5625e67c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 1.9772 - accuracy: 0.0205\n",
            "Epoch 2/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 1.7333 - accuracy: 0.0343\n",
            "Epoch 3/50\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 1.4773 - accuracy: 0.0428\n",
            "Epoch 4/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 1.3231 - accuracy: 0.0461\n",
            "Epoch 5/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 1.2285 - accuracy: 0.0565\n",
            "Epoch 6/50\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 1.1399 - accuracy: 0.0671\n",
            "Epoch 7/50\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 1.0588 - accuracy: 0.0749\n",
            "Epoch 8/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.9860 - accuracy: 0.0820\n",
            "Epoch 9/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.9223 - accuracy: 0.0876\n",
            "Epoch 10/50\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 0.8645 - accuracy: 0.0922\n",
            "Epoch 11/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.8102 - accuracy: 0.0970\n",
            "Epoch 12/50\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 0.7587 - accuracy: 0.1017\n",
            "Epoch 13/50\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 0.7087 - accuracy: 0.1062\n",
            "Epoch 14/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.6598 - accuracy: 0.1115\n",
            "Epoch 15/50\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 0.6112 - accuracy: 0.1174\n",
            "Epoch 16/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.5636 - accuracy: 0.1233\n",
            "Epoch 17/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.5145 - accuracy: 0.1300\n",
            "Epoch 18/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.4662 - accuracy: 0.1375\n",
            "Epoch 19/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.4175 - accuracy: 0.1457\n",
            "Epoch 20/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.3698 - accuracy: 0.1541\n",
            "Epoch 21/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.3271 - accuracy: 0.1622\n",
            "Epoch 22/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.2841 - accuracy: 0.1707\n",
            "Epoch 23/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.2490 - accuracy: 0.1784\n",
            "Epoch 24/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.2151 - accuracy: 0.1851\n",
            "Epoch 25/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.1899 - accuracy: 0.1900\n",
            "Epoch 26/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.1679 - accuracy: 0.1941\n",
            "Epoch 27/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.1500 - accuracy: 0.1978\n",
            "Epoch 28/50\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 0.1376 - accuracy: 0.1997\n",
            "Epoch 29/50\n",
            "115/115 [==============================] - 5s 46ms/step - loss: 0.1292 - accuracy: 0.2012\n",
            "Epoch 30/50\n",
            "115/115 [==============================] - 5s 47ms/step - loss: 0.1197 - accuracy: 0.2037\n",
            "Epoch 31/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.1146 - accuracy: 0.2045\n",
            "Epoch 32/50\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 0.1084 - accuracy: 0.2058\n",
            "Epoch 33/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.1058 - accuracy: 0.2063\n",
            "Epoch 34/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.1025 - accuracy: 0.2068\n",
            "Epoch 35/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0975 - accuracy: 0.2080\n",
            "Epoch 36/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0967 - accuracy: 0.2082\n",
            "Epoch 37/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0897 - accuracy: 0.2102\n",
            "Epoch 38/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0840 - accuracy: 0.2118\n",
            "Epoch 39/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0790 - accuracy: 0.2131\n",
            "Epoch 40/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0746 - accuracy: 0.2145\n",
            "Epoch 41/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0704 - accuracy: 0.2154\n",
            "Epoch 42/50\n",
            "115/115 [==============================] - 5s 43ms/step - loss: 0.0664 - accuracy: 0.2164\n",
            "Epoch 43/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0613 - accuracy: 0.2181\n",
            "Epoch 44/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0598 - accuracy: 0.2183\n",
            "Epoch 45/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0552 - accuracy: 0.2200\n",
            "Epoch 46/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0531 - accuracy: 0.2203\n",
            "Epoch 47/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0533 - accuracy: 0.2201\n",
            "Epoch 48/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0510 - accuracy: 0.2207\n",
            "Epoch 49/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0485 - accuracy: 0.2216\n",
            "Epoch 50/50\n",
            "115/115 [==============================] - 5s 44ms/step - loss: 0.0448 - accuracy: 0.2224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f609a195be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz2ggpTV_lr0",
        "outputId": "917777ec-98f0-49d0-81a4-632c6717e901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Transformer_text_savedmodelform\")"
      ],
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Transformer_text_savedmodelform/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6EDnEOwI_G7"
      },
      "source": [
        "## Transformer Predict\n",
        " - make_predict_input('안녕하세요') -> input_seq\n",
        " - evaluate(input_seq) -> ans_seq_tensor\n",
        " - convert_index_words(ans_seq_tensor, index_to_word) -> '어서오세요'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm421XH_2_72"
      },
      "source": [
        "tmodel = models.load_model(\"/content/drive/My Drive/Transformer_text_savedmodelform\", compile=False)"
      ],
      "execution_count": 412,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrZkFb283DFl",
        "outputId": "1358b1fa-d7dd-44a9-c19f-4c1da6d44f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "convert_index_to_text(evaluate(make_predict_input('')), index_to_word)"
      ],
      "execution_count": 417,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'네 학생 에 이 많이 신어 요 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 417
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTKwTK423FpI"
      },
      "source": [
        "# input : '안녕하세요'\n",
        "# output : array([[2077,  397, 3411, 6122, 4566,    0,    0,   ...    0,    0]])\n",
        "def make_predict_input(sentence):\n",
        "\n",
        "    sentences = []\n",
        "    sentences.append(sentence)\n",
        "    sentences = pos_tag(sentences)\n",
        "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
        "    \n",
        "    return input_seq"
      ],
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojz767_-3Jg1"
      },
      "source": [
        "# input : array([[2077,  397, 3411, 6122, 4566,    0,    0,   ...    0,    0]])\n",
        "# output : <tf.Tensor: shape=(3,), dtype=int32, numpy=array([   1, 1464,  422], dtype=int32)>\n",
        "def evaluate(input_seq):\n",
        "\n",
        "  input_seq = input_seq.squeeze()\n",
        "  sentence = tf.expand_dims(input_seq, axis=0)\n",
        "  output = tf.expand_dims([1], 0)\n",
        "\n",
        "  for i in range(max_sequences):\n",
        "    # predictions = model(inputs=[sentence, output], training=False)\n",
        "    predictions = tmodel.predict([sentence, output])\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, 2):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)"
      ],
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsfLvDhJ3Mqt"
      },
      "source": [
        "# 인덱스를 문장으로 변환\n",
        "def convert_index_to_text(indexs, vocabulary):\n",
        "    indexs = indexs[1:].numpy()\n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == END_INDEX:\n",
        "            # 종료 인덱스면 중지\n",
        "            break;\n",
        "        if vocabulary.get(index) is not None:\n",
        "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
        "            sentence += vocabulary[index]\n",
        "        else:\n",
        "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
        "            sentence.extend([vocabulary[OOV_INDEX]])\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjLQI4czaTs1"
      },
      "source": [
        "##doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAs_p0bLhlPy"
      },
      "source": [
        "# import os\n",
        "# from gensim.models import doc2vec\n",
        "# from gensim.models.doc2vec import TaggedDocument\n",
        "# import pandas as pd\n",
        "# import jpype\n",
        "# from konlpy.tag import Kkma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYLVCfVfaB88"
      },
      "source": [
        "# import warnings\n",
        "# warnings.filterwarnings(action='ignore') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exGo1HnHR5Dg"
      },
      "source": [
        "# kkma = Kkma()\n",
        "# filter_kkma = ['NNG', 'NNP','OL','VA','VV','VXV']\n",
        "\n",
        "# def tokenizer_kkma(doc):\n",
        "#     # 꼬꼬마 형태소 분석기가 자바 기반이어서 파이썬에서 자바함수들을 실행할 수 있는 명령어 (jpype) 를 써줘야한다.\n",
        "#     jpype.attachThreadToJVM()       \n",
        "#     token_doc = [\"/\".join(word) for word in kkma.pos(doc)]\n",
        "#     return token_doc\n",
        "\n",
        "# def tokenize_kkma_noun_verb(doc):\n",
        "#     jpype.attachThreadToJVM()\n",
        "#     token_doc = [\"/\".join(word) for word in kkma.pos(doc) if word[1] in filter_kkma]\n",
        "#     return token_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzqye7pxR8kD"
      },
      "source": [
        "# token_faqs = [(tokenizer_kkma(row[1]), row[0]) for row in faqs]\n",
        "# tagged_faqs = [TaggedDocument(d,[c]) for d,c in token_faqs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_DB1CbDSNQj",
        "outputId": "5360a19d-a53c-4000-e46f-4b65430a4f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# # 모델 만들기\n",
        "# # cpu 몇 개 쓸 건지\n",
        "# import multiprocessing\n",
        "# # 내 컴에 있는 cpu 갯수 cores 에 저장\n",
        "# cores = multiprocessing.cpu_count()\n",
        "# # vector_size : 임베딩할 벡터 차원\n",
        "# # negaive : negative sampling\n",
        "# d2v_faqs = doc2vec.Doc2Vec(\n",
        "#     vector_size = 100,\n",
        "#     alpha = 0.025,\n",
        "#     min_alpha = 0.025,\n",
        "#     hs = 1,\n",
        "#     negative = 0,\n",
        "#     dm = 0,\n",
        "#     dbow_words = 1,\n",
        "#     min_count = 1,\n",
        "#     workers = cores,\n",
        "#     seed = 0\n",
        "# )\n",
        "\n",
        "# # 단어 사전 만들기\n",
        "# d2v_faqs.build_vocab(tagged_faqs)\n",
        "# for epoch in range(4):\n",
        "#   # 모델 학습\n",
        "#   print(epoch)\n",
        "#   d2v_faqs.train(tagged_faqs,\n",
        "#                  total_examples = d2v_faqs.corpus_count,\n",
        "#                  epochs = d2v_faqs.epochs)\n",
        "#   d2v_faqs.alpha -=0.0025\n",
        "#   d2v_faqs.min_alpha = d2v_faqs.min_alpha"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx-jxXncYmlp"
      },
      "source": [
        "## Category & Main Classification\n",
        " - preprocess data x, y\n",
        " - Define model\n",
        " - Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAyr-ECE-tH-"
      },
      "source": [
        "# # 분류기의 경우 따로 <STA> <END> 토큰을 사용할 필요가 없다.\n",
        "# def convert_text_to_index_for_classification(sentences, vocabulary): \n",
        "    \n",
        "#     sentences_index = []\n",
        "    \n",
        "#     # 모든 문장에 대해서 반복\n",
        "#     for sentence in sentences:\n",
        "#         sentence_index = []\n",
        "        \n",
        "#         # 문장의 단어들을 띄어쓰기로 분리\n",
        "#         for word in sentence.split():\n",
        "#             if vocabulary.get(word) is not None:\n",
        "#                 # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "#                 sentence_index.extend([vocabulary[word]])\n",
        "#             else:\n",
        "#                 # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "#                 sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "#         if len(sentence_index) > max_sequences:\n",
        "#             sentence_index = sentence_index[:max_sequences]\n",
        "            \n",
        "#         # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "#         sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "        \n",
        "#         # 문장의 인덱스 배열을 추가\n",
        "#         sentences_index.append(sentence_index)\n",
        "\n",
        "#     return sentences_index"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ioc_akA_aZw"
      },
      "source": [
        "# # 분류모델에 들어갈 x 만들기\n",
        "# question_index_for_cl = []\n",
        "# answer_index_for_cl = []\n",
        "# question_index_for_cl = convert_text_to_index_for_classification(question, word_to_index) #질문 문장에 정수인코딩,패딩\n",
        "# answer_index_for_cl = convert_text_to_index_for_classification(answer, word_to_index)\n",
        "\n",
        "# question_index_for_cl.extend(answer_index_for_cl) # 이렇게 합쳐줌으로써 question_index_for_cl 이 결국 분류모델의 x로 들어가게 될 예정"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEkfYKqa8a9c"
      },
      "source": [
        "# # 분류모델에 들어갈 y만들기\n",
        "# category_y = []\n",
        "# main_y = []\n",
        "# for i in faqs:\n",
        "#   category_y.append(i[3])\n",
        "#   main_y.append(i[4])\n",
        "\n",
        "# category_y.extend(category_y) # 자기것을 그대로 뒤에 갓다붙임. 그래도 되는게, x의 0번 인덱스의 문장(고객의 질문)과 7301번 인덱스의 문장(점원의 답변)이 카테고리,의도가 같음.\n",
        "# main_y.extend(main_y)"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW-r-YFCfVgv"
      },
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, LSTM, Embedding, Masking, Bidirectional\n",
        "\n",
        "# #의도 분류모델\n",
        "# mmodel = Sequential()\n",
        "# mmodel.add(Embedding(VOCAB_SIZE, 100))\n",
        "# mmodel.add(Masking(mask_value=0.0))\n",
        "# mmodel.add(Bidirectional(LSTM(128)))\n",
        "# mmodel.add(Dense(387, activation='softmax'))\n",
        "\n",
        "# #카테고리 분류모델\n",
        "# cmodel = Sequential()\n",
        "# cmodel.add(Embedding(VOCAB_SIZE, 100))\n",
        "# cmodel.add(Masking(mask_value=0.0))\n",
        "# cmodel.add(Bidirectional(LSTM(128)))\n",
        "# cmodel.add(Dense(4, activation='softmax'))"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHQoXs8wfkYk",
        "outputId": "585b261c-e6f1-4d7a-8987-de77cfb82027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# mmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "# history_m = mmodel.fit(np.asarray(question_index_for_cl), np.asarray(main_y), validation_split=0.1, batch_size=BATCH_SIZE, epochs=EPOCHS)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "206/206 [==============================] - 9s 45ms/step - loss: 4.6680 - acc: 0.1334 - val_loss: 4.6769 - val_acc: 0.0979\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 4.0755 - acc: 0.1925 - val_loss: 4.2606 - val_acc: 0.1164\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 4s 18ms/step - loss: 3.4505 - acc: 0.2800 - val_loss: 4.0805 - val_acc: 0.1793\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 2.9066 - acc: 0.3744 - val_loss: 3.8667 - val_acc: 0.2498\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 2.4846 - acc: 0.4444 - val_loss: 3.8875 - val_acc: 0.2485\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 2.1508 - acc: 0.5114 - val_loss: 3.7881 - val_acc: 0.2772\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 1.8807 - acc: 0.5699 - val_loss: 3.8946 - val_acc: 0.2731\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 1.6507 - acc: 0.6152 - val_loss: 3.9581 - val_acc: 0.2697\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 1.4681 - acc: 0.6535 - val_loss: 4.0565 - val_acc: 0.2710\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 1.3184 - acc: 0.6892 - val_loss: 4.0440 - val_acc: 0.2731\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 1.1871 - acc: 0.7214 - val_loss: 4.1632 - val_acc: 0.2765\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 1.0702 - acc: 0.7474 - val_loss: 4.2071 - val_acc: 0.2772\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.9786 - acc: 0.7711 - val_loss: 4.3535 - val_acc: 0.2526\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.8960 - acc: 0.7888 - val_loss: 4.5060 - val_acc: 0.2444\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.8229 - acc: 0.8062 - val_loss: 4.5275 - val_acc: 0.2786\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.7700 - acc: 0.8193 - val_loss: 4.5983 - val_acc: 0.2587\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.7165 - acc: 0.8308 - val_loss: 4.5021 - val_acc: 0.2916\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.6636 - acc: 0.8437 - val_loss: 4.6862 - val_acc: 0.2580\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.6221 - acc: 0.8517 - val_loss: 4.6256 - val_acc: 0.2690\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.5875 - acc: 0.8597 - val_loss: 4.8412 - val_acc: 0.2567\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.5528 - acc: 0.8665 - val_loss: 4.9520 - val_acc: 0.2396\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.5258 - acc: 0.8731 - val_loss: 4.9890 - val_acc: 0.2478\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4921 - acc: 0.8802 - val_loss: 4.9200 - val_acc: 0.2553\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4652 - acc: 0.8861 - val_loss: 5.0811 - val_acc: 0.2546\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4453 - acc: 0.8898 - val_loss: 5.1211 - val_acc: 0.2608\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4286 - acc: 0.8948 - val_loss: 5.2644 - val_acc: 0.2348\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4042 - acc: 0.8980 - val_loss: 5.0779 - val_acc: 0.2669\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3921 - acc: 0.9011 - val_loss: 5.1732 - val_acc: 0.2710\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3757 - acc: 0.9034 - val_loss: 5.3265 - val_acc: 0.2594\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3611 - acc: 0.9062 - val_loss: 5.4354 - val_acc: 0.2464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bX-vKIaS3MF"
      },
      "source": [
        "# mmodel.save('main_lstm_cl.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGQ3iSMkThaN"
      },
      "source": [
        "# load_m_model = models.load_model('main_lstm_cl.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlLD_Nv6GMYz",
        "outputId": "c379a23f-f5bf-4218-829d-d3cb7279add3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# fig, loss_ax = plt.subplots()\n",
        "# acc_ax = loss_ax.twinx()\n",
        "\n",
        "# loss_ax.plot(history_m.history['loss'], 'y', label='train loss')\n",
        "# loss_ax.plot(history_m.history['val_loss'], 'r', label='val loss')\n",
        "# loss_ax.set_xlabel('epoch')\n",
        "# loss_ax.set_ylabel('loss')\n",
        "# loss_ax.legend(loc='upper left')\n",
        "\n",
        "# acc_ax.plot(history_m.history['acc'], 'b', label='train acc')\n",
        "# acc_ax.plot(history_m.history['val_acc'], 'g', label='val acc')\n",
        "# acc_ax.set_ylabel('accuracy')\n",
        "# acc_ax.legend(loc='lower right')\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYqy-6NEfrXJ",
        "outputId": "2dbb467e-8f7f-4d95-b857-14093fe20f4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# cmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "# history_c = cmodel.fit(np.asarray(question_index_for_cl), np.asarray(category_y), validation_split=0.1, batch_size=BATCH_SIZE, epochs=EPOCHS) # 128 64 32 실험"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "206/206 [==============================] - 10s 48ms/step - loss: 1.1463 - acc: 0.4819 - val_loss: 0.6919 - val_acc: 0.7474\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.7792 - acc: 0.6764 - val_loss: 0.6650 - val_acc: 0.7515\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 4s 18ms/step - loss: 0.6363 - acc: 0.7414 - val_loss: 0.7455 - val_acc: 0.6694\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.5643 - acc: 0.7665 - val_loss: 0.7858 - val_acc: 0.6715\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.5152 - acc: 0.7843 - val_loss: 0.8312 - val_acc: 0.6660\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4839 - acc: 0.7948 - val_loss: 0.8444 - val_acc: 0.6735\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4620 - acc: 0.8048 - val_loss: 0.9092 - val_acc: 0.6537\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4407 - acc: 0.8101 - val_loss: 0.9033 - val_acc: 0.6728\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4227 - acc: 0.8164 - val_loss: 0.9963 - val_acc: 0.6612\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.4074 - acc: 0.8250 - val_loss: 0.9596 - val_acc: 0.6667\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3909 - acc: 0.8298 - val_loss: 1.0102 - val_acc: 0.6667\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 3s 16ms/step - loss: 0.3797 - acc: 0.8352 - val_loss: 1.1228 - val_acc: 0.6557\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3677 - acc: 0.8394 - val_loss: 1.1597 - val_acc: 0.6496\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3550 - acc: 0.8455 - val_loss: 1.1049 - val_acc: 0.6735\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3433 - acc: 0.8512 - val_loss: 1.2453 - val_acc: 0.6543\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3349 - acc: 0.8547 - val_loss: 1.2523 - val_acc: 0.6564\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3322 - acc: 0.8553 - val_loss: 1.3597 - val_acc: 0.6482\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3191 - acc: 0.8615 - val_loss: 1.3912 - val_acc: 0.6557\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3140 - acc: 0.8641 - val_loss: 1.3565 - val_acc: 0.6482\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3086 - acc: 0.8671 - val_loss: 1.4349 - val_acc: 0.6516\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.3023 - acc: 0.8693 - val_loss: 1.4472 - val_acc: 0.6441\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2954 - acc: 0.8709 - val_loss: 1.4528 - val_acc: 0.6441\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2861 - acc: 0.8753 - val_loss: 1.5644 - val_acc: 0.6338\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2817 - acc: 0.8772 - val_loss: 1.5268 - val_acc: 0.6420\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2783 - acc: 0.8795 - val_loss: 1.5682 - val_acc: 0.6489\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2703 - acc: 0.8835 - val_loss: 1.6611 - val_acc: 0.6372\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2623 - acc: 0.8830 - val_loss: 1.7077 - val_acc: 0.6448\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2593 - acc: 0.8865 - val_loss: 1.7626 - val_acc: 0.6235\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2588 - acc: 0.8882 - val_loss: 1.6627 - val_acc: 0.6441\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 3s 15ms/step - loss: 0.2512 - acc: 0.8899 - val_loss: 1.8027 - val_acc: 0.6304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiLiJVHRUgVr"
      },
      "source": [
        "# cmodel.save('category_lstm_cl.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SlrE3fAMIGo",
        "outputId": "4b0fccf3-cea8-4d88-983b-575182c47ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# fig, loss_ax = plt.subplots()\n",
        "# acc_ax = loss_ax.twinx()\n",
        "\n",
        "# loss_ax.plot(history_c.history['loss'], 'y', label='train loss')\n",
        "# loss_ax.plot(history_c.history['val_loss'], 'r', label='val loss')\n",
        "# loss_ax.set_xlabel('epoch')\n",
        "# loss_ax.set_ylabel('loss')\n",
        "# loss_ax.legend(loc='upper left')\n",
        "\n",
        "# acc_ax.plot(history_c.history['acc'], 'b', label='train acc')\n",
        "# acc_ax.plot(history_c.history['val_acc'], 'g', label='val acc')\n",
        "# acc_ax.set_ylabel('accuracy')\n",
        "# acc_ax.legend(loc='lower right')\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zdmR5oZHWsq"
      },
      "source": [
        "# def predict_cm(question_index_for_cl, category_y, main_y): #형태소 분리된 문장들의 list가 입력으로 가야함.\n",
        "#   # stc_x = convert_text_to_index_for_classification(questions, word_to_index)\n",
        "#   j = 0\n",
        "#   c = 0\n",
        "#   m = 0\n",
        "#   for i in question_index_for_cl:\n",
        "#     if np.argmax(cmodel.predict(np.asarray(i).reshape(1,30))) != category_y[j]:\n",
        "#       c += 1\n",
        "#     if np.argmax(mmodel.predict(np.asarray(i).reshape(1,30))) != main_y[j]:\n",
        "#       m += 1\n",
        "#     j+=1\n",
        "#   print(c, \"개의 문장의 카테고리가 맞지 않음\")\n",
        "#   print(m, \"개의 문장의 의도가 맞지 않음\")"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXA9XMEZy7x4",
        "outputId": "062b5b33-d685-47cf-8e43-e76ff673abef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# predict_cm(question_index_for_cl, category_y, main_y)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1780 개의 문장의 카테고리가 맞지 않음\n",
            "2146 개의 문장의 의도가 맞지 않음\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXEMQH_jf5jl"
      },
      "source": [
        "# def find_category(stc,tokenizer,model,category_list):\n",
        "#     tagger = Okt()\n",
        "#     stc = tagger.morphs(stc)\n",
        "#     encode_stc = tokenizer.texts_to_sequences([stc])\n",
        "#     pad_stc = pad_sequences(encode_stc, maxlen=15)\n",
        "#     score = model.predict(pad_stc)\n",
        "#     return (category_list[score.argmax()], score[0, score.argmax()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPuuoO9WUwfT"
      },
      "source": [
        "# spell check and spacing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvEHNJR5X7Xh"
      },
      "source": [
        "# def grammar_checker(sentence):\n",
        "\n",
        "#   spacing_sentence = spacing(sentence.replace(' ',''))\n",
        "#   spelled_sentence = spell_checker.check(spacing_sentence)\n",
        "#   checked_sentence = spelled_sentence.checked\n",
        "\n",
        "#   return checked_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjxPAkUcRXNQ"
      },
      "source": [
        "##합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "audGWlqWURLT"
      },
      "source": [
        "# def give_cate(input_question): #카테고리추출하는 함수\n",
        "#   big_cate=find_category(input_question,ctokenizer,cmodel,category_list)\n",
        "#   samll_cate=find_category(input_question,rtokenizer,rmodel,rough_category_list)\n",
        "#   return big_cate,samll_cate #리턴값으로 큰카테고리(이름,유사도),작은 카테고리(이름,유사도)\n",
        "\n",
        "# def give_answer(input_question): #질문입력시 transfomer로 답변함\n",
        "#   return convert_index_to_text(evaluate(make_predict_input(input_question)).numpy()[1:],index_to_word)\n",
        "\n",
        "# def doc2_answer(input_question): #질문 입력시 doc2으로 답변함\n",
        "#   token_test = tokenizer_kkma(input_question)\n",
        "#   predict_vector = d2v_faqs.infer_vector(token_test)\n",
        "#   result = d2v_faqs.docvecs.most_similar([predict_vector],topn=1)\n",
        "#   return faqs[int(result[0][0])-1][2]\n",
        "\n",
        "# def score_calcul(left_cate,right_cate):#카테고리를 두개를 입력하면 유사도를 계산함\n",
        "#   result = 0\n",
        "#   if left_cate[0]==right_cate[0]:\n",
        "#     result += abs(left_cate[1]-right_cate[1])\n",
        "#   return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oOsaFW9RpBK",
        "outputId": "a2029d76-5358-4ca2-e3c3-26a87cc6c8db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# input_question = input()\n",
        "\n",
        "# q_big_cate,q_samll_cate=give_cate(input_question)\n",
        "\n",
        "# print(f\"{q_big_cate},{q_samll_cate}\")\n",
        "\n",
        "# dm=doc2_answer(input_question)\n",
        "# dm_big_cate,dm_small_cate=give_cate(dm)\n",
        "# cm=give_answer(input_question)\n",
        "# cm_big_cate,cm_small_cate=give_cate(cm)\n",
        "\n",
        "# doc2_score=0\n",
        "# tran_score=0\n",
        "\n",
        "# doc2_score += score_calcul(q_big_cate,dm_big_cate)\n",
        "# doc2_score += score_calcul(q_big_cate,dm_small_cate)\n",
        "# tran_score += score_calcul(q_big_cate,cm_big_cate)\n",
        "# tran_score += score_calcul(q_big_cate,dm_small_cate)\n",
        "\n",
        "# if doc2_score>=tran_score:\n",
        "#   print(f\"***doc2: {grammar_checker(dm)}\")\n",
        "# else:\n",
        "#   print(f\"***tran: {grammar_checker(cm)}\")\n",
        "\n",
        "# print(\"==================================\")\n",
        "# print(f\"doc2: {dm_big_cate},{dm_small_cate}\")\n",
        "# print(grammar_checker(dm))\n",
        "# if doc2_score!=0:\n",
        "#   print(doc2_score)\n",
        "# else:\n",
        "#   print(\"평가불가\")\n",
        "# print(\"\")\n",
        "# print(f\"tran: {cm_big_cate},{cm_small_cate}\")\n",
        "# print(grammar_checker(cm))\n",
        "# if tran_score!=0:\n",
        "#   print(tran_score)\n",
        "# else:\n",
        "#   print(\"평가불가\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "카운터에 있는 점원이 입고 있는 옷 맘에 드는데 어떤 제품인가요?\n",
            "('유사제품추천문의', 0.6587085),('신발', 0.9972078)\n",
            "***doc2: 네 피팅룸은 이쪽입니다\n",
            "==================================\n",
            "doc2: ('제품요청', 0.50416297),('의류', 0.999944)\n",
            "네 피팅룸은 이쪽입니다\n",
            "평가불가\n",
            "\n",
            "tran: ('제품별추천문의', 0.67691714),('의류', 0.88469416)\n",
            "고객 님 이 제품 은 어떠 신지 요 ? \n",
            "평가불가\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}