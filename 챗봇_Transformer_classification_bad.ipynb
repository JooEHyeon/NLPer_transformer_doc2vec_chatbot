{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "챗봇_Transformer_classification_bad",
      "provenance": [],
      "collapsed_sections": [
        "9UA-8fQ2EDnp",
        "ioT3c4eLEKon",
        "jx-jxXncYmlp",
        "e6EDnEOwI_G7",
        "kjLQI4czaTs1"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ideablast/NLPer_chatbot/blob/kdg/%EC%B1%97%EB%B4%87_Transformer_classification_bad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsiilWsMNHHL",
        "outputId": "725fb02c-2cf1-4ef1-f099-1a3f00b4eb35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/96/1030895dea70855a2e1078e3fe0d6a63dcb7c212309e07dc9ee39d33af54/JPype1-1.1.2-cp36-cp36m-manylinux2010_x86_64.whl (450kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 73.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: JPype1, beautifulsoup4, colorama, tweepy, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.1.2 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UA-8fQ2EDnp"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DAFy5c7ydzC"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers, losses, metrics\n",
        "from keras import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioT3c4eLEKon"
      },
      "source": [
        "## Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9YUdE1OydzG"
      },
      "source": [
        "# 태그 단어\n",
        "PAD = \"<PADDING>\"   # 패딩\n",
        "STA = \"<START>\"     # 시작\n",
        "END = \"<END>\"       # 끝\n",
        "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
        "\n",
        "# 태그 인덱스\n",
        "PAD_INDEX = 0\n",
        "STA_INDEX = 1\n",
        "END_INDEX = 2\n",
        "OOV_INDEX = 3\n",
        "\n",
        "# 데이터 타입\n",
        "ENCODER_INPUT  = 0\n",
        "DECODER_INPUT  = 1\n",
        "DECODER_TARGET = 2\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256 ##word embedding dim\n",
        "NUM_HEADS = 8 ## D_Model % NUM_HEADS == 0이 되야하므로...\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "EPOCHS = 50\n",
        "# for data pipelining\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "VOCAB_SIZE = 0 # 후에 len(words) 로 바뀜.\n",
        "\n",
        "# 한 문장에서 단어 시퀀스의 최대 개수\n",
        "max_sequences = 30\n",
        "\n",
        "# 정규 표현식 필터\n",
        "RE_FILTER = re.compile(\"[\\\"':;~()]\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhVVnW_uEWT1"
      },
      "source": [
        "## Data Load & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80IauV0FpUv2",
        "outputId": "09b32aca-b3ff-4370-be44-b1363542f918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEHDnPXNzZlM",
        "outputId": "cce9614c-3712-49ea-aa9e-89fe6915f326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wear_data = pd.read_csv(\"/content/drive/My Drive/wear.csv\")\n",
        "print(wear_data.shape)\n",
        "customer = wear_data[wear_data.SPEAKER == \"고객\"].SENTENCE\n",
        "store = wear_data[wear_data.SPEAKER == \"점원\"].SENTENCE\n",
        "print(customer.shape, store.shape) # 질문의 개수와 답의 개수가 일치하지 않는다."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15826, 20)\n",
            "(8381,) (7445,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLNSiqcHM4WY",
        "outputId": "e104cef3-9f3b-4295-a395-9dd6a2e4af08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "prev = \"고객\"\n",
        "store_arr = []\n",
        "customer_arr = []\n",
        "store_stc = \"\"\n",
        "customer_stc = \"\"\n",
        "\n",
        "for i in range(wear_data.shape[0]):\n",
        "    if (prev == wear_data.iloc[i].SPEAKER):\n",
        "        if prev == \"점원\":\n",
        "             store_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "        else : \n",
        "             customer_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "            \n",
        "    elif prev == \"점원\":\n",
        "        store_arr.append(store_stc)\n",
        "        customer_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"고객\"\n",
        "    else :\n",
        "        customer_arr.append(customer_stc)\n",
        "        store_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"점원\"\n",
        "faqs = []\n",
        "\n",
        "for i in range(len(store_arr)):\n",
        "    faqs_tmp =[]\n",
        "    faqs_tmp.append(str(i+1))\n",
        "    faqs_tmp.append(customer_arr[i])\n",
        "    faqs_tmp.append(store_arr[i])\n",
        "\n",
        "    faqs.append(faqs_tmp)\n",
        "print(len(store_arr))\n",
        "print(len(customer_arr))\n",
        "print(store_arr[-1])\n",
        "print(customer_arr[-1]) # 자료 상에서 이후에는 계속 고객의 물음만 계속된다. 코드 레벨에서 이 부분은 빼게 구현했다. (stc는 만들어지지만 arr에 append 안하게 된다.)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7301\n",
            "7301\n",
            "요즘 파스텔 톤이 유행이에요\n",
            "요즘 유행하는 색깔이 뭐예요?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNvig2FMzjXj",
        "outputId": "5fc3dd57-1169-4bfc-90d7-9562adc79e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "question = []\n",
        "answer = []\n",
        "\n",
        "for Q in customer_arr:\n",
        "    question.append(Q.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "for A in store_arr:\n",
        "    answer.append(A.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "len(question), len(answer)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7301, 7301)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbivSckMydzN"
      },
      "source": [
        "# 형태소분석 함수\n",
        "def pos_tag(sentences):\n",
        "    \n",
        "    # KoNLPy 형태소분석기 설정\n",
        "    tagger = Okt()\n",
        "    \n",
        "    # 문장 품사 변수 초기화\n",
        "    sentences_pos = []\n",
        "    \n",
        "    # 모든 문장 반복\n",
        "    for sentence in sentences:\n",
        "        # [\\\"':;~()] 특수기호 제거\n",
        "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
        "        \n",
        "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
        "        sentence = \" \".join(tagger.morphs(sentence))\n",
        "        sentences_pos.append(sentence)\n",
        "        \n",
        "    return sentences_pos"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seqSNWcydzP",
        "outputId": "e6b8d300-164a-40cb-c6bd-f2ad4558a885",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 형태소분석 수행\n",
        "question = pos_tag(question)\n",
        "answer = pos_tag(answer)\n",
        "\n",
        "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
        "for i in range(5):\n",
        "    print('Q : ' + question[i])\n",
        "    print('A : ' + answer[i])\n",
        "    print()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q : 신발 은 여기 있는 게 다예 요 ?\n",
            "A : 네 성인 이나 아동 다 있어요 발 사이즈 몇 신으세요 ?\n",
            "\n",
            "Q : 230 이요\n",
            "A : 편하게 신 을 수 있는 거 찾으세요 ?\n",
            "\n",
            "Q : 네 봄 이니까 편하게 신 을 수 있는 거\n",
            "A : 이런 건 어떠세요 ? 이런 거도 신발 무척 편하거든요\n",
            "\n",
            "Q : 굽 좀 높은 거 없나요 ?\n",
            "A : 봄 상품 은 아직 어른 제품 이 많이 안 나왔습니다\n",
            "\n",
            "Q : 언제 들어와요 ?\n",
            "A : 이번 주 지나면 들어올 거 예요\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrnct_nzydzR"
      },
      "source": [
        "# 질문과 대답 문장들을 하나로 합침\n",
        "sentences = []\n",
        "sentences.extend(question)\n",
        "sentences.extend(answer)\n",
        "\n",
        "words = []\n",
        "\n",
        "# 단어들의 배열 생성\n",
        "for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "        words.append(word)\n",
        "\n",
        "# 길이가 0인 단어는 삭제\n",
        "words = [word for word in words if len(word) > 0]\n",
        "\n",
        "# 중복된 단어 삭제\n",
        "words = list(set(words))\n",
        "\n",
        "# 제일 앞에 태그 단어 삽입\n",
        "words[:0] = [PAD, STA, END, OOV]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE9ZhJpEy_rT",
        "outputId": "5ec331ee-8a14-40fb-fb52-fdd136e69276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "VOCAB_SIZE = len(words)\n",
        "print(\"손님과 점원의 말에서 사용된 총 단어의 수 :\",len(words))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "손님과 점원의 말에서 사용된 총 단어의 수 : 6409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkvyOnSvydzX"
      },
      "source": [
        "# 단어와 인덱스의 딕셔너리 생성\n",
        "word_to_index = {word: index for index, word in enumerate(words)}\n",
        "index_to_word = {index: word for index, word in enumerate(words)}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfoTztrvydzc"
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "def convert_text_to_index(sentences, vocabulary, type): \n",
        "    \n",
        "    sentences_index = []\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for sentence in sentences:\n",
        "        sentence_index = []\n",
        "        \n",
        "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
        "        if type == DECODER_INPUT:\n",
        "            sentence_index.extend([vocabulary[STA]])\n",
        "        \n",
        "        # 문장의 단어들을 띄어쓰기로 분리\n",
        "        for word in sentence.split():\n",
        "            if vocabulary.get(word) is not None:\n",
        "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[word]])\n",
        "            else:\n",
        "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "        # 최대 길이 검사\n",
        "        if type == DECODER_TARGET:\n",
        "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
        "            if len(sentence_index) >= max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
        "            else:\n",
        "                sentence_index += [vocabulary[END]]\n",
        "        else:\n",
        "            if len(sentence_index) > max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences]\n",
        "            \n",
        "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "        \n",
        "        # 문장의 인덱스 배열을 추가\n",
        "        sentences_index.append(sentence_index)\n",
        "\n",
        "    return np.asarray(sentences_index)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zezFPTvcydzf",
        "outputId": "8b1a00af-14b7-4a8b-d05a-68a7e1713dd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 인코더 입력 인덱스 변환\n",
        "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
        "\n",
        "# 첫 번째 인코더 입력 출력 (신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_encoder[0]\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4633, 4930, 2770,  696, 5080, 6196,  589, 5047,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmql1Lf_ydzh",
        "outputId": "ce7f4136-2605-4b8e-897c-fb328382244e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 입력 인덱스 변환\n",
        "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (<START> 신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_decoder[0]\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,  752, 4835, 1188, 4335,  944, 5157, 6234, 5145,  126, 3812,\n",
              "       5047,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIhDbaLydzk",
        "outputId": "d0cf1e07-1328-43dd-f4c6-a79d12512c38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 목표 인덱스 변환\n",
        "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (신발 은 여기 있는 게 다예 요 <END>)\n",
        "print(question[0])\n",
        "y_decoder[0]\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 752, 4835, 1188, 4335,  944, 5157, 6234, 5145,  126, 3812, 5047,\n",
              "          2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsf4tJl61Xi9"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsxmXWS41XVd"
      },
      "source": [
        "# decoder inputs use the previous target as input\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': x_encoder,\n",
        "        'dec_inputs': x_decoder\n",
        "    },\n",
        "    {\n",
        "        'outputs': y_decoder\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxXCQWvw2jwx"
      },
      "source": [
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH-k-kk_1_Vu"
      },
      "source": [
        "## scaled dot product Attention\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True) # QK^T\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth) #  QK^T / sqrt(d_k)\n",
        "\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9) # zero padding token softmax 결과가 0이 나오도록\n",
        "  \n",
        "  attention_weights = tf.nn.softmax(logits, axis = -1) # softmax(QK^T / sqrt(d_k))\n",
        "\n",
        "  output = tf.matmul(attention_weights, value) # softmax(QK^T / sqrt(d_k)) * V\n",
        "\n",
        "  return output"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7orcKMr13xY8"
      },
      "source": [
        "## multi-head attention\n",
        "## each head need (scaled_dot_product_attention)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0 # 128,8\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "  \n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(inputs, shape=(batch_size,-1,self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3]) ##????\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    #linear\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    #split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    #scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    #concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "\n",
        "    #final linear\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmlW0oi89nEC"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37sh3f8P-JUB",
        "outputId": "5d4b110c-d2a8-4939-c847-0538a01a5704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W7ld50z3vT2"
      },
      "source": [
        "# it handle mask future tokens in a sequence used decoder. and mask pad tokens\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W25teKwt_F80",
        "outputId": "4fa8dfce-eb76-4a76-a12f-45d59bbeeda2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLhXEIJgASo3"
      },
      "source": [
        "Positional encoding\n",
        "\n",
        "since we don't use any rnn, cnn, positional encoding give model position information of words in sentence.\n",
        "\n",
        "positional encoding vector is added to embedding vector\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7s19-x3_Hpq"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "  \n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles #pos/10000^(2i/d_model)\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position = tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model = d_model)\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLiumNZZDZGY"
      },
      "source": [
        "### Encoder Layer\n",
        "1. Multi-head attention (with padding mask)\n",
        "2. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oarRWUMLDYnC"
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query':inputs,\n",
        "          'key':inputs,\n",
        "          'value':inputs,\n",
        "          'mask':padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3rO9IcDHGE5"
      },
      "source": [
        "### Encoder\n",
        "1. Input Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` encoder layers\n",
        "\n",
        "Embedding + positional encoding : input\n",
        "\n",
        "going encoder layers.\n",
        "\n",
        "output going decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOwoi2_jHvbA"
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)#??왜 vocab_size가 들어가지?\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, padding_mask], outputs = outputs, name=name)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8XHH5dpJr-G"
      },
      "source": [
        "### Decoder Layer\n",
        "1. Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2. Multi-head attention (with padding mask). `value` and `key` is from encoder output. `query` is from Multi-head attention layer output\n",
        "3. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtAfKdk-JrxK"
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name=\"padding_mask\")\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query' : inputs,\n",
        "          'key' : inputs,\n",
        "          'value' : inputs,\n",
        "          'mask' : look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query' : attention1,\n",
        "          'key' : enc_outputs,\n",
        "          'value' : enc_outputs,\n",
        "          'mask' : padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnBSBcm1NAYv"
      },
      "source": [
        "### Decoder\n",
        "1. output Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` decoder layers\n",
        "\n",
        "Embedding + positional encoding : input (target)\n",
        "\n",
        "going decoder layers.\n",
        "\n",
        "output going final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnA-8FEAOT4F"
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"decoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name='padding_mask')\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"decoder_layer_{}\".format(i),\n",
        "    )(inputs = [outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-vmtqKQjhf"
      },
      "source": [
        "### Transformer\n",
        "1. encoder\n",
        "2. decoder\n",
        "3. final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEMfL5SFQqr4"
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"enc_padding_mask\")(inputs)\n",
        "  \n",
        "  #mask future tokens for decoder inputs at 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1,None,None),\n",
        "      name=\"look_ahead_mask\")(dec_inputs)\n",
        "  \n",
        "  #mask encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"dec_padding_mask\")(inputs)\n",
        "  \n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A44_Bc6RHJ3c"
      },
      "source": [
        "## Transformer for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9fUGKCwJS9J"
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7KTHsUdHQGm"
      },
      "source": [
        "class MultiHeadSelfAttention_classification(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super(MultiHeadSelfAttention_classification, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w25FGb6kHVxq"
      },
      "source": [
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention_classification(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khZdXSThHaTr"
      },
      "source": [
        "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvW0OXzJIC2C"
      },
      "source": [
        "inputs = layers.Input(shape=(max_sequences,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_sequences, VOCAB_SIZE, D_MODEL)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(D_MODEL, NUM_HEADS, UNITS)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(40, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dje6ooiUl4a"
      },
      "source": [
        "seq_x = convert_text_to_index(wear_data['SENTENCE'].tolist(), word_to_index, ENCODER_INPUT)\n",
        "catgory_index_arr = pd.factorize(wear_data['CATEGORY'])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_OKRIMuJY1g",
        "outputId": "070b362a-a371-4fba-8f58-acaf51faab0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(\n",
        "    seq_x, catgory_index_arr, batch_size=8, epochs=30, validation_split=0.1\n",
        ")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 1.2396 - accuracy: 0.3790 - val_loss: 1.1789 - val_accuracy: 0.3544\n",
            "Epoch 2/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 1.2082 - accuracy: 0.3966 - val_loss: 1.1966 - val_accuracy: 0.3872\n",
            "Epoch 3/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 1.1626 - accuracy: 0.4355 - val_loss: 1.1888 - val_accuracy: 0.5685\n",
            "Epoch 4/30\n",
            "1781/1781 [==============================] - 25s 14ms/step - loss: 1.1246 - accuracy: 0.4664 - val_loss: 1.1630 - val_accuracy: 0.5679\n",
            "Epoch 5/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 1.0788 - accuracy: 0.4993 - val_loss: 1.1957 - val_accuracy: 0.5648\n",
            "Epoch 6/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 1.0286 - accuracy: 0.5222 - val_loss: 1.2198 - val_accuracy: 0.5742\n",
            "Epoch 7/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.9825 - accuracy: 0.5449 - val_loss: 1.3654 - val_accuracy: 0.5679\n",
            "Epoch 8/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.9468 - accuracy: 0.5617 - val_loss: 1.2379 - val_accuracy: 0.5875\n",
            "Epoch 9/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.9235 - accuracy: 0.5698 - val_loss: 1.2673 - val_accuracy: 0.5982\n",
            "Epoch 10/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.9026 - accuracy: 0.5793 - val_loss: 1.1793 - val_accuracy: 0.5774\n",
            "Epoch 11/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.8824 - accuracy: 0.5855 - val_loss: 1.2225 - val_accuracy: 0.5938\n",
            "Epoch 12/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.8737 - accuracy: 0.5910 - val_loss: 1.4619 - val_accuracy: 0.5648\n",
            "Epoch 13/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8619 - accuracy: 0.5970 - val_loss: 1.4117 - val_accuracy: 0.5736\n",
            "Epoch 14/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.8524 - accuracy: 0.5998 - val_loss: 1.3523 - val_accuracy: 0.5812\n",
            "Epoch 15/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8395 - accuracy: 0.6035 - val_loss: 1.5502 - val_accuracy: 0.5768\n",
            "Epoch 16/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8346 - accuracy: 0.6034 - val_loss: 1.4682 - val_accuracy: 0.5824\n",
            "Epoch 17/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8255 - accuracy: 0.6089 - val_loss: 1.7574 - val_accuracy: 0.5654\n",
            "Epoch 18/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8201 - accuracy: 0.6096 - val_loss: 1.6058 - val_accuracy: 0.5698\n",
            "Epoch 19/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8056 - accuracy: 0.6134 - val_loss: 1.6498 - val_accuracy: 0.5401\n",
            "Epoch 20/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.8065 - accuracy: 0.6133 - val_loss: 1.4237 - val_accuracy: 0.5837\n",
            "Epoch 21/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.8010 - accuracy: 0.6203 - val_loss: 1.5852 - val_accuracy: 0.5736\n",
            "Epoch 22/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.7946 - accuracy: 0.6178 - val_loss: 1.5129 - val_accuracy: 0.5907\n",
            "Epoch 23/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.7876 - accuracy: 0.6235 - val_loss: 1.7988 - val_accuracy: 0.5666\n",
            "Epoch 24/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.7810 - accuracy: 0.6271 - val_loss: 1.6766 - val_accuracy: 0.5761\n",
            "Epoch 25/30\n",
            "1781/1781 [==============================] - 26s 14ms/step - loss: 0.7749 - accuracy: 0.6319 - val_loss: 1.7024 - val_accuracy: 0.5799\n",
            "Epoch 26/30\n",
            "1781/1781 [==============================] - 27s 15ms/step - loss: 0.7719 - accuracy: 0.6301 - val_loss: 1.7807 - val_accuracy: 0.5711\n",
            "Epoch 27/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.7621 - accuracy: 0.6326 - val_loss: 1.8464 - val_accuracy: 0.5464\n",
            "Epoch 28/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.7600 - accuracy: 0.6355 - val_loss: 1.6392 - val_accuracy: 0.5831\n",
            "Epoch 29/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.7562 - accuracy: 0.6353 - val_loss: 1.7921 - val_accuracy: 0.5610\n",
            "Epoch 30/30\n",
            "1781/1781 [==============================] - 26s 15ms/step - loss: 0.7552 - accuracy: 0.6391 - val_loss: 1.9658 - val_accuracy: 0.5761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq4hjB86TeiS",
        "outputId": "c1baba82-bc97-473c-c206-e6231bfd3bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLSnlpg0QxOd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pav-8Jd3ydzp"
      },
      "source": [
        "## 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8y-mjWtydzp"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK3IwtA4TOnN"
      },
      "source": [
        "### Loss function\n",
        "since target sequences are padded, deal this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi7YnqpVTYn2"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "  \n",
        "  mask = tf.cast(tf.not_equal(y_true,0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzHEmCzUVhTu"
      },
      "source": [
        "### Custom learning rate\n",
        "use Adam optimizer with custom learning rate\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkFm9m_LVt8c"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb8PGbKgWAbP"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vql4FYFUV_3_"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTXbb1Z2I4IM"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl3V7BllWWFG",
        "outputId": "c4486f9b-39ab-4bbc-a143-8f0c42b349b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.9745 - accuracy: 0.0212\n",
            "Epoch 2/50\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.7337 - accuracy: 0.0333\n",
            "Epoch 3/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.4780 - accuracy: 0.0421\n",
            "Epoch 4/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.3197 - accuracy: 0.0458\n",
            "Epoch 5/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.2290 - accuracy: 0.0561\n",
            "Epoch 6/50\n",
            "115/115 [==============================] - 6s 57ms/step - loss: 1.1427 - accuracy: 0.0669\n",
            "Epoch 7/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 1.0619 - accuracy: 0.0749\n",
            "Epoch 8/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.9901 - accuracy: 0.0812\n",
            "Epoch 9/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.9265 - accuracy: 0.0865\n",
            "Epoch 10/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.8684 - accuracy: 0.0916\n",
            "Epoch 11/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.8145 - accuracy: 0.0964\n",
            "Epoch 12/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.7614 - accuracy: 0.1010\n",
            "Epoch 13/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.7114 - accuracy: 0.1056\n",
            "Epoch 14/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.6626 - accuracy: 0.1111\n",
            "Epoch 15/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.6111 - accuracy: 0.1175\n",
            "Epoch 16/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.5616 - accuracy: 0.1236\n",
            "Epoch 17/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.5127 - accuracy: 0.1302\n",
            "Epoch 18/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.4641 - accuracy: 0.1377\n",
            "Epoch 19/50\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4141 - accuracy: 0.1464\n",
            "Epoch 20/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.3699 - accuracy: 0.1541\n",
            "Epoch 21/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.3243 - accuracy: 0.1625\n",
            "Epoch 22/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.2804 - accuracy: 0.1720\n",
            "Epoch 23/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.2446 - accuracy: 0.1786\n",
            "Epoch 24/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.2120 - accuracy: 0.1850\n",
            "Epoch 25/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1853 - accuracy: 0.1909\n",
            "Epoch 26/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1654 - accuracy: 0.1948\n",
            "Epoch 27/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1472 - accuracy: 0.1982\n",
            "Epoch 28/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1370 - accuracy: 0.1998\n",
            "Epoch 29/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1279 - accuracy: 0.2015\n",
            "Epoch 30/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1167 - accuracy: 0.2041\n",
            "Epoch 31/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1119 - accuracy: 0.2052\n",
            "Epoch 32/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.1082 - accuracy: 0.2057\n",
            "Epoch 33/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1045 - accuracy: 0.2067\n",
            "Epoch 34/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1004 - accuracy: 0.2074\n",
            "Epoch 35/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0997 - accuracy: 0.2078\n",
            "Epoch 36/50\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 0.0928 - accuracy: 0.2092\n",
            "Epoch 37/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0908 - accuracy: 0.2099\n",
            "Epoch 38/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0832 - accuracy: 0.2120\n",
            "Epoch 39/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0788 - accuracy: 0.2133\n",
            "Epoch 40/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0733 - accuracy: 0.2148\n",
            "Epoch 41/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0689 - accuracy: 0.2158\n",
            "Epoch 42/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0662 - accuracy: 0.2163\n",
            "Epoch 43/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0630 - accuracy: 0.2175\n",
            "Epoch 44/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0610 - accuracy: 0.2180\n",
            "Epoch 45/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0573 - accuracy: 0.2191\n",
            "Epoch 46/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0539 - accuracy: 0.2200\n",
            "Epoch 47/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.0522 - accuracy: 0.2205\n",
            "Epoch 48/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.0507 - accuracy: 0.2210\n",
            "Epoch 49/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0486 - accuracy: 0.2217\n",
            "Epoch 50/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0487 - accuracy: 0.2215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbf34ac27f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx-jxXncYmlp"
      },
      "source": [
        "## Category Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWvr6fgJLGHP"
      },
      "source": [
        "seq_x = convert_text_to_index(wear_data['SENTENCE'].tolist(), word_to_index, ENCODER_INPUT)\n",
        "catgory_index_arr = pd.factorize(wear_data['CATEGORY'])[0]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seok_9PxYrlV"
      },
      "source": [
        "main = wear_data['MAIN']\n",
        "category = wear_data['CATEGORY']\n",
        "all_stc = wear_data['SENTENCE']\n",
        "\n",
        "category_info = pd.DataFrame({\"stc\":all_stc, \"cate\":main})\n",
        "rough_info = pd.DataFrame({\"stc\":all_stc, \"cate\":category})"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uawcREfY87l",
        "outputId": "5972ccb5-28dc-42de-8462-7dd2bc6901e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "category_info.dropna(inplace = True)\n",
        "category_info.reset_index(drop=True, inplace = True)\n",
        "\n",
        "rough_info.dropna(inplace = True)\n",
        "rough_info.reset_index(drop=True, inplace = True)\n",
        "\n",
        "print(category_info.shape, rough_info.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15725, 2) (15826, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-h0d_06Y_GA"
      },
      "source": [
        "def make_tokenize(info):\n",
        "    tagger = Okt()\n",
        "\n",
        "    for i in range(info.shape[0]):\n",
        "        info['stc'][i] = tagger.morphs(info['stc'][i])\n",
        "\n",
        "make_tokenize(category_info)\n",
        "make_tokenize(rough_info)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmGrD5juZ_ET"
      },
      "source": [
        "category_list = pd.factorize(category_info['cate'])[1]\n",
        "category_info['cate'] = pd.factorize(category_info['cate'])[0]\n",
        "\n",
        "rough_category_list = pd.factorize(rough_info['cate'])[1]\n",
        "rough_info['cate'] = pd.factorize(rough_info['cate'])[0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQLKF7FkbRAi"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "category_ans = to_categorical(category_info['cate']) # 카테고리 관련 원핫벡터 카테고리\n",
        "rough_ans = to_categorical(rough_info['cate']) # 4개 카테고리 관련 원핫벡터 카테고리"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZavgRPJdM79"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "ctokenizer = Tokenizer(5000) \n",
        "ctokenizer.fit_on_texts(category_info['stc'])\n",
        "ctoken_stc = ctokenizer.texts_to_sequences(category_info['stc'])\n",
        "category_stc = ctoken_stc\n",
        "\n",
        "rtokenizer = Tokenizer(5000) \n",
        "rtokenizer.fit_on_texts(rough_info['stc'])\n",
        "rtoken_stc = rtokenizer.texts_to_sequences(rough_info['stc'])\n",
        "rough_stc = rtoken_stc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soNw3c6Cen_G"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len = 15\n",
        "category_stc = pad_sequences(category_stc, maxlen=max_len) # 카테고리 관련 패딩까지 마친 문장 모음\n",
        "rough_stc = pad_sequences(rough_stc, maxlen=max_len) # 4개 카테고리 관련 패딩까지 마친 문장 모음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2SP7QT_a-4n"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cX_train, cX_test, cy_train, cy_test = train_test_split(\n",
        "    category_stc, category_ans, test_size = 0.2, shuffle = True, random_state = 11)\n",
        "\n",
        "rX_train, rX_test, ry_train, ry_test = train_test_split(\n",
        "    rough_stc, rough_ans, test_size = 0.2, shuffle = True, random_state = 11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW-r-YFCfVgv"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "\n",
        "cmodel = Sequential()\n",
        "cmodel.add(Embedding(5000, 128))\n",
        "cmodel.add(LSTM(128))\n",
        "cmodel.add(Dense(405, activation='softmax'))\n",
        "\n",
        "rmodel = Sequential()\n",
        "rmodel.add(Embedding(5000, 100))\n",
        "rmodel.add(LSTM(128))\n",
        "rmodel.add(Dense(4, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHQoXs8wfkYk"
      },
      "source": [
        "cmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "cmodel.fit(cX_train, cy_train, validation_data=(cX_test, cy_test), batch_size=32, epochs=30) # 128 64 32 실험"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYqy-6NEfrXJ"
      },
      "source": [
        "rmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "rmodel.fit(rX_train, ry_train, validation_data=(rX_test, ry_test), batch_size=10, epochs=10) # 128 64 32 실험"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXEMQH_jf5jl"
      },
      "source": [
        "def find_category(stc,tokenizer,model,category_list):\n",
        "    tagger = Okt()\n",
        "    stc = tagger.morphs(stc)\n",
        "    encode_stc = tokenizer.texts_to_sequences([stc])\n",
        "    pad_stc = pad_sequences(encode_stc, maxlen=15)\n",
        "    score = model.predict(pad_stc)\n",
        "    return (category_list[score.argmax()], score[0, score.argmax()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6EDnEOwI_G7"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxi2B-vjydzt"
      },
      "source": [
        "# 인덱스를 문장으로 변환\n",
        "def convert_index_to_text(indexs, vocabulary): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == END_INDEX:\n",
        "            # 종료 인덱스면 중지\n",
        "            break;\n",
        "        if vocabulary.get(index) is not None:\n",
        "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
        "            sentence += vocabulary[index]\n",
        "        else:\n",
        "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
        "            sentence.extend([vocabulary[OOV_INDEX]])\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E66RpbXydzy"
      },
      "source": [
        "# 예측을 위한 입력 생성\n",
        "def make_predict_input(sentence):\n",
        "\n",
        "    sentences = []\n",
        "    sentences.append(sentence)\n",
        "    sentences = pos_tag(sentences)\n",
        "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
        "    \n",
        "    return input_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umBNECObKCJj"
      },
      "source": [
        "def evaluate(input_seq):\n",
        "\n",
        "  input_seq = input_seq.squeeze()\n",
        "  sentence = tf.expand_dims(input_seq, axis=0)\n",
        "  output = tf.expand_dims([1], 0)\n",
        "\n",
        "  for i in range(max_sequences):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, 2):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjLQI4czaTs1"
      },
      "source": [
        "##doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAs_p0bLhlPy"
      },
      "source": [
        "import os\n",
        "from gensim.models import doc2vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import pandas as pd\n",
        "import jpype\n",
        "from konlpy.tag import Kkma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYLVCfVfaB88"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exGo1HnHR5Dg"
      },
      "source": [
        "kkma = Kkma()\n",
        "filter_kkma = ['NNG', 'NNP','OL','VA','VV','VXV']\n",
        "\n",
        "def tokenizer_kkma(doc):\n",
        "    # 꼬꼬마 형태소 분석기가 자바 기반이어서 파이썬에서 자바함수들을 실행할 수 있는 명령어 (jpype) 를 써줘야한다.\n",
        "    jpype.attachThreadToJVM()       \n",
        "    token_doc = [\"/\".join(word) for word in kkma.pos(doc)]\n",
        "    return token_doc\n",
        "\n",
        "def tokenize_kkma_noun_verb(doc):\n",
        "    jpype.attachThreadToJVM()\n",
        "    token_doc = [\"/\".join(word) for word in kkma.pos(doc) if word[1] in filter_kkma]\n",
        "    return token_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzqye7pxR8kD"
      },
      "source": [
        "token_faqs = [(tokenizer_kkma(row[1]), row[0]) for row in faqs]\n",
        "tagged_faqs = [TaggedDocument(d,[c]) for d,c in token_faqs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_DB1CbDSNQj",
        "outputId": "5360a19d-a53c-4000-e46f-4b65430a4f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 모델 만들기\n",
        "# cpu 몇 개 쓸 건지\n",
        "import multiprocessing\n",
        "# 내 컴에 있는 cpu 갯수 cores 에 저장\n",
        "cores = multiprocessing.cpu_count()\n",
        "# vector_size : 임베딩할 벡터 차원\n",
        "# negaive : negative sampling\n",
        "d2v_faqs = doc2vec.Doc2Vec(\n",
        "    vector_size = 100,\n",
        "    alpha = 0.025,\n",
        "    min_alpha = 0.025,\n",
        "    hs = 1,\n",
        "    negative = 0,\n",
        "    dm = 0,\n",
        "    dbow_words = 1,\n",
        "    min_count = 1,\n",
        "    workers = cores,\n",
        "    seed = 0\n",
        ")\n",
        "\n",
        "# 단어 사전 만들기\n",
        "d2v_faqs.build_vocab(tagged_faqs)\n",
        "for epoch in range(4):\n",
        "  # 모델 학습\n",
        "  print(epoch)\n",
        "  d2v_faqs.train(tagged_faqs,\n",
        "                 total_examples = d2v_faqs.corpus_count,\n",
        "                 epochs = d2v_faqs.epochs)\n",
        "  d2v_faqs.alpha -=0.0025\n",
        "  d2v_faqs.min_alpha = d2v_faqs.min_alpha"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjxPAkUcRXNQ"
      },
      "source": [
        "##합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "audGWlqWURLT"
      },
      "source": [
        "def give_cate(input_question): #카테고리추출하는 함수\n",
        "  big_cate=find_category(input_question,ctokenizer,cmodel,category_list)\n",
        "  samll_cate=find_category(input_question,rtokenizer,rmodel,rough_category_list)\n",
        "  return big_cate,samll_cate #리턴값으로 큰카테고리(이름,유사도),작은 카테고리(이름,유사도)\n",
        "\n",
        "def give_answer(input_question): #질문입력시 transfomer로 답변함\n",
        "  return convert_index_to_text(evaluate(make_predict_input(input_question)).numpy()[1:],index_to_word)\n",
        "\n",
        "def doc2_answer(input_question): #질문 입력시 doc2으로 답변함\n",
        "  token_test = tokenizer_kkma(input_question)\n",
        "  predict_vector = d2v_faqs.infer_vector(token_test)\n",
        "  result = d2v_faqs.docvecs.most_similar([predict_vector],topn=1)\n",
        "  return faqs[int(result[0][0])-1][2]\n",
        "\n",
        "def score_calcul(left_cate,right_cate):#카테고리를 두개를 입력하면 유사도를 계산함\n",
        "  result = 0\n",
        "  if left_cate[0]==right_cate[0]:\n",
        "    result += abs(left_cate[1]-right_cate[1])\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oOsaFW9RpBK",
        "outputId": "a2029d76-5358-4ca2-e3c3-26a87cc6c8db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_question = input()\n",
        "\n",
        "q_big_cate,q_samll_cate=give_cate(input_question)\n",
        "\n",
        "print(f\"{q_big_cate},{q_samll_cate}\")\n",
        "\n",
        "dm=doc2_answer(input_question)\n",
        "dm_big_cate,dm_small_cate=give_cate(dm)\n",
        "cm=give_answer(input_question)\n",
        "cm_big_cate,cm_small_cate=give_cate(cm)\n",
        "\n",
        "doc2_score=0\n",
        "tran_score=0\n",
        "\n",
        "doc2_score += score_calcul(q_big_cate,dm_big_cate)\n",
        "doc2_score += score_calcul(q_big_cate,dm_small_cate)\n",
        "tran_score += score_calcul(q_big_cate,cm_big_cate)\n",
        "tran_score += score_calcul(q_big_cate,dm_small_cate)\n",
        "\n",
        "if doc2_score>=tran_score:\n",
        "  print(f\"***doc2: {dm}\")\n",
        "else:\n",
        "  print(f\"***tran: {cm}\")\n",
        "\n",
        "print(\"==================================\")\n",
        "print(f\"doc2: {dm_big_cate},{dm_small_cate}\")\n",
        "print(dm)\n",
        "if doc2_score!=0:\n",
        "  print(doc2_score)\n",
        "else:\n",
        "  print(\"평가불가\")\n",
        "print(\"\")\n",
        "print(f\"tran: {cm_big_cate},{cm_small_cate}\")\n",
        "print(cm)\n",
        "if tran_score!=0:\n",
        "  print(tran_score)\n",
        "else:\n",
        "  print(\"평가불가\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "카운터에 있는 점원이 입고 있는 옷 맘에 드는데 어떤 제품인가요?\n",
            "('유사제품추천문의', 0.6587085),('신발', 0.9972078)\n",
            "***doc2: 네 피팅룸은 이쪽입니다\n",
            "==================================\n",
            "doc2: ('제품요청', 0.50416297),('의류', 0.999944)\n",
            "네 피팅룸은 이쪽입니다\n",
            "평가불가\n",
            "\n",
            "tran: ('제품별추천문의', 0.67691714),('의류', 0.88469416)\n",
            "고객 님 이 제품 은 어떠 신지 요 ? \n",
            "평가불가\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}