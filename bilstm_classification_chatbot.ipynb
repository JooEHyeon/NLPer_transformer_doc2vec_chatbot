{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "bilstm_classification_chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ioT3c4eLEKon",
        "jx-jxXncYmlp",
        "e6EDnEOwI_G7"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ideablast/NLPer_chatbot/blob/kdg/bilstm_classification_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsiilWsMNHHL",
        "outputId": "6ed4d82a-68ad-4593-9c1a-d02756093397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install konlpy\n",
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 74.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/96/1030895dea70855a2e1078e3fe0d6a63dcb7c212309e07dc9ee39d33af54/JPype1-1.1.2-cp36-cp36m-manylinux2010_x86_64.whl (450kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 59.5MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, tweepy, beautifulsoup4, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.1.2 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n",
            "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
            "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-58ewcrob\n",
            "  Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-58ewcrob\n",
            "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.3.0)\n",
            "Requirement already satisfied: keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.4.3)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.3) (2.10.0)\n",
            "Collecting argparse>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.33.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (3.3.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.18.5)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.35.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.12.1)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->pykospacing==0.3) (0.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.4.3->pykospacing==0.3) (3.13)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.17.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (2.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (4.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->pykospacing==0.3) (0.4.8)\n",
            "Building wheels for collected packages: pykospacing\n",
            "  Building wheel for pykospacing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykospacing: filename=pykospacing-0.3-cp36-none-any.whl size=2255638 sha256=8919f3772dcd6bbb2acd577c399afa4b8bcd87124ca0ce7ebd3214c74cb07aac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t0o_1p9m/wheels/4d/45/58/e26cb2b7f6a063d234158c6fd1e5700f6e15b99d67154340ba\n",
            "Successfully built pykospacing\n",
            "Installing collected packages: argparse, pykospacing\n",
            "Successfully installed argparse-1.4.0 pykospacing-0.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ssut/py-hanspell.git\n",
            "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-dijt3fy2\n",
            "  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-dijt3fy2\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from py-hanspell==1.1) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (2020.6.20)\n",
            "Building wheels for collected packages: py-hanspell\n",
            "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-hanspell: filename=py_hanspell-1.1-cp36-none-any.whl size=4854 sha256=f6ac4f76d83bccd8924988e6121606aec7a78fdfdba363b82d08eefae5e30f0e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d5syj4ic/wheels/0a/25/d1/e5e96476dbb1c318cc26c992dd493394fe42b0c204b3e65588\n",
            "Successfully built py-hanspell\n",
            "Installing collected packages: py-hanspell\n",
            "Successfully installed py-hanspell-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UA-8fQ2EDnp"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DAFy5c7ydzC"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers, losses, metrics\n",
        "from keras import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from hanspell import spell_checker\n",
        "from pykospacing import spacing\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioT3c4eLEKon"
      },
      "source": [
        "## Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9YUdE1OydzG"
      },
      "source": [
        "# 태그 단어\n",
        "PAD = \"<PADDING>\"   # 패딩\n",
        "STA = \"<START>\"     # 시작\n",
        "END = \"<END>\"       # 끝\n",
        "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
        "\n",
        "# 태그 인덱스\n",
        "PAD_INDEX = 0\n",
        "STA_INDEX = 1\n",
        "END_INDEX = 2\n",
        "OOV_INDEX = 3\n",
        "\n",
        "# 데이터 타입\n",
        "ENCODER_INPUT  = 0\n",
        "DECODER_INPUT  = 1\n",
        "DECODER_TARGET = 2\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256 ##word embedding dim\n",
        "NUM_HEADS = 8 ## D_Model % NUM_HEADS == 0이 되야하므로...\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "EPOCHS = 50\n",
        "# for data pipelining\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "VOCAB_SIZE = 0 # 후에 len(words) 로 바뀜.\n",
        "\n",
        "# 한 문장에서 단어 시퀀스의 최대 개수\n",
        "max_sequences = 30\n",
        "\n",
        "# 정규 표현식 필터\n",
        "RE_FILTER = re.compile(\"[\\\"':;~()]\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhVVnW_uEWT1"
      },
      "source": [
        "## Data Load & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80IauV0FpUv2",
        "outputId": "9f74e7d2-35df-4bff-ef14-b6023470f4bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEHDnPXNzZlM",
        "outputId": "3f15a3d9-83a0-4f8f-b9ef-0ed2a4376863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wear_data = pd.read_csv(\"/content/drive/My Drive/wear_MAIN_edited.csv\")\n",
        "print(wear_data.shape)\n",
        "customer = wear_data[wear_data.SPEAKER == \"고객\"].SENTENCE\n",
        "store = wear_data[wear_data.SPEAKER == \"점원\"].SENTENCE\n",
        "print(customer.shape, store.shape) # 질문의 개수와 답의 개수가 일치하지 않는다."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15826, 20)\n",
            "(8381,) (7445,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLNSiqcHM4WY"
      },
      "source": [
        "prev = \"고객\"\n",
        "store_arr = []\n",
        "customer_arr = []\n",
        "store_stc = \"\"\n",
        "customer_stc = \"\"\n",
        "customer_C = \"\" #고객의 마지막 문장의 CATEGORY\n",
        "customer_M = \"\" #고객의 마지막 문장의 의도\n",
        "\n",
        "c_m = []\n",
        "for i in range(wear_data.shape[0]):\n",
        "    customer_C = wear_data.iloc[i].CATEGORY\n",
        "    customer_M = wear_data.iloc[i].MAIN\n",
        "    if (prev == wear_data.iloc[i].SPEAKER):\n",
        "        if prev == \"점원\":\n",
        "             store_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "        else : \n",
        "             customer_stc += (\" \"+wear_data.iloc[i].SENTENCE)\n",
        "            \n",
        "    elif prev == \"점원\": # 점원 -> 고객\n",
        "        store_arr.append(store_stc)\n",
        "        customer_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"고객\"\n",
        "    else : # 고객 -> 점원\n",
        "        customer_arr.append(customer_stc)\n",
        "        c_m.append([customer_C,customer_M])\n",
        "        store_stc = wear_data.iloc[i].SENTENCE\n",
        "        prev = \"점원\"\n",
        "\n",
        "# print(len(store_arr))\n",
        "# print(len(customer_arr))\n",
        "# print(store_arr[-1])\n",
        "# print(customer_arr[-1]) # 자료 상에서 이후에는 계속 고객의 물음만 계속된다. 코드 레벨에서 이 부분은 빼게 구현했다. (stc는 만들어지지만 arr에 append 안하게 된다.)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByO6b_S10b6m"
      },
      "source": [
        "faqs = []\n",
        "for i in range(len(store_arr)):\n",
        "    faqs_tmp =[]\n",
        "    faqs_tmp.append(str(i+1))\n",
        "    faqs_tmp.append(customer_arr[i])\n",
        "    faqs_tmp.append(store_arr[i])\n",
        "\n",
        "    faqs.append(faqs_tmp)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSC-cPrN7Sen"
      },
      "source": [
        "for i in range(len(faqs)):\n",
        "  faqs[i].extend(c_m[i])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUOvBciM4G2g"
      },
      "source": [
        "category_arr = []\n",
        "main_arr = []\n",
        "for i in faqs:\n",
        "  category_arr.append(i[3])\n",
        "  main_arr.append(i[4])\n",
        "\n",
        "category_set = set(category_arr)\n",
        "main_set = set(main_arr)\n",
        "\n",
        "category_to_index = {word: index for index, word in enumerate(category_set)}\n",
        "main_to_index = {word: index for index, word in enumerate(main_set)} #질문의 의도만 가져오다보니 405개에서 387개로 줄어들음\n",
        "\n",
        "index_to_category = {index: word for index, word in enumerate(category_set)}\n",
        "index_to_main = {index: word for index, word in enumerate(main_set)}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IBBlpka5yNP"
      },
      "source": [
        "for i,item in enumerate(faqs):\n",
        "  faqs[i][3] = category_to_index[item[3]]\n",
        "  faqs[i][4] = main_to_index[item[4]]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNvig2FMzjXj",
        "outputId": "2a2d31f7-010f-467f-be0b-43ec45f82d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "question = []\n",
        "answer = []\n",
        "\n",
        "for Q in customer_arr:\n",
        "    question.append(Q.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "for A in store_arr:\n",
        "    answer.append(A.replace(\"[^\\w]\", \" \"))\n",
        "\n",
        "len(question), len(answer)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7301, 7301)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbivSckMydzN"
      },
      "source": [
        "# 형태소분석 함수\n",
        "def pos_tag(sentences):\n",
        "    \n",
        "    # KoNLPy 형태소분석기 설정\n",
        "    tagger = Okt()\n",
        "    \n",
        "    # 문장 품사 변수 초기화\n",
        "    sentences_pos = []\n",
        "    \n",
        "    # 모든 문장 반복\n",
        "    for sentence in sentences:\n",
        "        # [\\\"':;~()] 특수기호 제거\n",
        "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
        "        \n",
        "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
        "        sentence = \" \".join(tagger.morphs(sentence))\n",
        "        sentences_pos.append(sentence)\n",
        "        \n",
        "    return sentences_pos"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seqSNWcydzP",
        "outputId": "9a6c530b-8051-4d04-9f76-b08141bcf7ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 형태소분석 수행\n",
        "question = pos_tag(question)\n",
        "answer = pos_tag(answer)\n",
        "\n",
        "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
        "for i in range(5):\n",
        "    print('Q : ' + question[i])\n",
        "    print('A : ' + answer[i])\n",
        "    print()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q : 신발 은 여기 있는 게 다예 요 ?\n",
            "A : 네 성인 이나 아동 다 있어요 발 사이즈 몇 신으세요 ?\n",
            "\n",
            "Q : 230 이요\n",
            "A : 편하게 신 을 수 있는 거 찾으세요 ?\n",
            "\n",
            "Q : 네 봄 이니까 편하게 신 을 수 있는 거\n",
            "A : 이런 건 어떠세요 ? 이런 거도 신발 무척 편하거든요\n",
            "\n",
            "Q : 굽 좀 높은 거 없나요 ?\n",
            "A : 봄 상품 은 아직 어른 제품 이 많이 안 나왔습니다\n",
            "\n",
            "Q : 언제 들어와요 ?\n",
            "A : 이번 주 지나면 들어올 거 예요\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrnct_nzydzR"
      },
      "source": [
        "# 질문과 대답 문장들을 하나로 합침\n",
        "sentences = []\n",
        "sentences.extend(question)\n",
        "sentences.extend(answer)\n",
        "\n",
        "words = []\n",
        "\n",
        "# 단어들의 배열 생성\n",
        "for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "        words.append(word)\n",
        "\n",
        "# 길이가 0인 단어는 삭제\n",
        "words = [word for word in words if len(word) > 0]\n",
        "\n",
        "# 중복된 단어 삭제\n",
        "words = list(set(words))\n",
        "\n",
        "# 제일 앞에 태그 단어 삽입\n",
        "words[:0] = [PAD, STA, END, OOV]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE9ZhJpEy_rT",
        "outputId": "c1fcb148-9e0a-46d4-d5d8-8562f9a40a13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "VOCAB_SIZE = len(words)\n",
        "print(\"손님과 점원의 말에서 사용된 총 단어의 수 :\",len(words))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "손님과 점원의 말에서 사용된 총 단어의 수 : 6409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN-hToCq2QL3",
        "outputId": "7866c252-0a8a-4640-c1ca-1f928e93bf06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "words[:10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<PADDING>',\n",
              " '<START>',\n",
              " '<END>',\n",
              " '<OOV>',\n",
              " '밸런스',\n",
              " '지워요',\n",
              " '된다',\n",
              " '9200원',\n",
              " '뒷',\n",
              " '가디건']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkvyOnSvydzX"
      },
      "source": [
        "# 단어와 인덱스의 딕셔너리 생성\n",
        "word_to_index = {word: index for index, word in enumerate(words)}\n",
        "index_to_word = {index: word for index, word in enumerate(words)}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfoTztrvydzc"
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "def convert_text_to_index(sentences, vocabulary, type): \n",
        "    \n",
        "    sentences_index = []\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for sentence in sentences:\n",
        "        sentence_index = []\n",
        "        \n",
        "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
        "        if type == DECODER_INPUT:\n",
        "            sentence_index.extend([vocabulary[STA]])\n",
        "        \n",
        "        # 문장의 단어들을 띄어쓰기로 분리\n",
        "        for word in sentence.split():\n",
        "            if vocabulary.get(word) is not None:\n",
        "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[word]])\n",
        "            else:\n",
        "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "        # 최대 길이 검사\n",
        "        if type == DECODER_TARGET:\n",
        "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
        "            if len(sentence_index) >= max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
        "            else:\n",
        "                sentence_index += [vocabulary[END]]\n",
        "        else:\n",
        "            if len(sentence_index) > max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences]\n",
        "            \n",
        "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "        \n",
        "        # 문장의 인덱스 배열을 추가\n",
        "        sentences_index.append(sentence_index)\n",
        "\n",
        "    return np.asarray(sentences_index)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zezFPTvcydzf",
        "outputId": "af93291e-a6ee-4d48-e644-b68d9173cfa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 인코더 입력 인덱스 변환\n",
        "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
        "\n",
        "# 첫 번째 인코더 입력 출력 (신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_encoder[0]\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4280, 1256, 5062, 3237, 1873, 1993, 5346, 3220,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmql1Lf_ydzh",
        "outputId": "e4687418-8d90-42c1-b248-033f35831021",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 입력 인덱스 변환\n",
        "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (<START> 신발 은 여기 있는 게 다예 요)\n",
        "print(question[0])\n",
        "x_decoder[0]\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1, 3128, 1435, 2031, 5501, 4270,  246, 1092,  551, 4643, 4224,\n",
              "       3220,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIhDbaLydzk",
        "outputId": "ff321f9d-c4d3-49b7-8a2a-748d02926b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 디코더 목표 인덱스 변환\n",
        "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (신발 은 여기 있는 게 다예 요 <END>)\n",
        "print(question[0])\n",
        "y_decoder[0]\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신발 은 여기 있는 게 다예 요 ?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3128, 1435, 2031, 5501, 4270,  246, 1092,  551, 4643, 4224, 3220,\n",
              "          2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsf4tJl61Xi9"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsxmXWS41XVd"
      },
      "source": [
        "# decoder inputs use the previous target as input\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': x_encoder,\n",
        "        'dec_inputs': x_decoder\n",
        "    },\n",
        "    {\n",
        "        'outputs': y_decoder\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxXCQWvw2jwx"
      },
      "source": [
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH-k-kk_1_Vu"
      },
      "source": [
        "## scaled dot product Attention\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True) # QK^T\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth) #  QK^T / sqrt(d_k)\n",
        "\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9) # zero padding token softmax 결과가 0이 나오도록\n",
        "  \n",
        "  attention_weights = tf.nn.softmax(logits, axis = -1) # softmax(QK^T / sqrt(d_k))\n",
        "\n",
        "  output = tf.matmul(attention_weights, value) # softmax(QK^T / sqrt(d_k)) * V\n",
        "\n",
        "  return output"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7orcKMr13xY8"
      },
      "source": [
        "## multi-head attention\n",
        "## each head need (scaled_dot_product_attention)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0 # 128,8\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "  \n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(inputs, shape=(batch_size,-1,self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3]) ##????\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    #linear\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    #split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    #scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    #concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "\n",
        "    #final linear\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmlW0oi89nEC"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37sh3f8P-JUB",
        "outputId": "7eb736af-23a0-4d88-f11b-39bdf14feed8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W7ld50z3vT2"
      },
      "source": [
        "# it handle mask future tokens in a sequence used decoder. and mask pad tokens\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W25teKwt_F80",
        "outputId": "f62376f9-0bdc-474a-ec29-34f96635fd1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLhXEIJgASo3"
      },
      "source": [
        "Positional encoding\n",
        "\n",
        "since we don't use any rnn, cnn, positional encoding give model position information of words in sentence.\n",
        "\n",
        "positional encoding vector is added to embedding vector\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7s19-x3_Hpq"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "  \n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles #pos/10000^(2i/d_model)\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position = tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model = d_model)\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLiumNZZDZGY"
      },
      "source": [
        "### Encoder Layer\n",
        "1. Multi-head attention (with padding mask)\n",
        "2. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oarRWUMLDYnC"
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query':inputs,\n",
        "          'key':inputs,\n",
        "          'value':inputs,\n",
        "          'mask':padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3rO9IcDHGE5"
      },
      "source": [
        "### Encoder\n",
        "1. Input Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` encoder layers\n",
        "\n",
        "Embedding + positional encoding : input\n",
        "\n",
        "going encoder layers.\n",
        "\n",
        "output going decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOwoi2_jHvbA"
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)#??왜 vocab_size가 들어가지?\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, padding_mask], outputs = outputs, name=name)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8XHH5dpJr-G"
      },
      "source": [
        "### Decoder Layer\n",
        "1. Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2. Multi-head attention (with padding mask). `value` and `key` is from encoder output. `query` is from Multi-head attention layer output\n",
        "3. 2 dense layers followed by dropout\n",
        "\n",
        "also has residual connection followd by a layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtAfKdk-JrxK"
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name=\"padding_mask\")\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query' : inputs,\n",
        "          'key' : inputs,\n",
        "          'value' : inputs,\n",
        "          'mask' : look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query' : attention1,\n",
        "          'key' : enc_outputs,\n",
        "          'value' : enc_outputs,\n",
        "          'mask' : padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnBSBcm1NAYv"
      },
      "source": [
        "### Decoder\n",
        "1. output Embedding\n",
        "2. Positional Encoding\n",
        "3. `num_layers` decoder layers\n",
        "\n",
        "Embedding + positional encoding : input (target)\n",
        "\n",
        "going decoder layers.\n",
        "\n",
        "output going final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnA-8FEAOT4F"
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"decoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1,1,None), name='padding_mask')\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units = units,\n",
        "        d_model = d_model,\n",
        "        num_heads = num_heads,\n",
        "        dropout = dropout,\n",
        "        name = \"decoder_layer_{}\".format(i),\n",
        "    )(inputs = [outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "  \n",
        "  return tf.keras.Model(\n",
        "      inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs = outputs,\n",
        "      name = name)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-vmtqKQjhf"
      },
      "source": [
        "### Transformer\n",
        "1. encoder\n",
        "2. decoder\n",
        "3. final linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEMfL5SFQqr4"
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"enc_padding_mask\")(inputs)\n",
        "  \n",
        "  #mask future tokens for decoder inputs at 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1,None,None),\n",
        "      name=\"look_ahead_mask\")(dec_inputs)\n",
        "  \n",
        "  #mask encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1,1,None),\n",
        "      name=\"dec_padding_mask\")(inputs)\n",
        "  \n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pav-8Jd3ydzp"
      },
      "source": [
        "## 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8y-mjWtydzp"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK3IwtA4TOnN"
      },
      "source": [
        "### Loss function\n",
        "since target sequences are padded, deal this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi7YnqpVTYn2"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "  \n",
        "  mask = tf.cast(tf.not_equal(y_true,0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzHEmCzUVhTu"
      },
      "source": [
        "### Custom learning rate\n",
        "use Adam optimizer with custom learning rate\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkFm9m_LVt8c"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb8PGbKgWAbP"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vql4FYFUV_3_"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, max_sequences))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTXbb1Z2I4IM"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl3V7BllWWFG",
        "outputId": "c4486f9b-39ab-4bbc-a143-8f0c42b349b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.9745 - accuracy: 0.0212\n",
            "Epoch 2/50\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.7337 - accuracy: 0.0333\n",
            "Epoch 3/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.4780 - accuracy: 0.0421\n",
            "Epoch 4/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.3197 - accuracy: 0.0458\n",
            "Epoch 5/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 1.2290 - accuracy: 0.0561\n",
            "Epoch 6/50\n",
            "115/115 [==============================] - 6s 57ms/step - loss: 1.1427 - accuracy: 0.0669\n",
            "Epoch 7/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 1.0619 - accuracy: 0.0749\n",
            "Epoch 8/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.9901 - accuracy: 0.0812\n",
            "Epoch 9/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.9265 - accuracy: 0.0865\n",
            "Epoch 10/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.8684 - accuracy: 0.0916\n",
            "Epoch 11/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.8145 - accuracy: 0.0964\n",
            "Epoch 12/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.7614 - accuracy: 0.1010\n",
            "Epoch 13/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.7114 - accuracy: 0.1056\n",
            "Epoch 14/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.6626 - accuracy: 0.1111\n",
            "Epoch 15/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.6111 - accuracy: 0.1175\n",
            "Epoch 16/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.5616 - accuracy: 0.1236\n",
            "Epoch 17/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.5127 - accuracy: 0.1302\n",
            "Epoch 18/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.4641 - accuracy: 0.1377\n",
            "Epoch 19/50\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4141 - accuracy: 0.1464\n",
            "Epoch 20/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.3699 - accuracy: 0.1541\n",
            "Epoch 21/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.3243 - accuracy: 0.1625\n",
            "Epoch 22/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.2804 - accuracy: 0.1720\n",
            "Epoch 23/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.2446 - accuracy: 0.1786\n",
            "Epoch 24/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.2120 - accuracy: 0.1850\n",
            "Epoch 25/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1853 - accuracy: 0.1909\n",
            "Epoch 26/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1654 - accuracy: 0.1948\n",
            "Epoch 27/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1472 - accuracy: 0.1982\n",
            "Epoch 28/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1370 - accuracy: 0.1998\n",
            "Epoch 29/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1279 - accuracy: 0.2015\n",
            "Epoch 30/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1167 - accuracy: 0.2041\n",
            "Epoch 31/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1119 - accuracy: 0.2052\n",
            "Epoch 32/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.1082 - accuracy: 0.2057\n",
            "Epoch 33/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1045 - accuracy: 0.2067\n",
            "Epoch 34/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.1004 - accuracy: 0.2074\n",
            "Epoch 35/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0997 - accuracy: 0.2078\n",
            "Epoch 36/50\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 0.0928 - accuracy: 0.2092\n",
            "Epoch 37/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0908 - accuracy: 0.2099\n",
            "Epoch 38/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0832 - accuracy: 0.2120\n",
            "Epoch 39/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0788 - accuracy: 0.2133\n",
            "Epoch 40/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0733 - accuracy: 0.2148\n",
            "Epoch 41/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0689 - accuracy: 0.2158\n",
            "Epoch 42/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0662 - accuracy: 0.2163\n",
            "Epoch 43/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0630 - accuracy: 0.2175\n",
            "Epoch 44/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0610 - accuracy: 0.2180\n",
            "Epoch 45/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0573 - accuracy: 0.2191\n",
            "Epoch 46/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0539 - accuracy: 0.2200\n",
            "Epoch 47/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.0522 - accuracy: 0.2205\n",
            "Epoch 48/50\n",
            "115/115 [==============================] - 7s 57ms/step - loss: 0.0507 - accuracy: 0.2210\n",
            "Epoch 49/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0486 - accuracy: 0.2217\n",
            "Epoch 50/50\n",
            "115/115 [==============================] - 6s 56ms/step - loss: 0.0487 - accuracy: 0.2215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbf34ac27f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx-jxXncYmlp"
      },
      "source": [
        "## Category Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8n8WAyTbYu1",
        "outputId": "ab89039d-44d2-4490-aa37-a996567284ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "faqs[:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['1', ' 신발은 여기 있는 게 다예요?', '네 성인이나 아동 다 있어요 발 사이즈 몇 신으세요?', 3, 197],\n",
              " ['2', '230이요', '편하게 신을 수 있는 거 찾으세요?', 3, 67],\n",
              " ['3', '네 봄이니까 편하게 신을 수 있는 거', '이런 건 어떠세요? 이런 거도 신발 무척 편하거든요', 3, 67],\n",
              " ['4', '굽 좀 높은 거 없나요?', '봄 상품은 아직 어른 제품이 많이 안나왔습니다', 3, 333],\n",
              " ['5', '언제 들어와요?', '이번주 지나면 들어올 거예요', 3, 242],\n",
              " ['6', '이거는 가죽이에요?', '가죽 아니고 쎄무예요', 3, 338],\n",
              " ['7', '가죽은 얼마예요?', '2만 9천 원입니다', 3, 347],\n",
              " ['8', '털 달린 거 저거는 사이즈 있어요?', '230이 없어요  이거 한 번 신어보세요', 3, 53],\n",
              " ['9', '좀 크네 또 안 들어와요?', '네 이건 다 끝났어요', 3, 242],\n",
              " ['10', '가방 매는 거 보고 있어요', '여기 있어요', 0, 219]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABLPQcW99mjB"
      },
      "source": [
        "category_y = []\n",
        "main_y = []\n",
        "for i in faqs:\n",
        "  category_y.append(i[3])\n",
        "  main_y.append(i[4])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAyr-ECE-tH-"
      },
      "source": [
        "def convert_text_to_index_for_classification(sentences, vocabulary): \n",
        "    \n",
        "    sentences_index = []\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for sentence in sentences:\n",
        "        sentence_index = []\n",
        "        \n",
        "        # 문장의 단어들을 띄어쓰기로 분리\n",
        "        for word in sentence.split():\n",
        "            if vocabulary.get(word) is not None:\n",
        "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[word]])\n",
        "            else:\n",
        "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "        if len(sentence_index) > max_sequences:\n",
        "            sentence_index = sentence_index[:max_sequences]\n",
        "            \n",
        "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "        \n",
        "        # 문장의 인덱스 배열을 추가\n",
        "        sentences_index.append(sentence_index)\n",
        "\n",
        "    return sentences_index"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ioc_akA_aZw",
        "outputId": "b4eb0ea5-3b69-443c-8342-69369cd6d2aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 분류모델에 들어갈 x 만들기\n",
        "question_index_for_cl = []\n",
        "answer_index_for_cl = []\n",
        "question_index_for_cl = convert_text_to_index_for_classification(question, word_to_index) #질문 문장에 정수인코딩,패딩\n",
        "answer_index_for_cl = convert_text_to_index_for_classification(answer, word_to_index)\n",
        "\n",
        "question_index_for_cl.extend(answer_index_for_cl) # 이렇게 합쳐줌으로써 question_index_for_cl 이 결국 분류모델의 x로 들어가게 될 예정\n",
        "len(question_index_for_cl)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEkfYKqa8a9c"
      },
      "source": [
        "# 분류모델에 들어갈 y만들기\n",
        "category_y = []\n",
        "main_y = []\n",
        "for i in faqs:\n",
        "  category_y.append(i[3])\n",
        "  main_y.append(i[4])\n",
        "\n",
        "category_y.extend(category_y) # 자기것을 그대로 뒤에 갓다붙임. 그래도 되는게, x의 0번 인덱스의 문장(고객의 질문)과 7301번 인덱스의 문장(점원의 답변)이 카테고리,의도가 같음.\n",
        "main_y.extend(main_y)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYhb9996D8Mq",
        "outputId": "10756733-fd05-401b-bf3c-db0d1caa0c90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(category_y), len(main_y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14602, 14602)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJOGQuodI_xy",
        "outputId": "3cf28d38-9b15-4a3e-f151-9bf4fb31c95a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.asarray(question_index_for_cl).shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14602, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "704PALElds4a",
        "outputId": "1d9b278d-92fd-4bfa-a6bc-da990bbe48e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "j = 0\n",
        "for i in np.asarray(question_index_for_cl):\n",
        "  if i[0]==0:\n",
        "    j+=1\n",
        "print(j)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB-wHnf9JCQZ",
        "outputId": "d29291cd-c30d-40ff-d645-d0181873080e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.asarray(main_y).shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14602,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHhczfJBkGtb",
        "outputId": "df6b06df-6dfd-4c7d-d55b-caab74dbf427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.asarray(question_index_for_cl).shape"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14602, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL5Wld5gkLDM",
        "outputId": "ffc3443d-b233-4891-af54-892057ef0198",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.asarray(category_y).shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14602,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW-r-YFCfVgv"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Masking, Bidirectional\n",
        "\n",
        "#의도 분류모델\n",
        "mmodel = Sequential()\n",
        "mmodel.add(Embedding(VOCAB_SIZE, 100))\n",
        "mmodel.add(Masking(mask_value=0.0))\n",
        "mmodel.add(Bidirectional(LSTM(128)))\n",
        "mmodel.add(Dense(387, activation='softmax'))\n",
        "\n",
        "#카테고리 분류모델\n",
        "cmodel = Sequential()\n",
        "cmodel.add(Embedding(VOCAB_SIZE, 100))\n",
        "cmodel.add(Masking(mask_value=0.0))\n",
        "cmodel.add(Bidirectional(LSTM(128)))\n",
        "cmodel.add(Dense(4, activation='softmax'))"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHQoXs8wfkYk",
        "outputId": "a6d964a3-530e-4f9b-bc28-5abab890e4f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "history_m = mmodel.fit(np.asarray(question_index_for_cl), np.asarray(main_y), validation_split=0.1, batch_size=32, epochs=30)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "411/411 [==============================] - 10s 25ms/step - loss: 4.5208 - acc: 0.1460 - val_loss: 4.4313 - val_acc: 0.1102\n",
            "Epoch 2/30\n",
            "411/411 [==============================] - 6s 14ms/step - loss: 3.5766 - acc: 0.2688 - val_loss: 3.9490 - val_acc: 0.2019\n",
            "Epoch 3/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 2.8578 - acc: 0.3805 - val_loss: 3.6150 - val_acc: 0.2628\n",
            "Epoch 4/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 2.3702 - acc: 0.4631 - val_loss: 3.7241 - val_acc: 0.2683\n",
            "Epoch 5/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 1.9932 - acc: 0.5358 - val_loss: 3.7051 - val_acc: 0.2888\n",
            "Epoch 6/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 1.7006 - acc: 0.5950 - val_loss: 3.7392 - val_acc: 0.2957\n",
            "Epoch 7/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 1.4605 - acc: 0.6479 - val_loss: 4.0561 - val_acc: 0.2882\n",
            "Epoch 8/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 1.2728 - acc: 0.6950 - val_loss: 4.1246 - val_acc: 0.2882\n",
            "Epoch 9/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 1.1201 - acc: 0.7285 - val_loss: 4.2427 - val_acc: 0.2731\n",
            "Epoch 10/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.9933 - acc: 0.7595 - val_loss: 4.1912 - val_acc: 0.2772\n",
            "Epoch 11/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.8798 - acc: 0.7904 - val_loss: 4.3537 - val_acc: 0.2758\n",
            "Epoch 12/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.7973 - acc: 0.8056 - val_loss: 4.4756 - val_acc: 0.2697\n",
            "Epoch 13/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.7269 - acc: 0.8219 - val_loss: 4.7863 - val_acc: 0.2615\n",
            "Epoch 14/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.6651 - acc: 0.8359 - val_loss: 4.8326 - val_acc: 0.2526\n",
            "Epoch 15/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.6044 - acc: 0.8530 - val_loss: 4.6881 - val_acc: 0.2704\n",
            "Epoch 16/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.5607 - acc: 0.8588 - val_loss: 4.7805 - val_acc: 0.2799\n",
            "Epoch 17/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.5212 - acc: 0.8689 - val_loss: 4.9022 - val_acc: 0.2656\n",
            "Epoch 18/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.4830 - acc: 0.8802 - val_loss: 5.0304 - val_acc: 0.2683\n",
            "Epoch 19/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.4488 - acc: 0.8876 - val_loss: 5.1461 - val_acc: 0.2594\n",
            "Epoch 20/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.4211 - acc: 0.8912 - val_loss: 5.1058 - val_acc: 0.2704\n",
            "Epoch 21/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.4016 - acc: 0.8956 - val_loss: 5.5094 - val_acc: 0.2368\n",
            "Epoch 22/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.3804 - acc: 0.9017 - val_loss: 5.4163 - val_acc: 0.2649\n",
            "Epoch 23/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.3602 - acc: 0.9060 - val_loss: 5.4292 - val_acc: 0.2533\n",
            "Epoch 24/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.3458 - acc: 0.9113 - val_loss: 5.3972 - val_acc: 0.2635\n",
            "Epoch 25/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.3378 - acc: 0.9113 - val_loss: 5.4986 - val_acc: 0.2663\n",
            "Epoch 26/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.3211 - acc: 0.9138 - val_loss: 5.5645 - val_acc: 0.2574\n",
            "Epoch 27/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.3037 - acc: 0.9193 - val_loss: 5.6717 - val_acc: 0.2601\n",
            "Epoch 28/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.2948 - acc: 0.9199 - val_loss: 5.5720 - val_acc: 0.2621\n",
            "Epoch 29/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.2906 - acc: 0.9202 - val_loss: 5.7106 - val_acc: 0.2621\n",
            "Epoch 30/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.2833 - acc: 0.9204 - val_loss: 5.7636 - val_acc: 0.2580\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bX-vKIaS3MF"
      },
      "source": [
        "mmodel.save('main_lstm_cl.h5')"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGQ3iSMkThaN"
      },
      "source": [
        "load_m_model = models.load_model('main_lstm_cl.h5')"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlLD_Nv6GMYz",
        "outputId": "ab47d6b2-f5c0-4dd5-f9cc-9d8af6a63c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(history_m.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(history_m.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(history_m.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(history_m.history['val_acc'], 'g', label='val acc')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYqy-6NEfrXJ",
        "outputId": "821fa01f-f2df-4a9d-96a8-68b4927a6272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "history_c = cmodel.fit(np.asarray(question_index_for_cl), np.asarray(category_y), validation_split=0.1, batch_size=32, epochs=30) # 128 64 32 실험"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "411/411 [==============================] - 8s 19ms/step - loss: 1.0851 - acc: 0.5161 - val_loss: 0.6656 - val_acc: 0.7632\n",
            "Epoch 2/30\n",
            "411/411 [==============================] - 6s 14ms/step - loss: 0.7553 - acc: 0.6901 - val_loss: 0.6915 - val_acc: 0.6831\n",
            "Epoch 3/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.6267 - acc: 0.7458 - val_loss: 0.7421 - val_acc: 0.6715\n",
            "Epoch 4/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.5550 - acc: 0.7701 - val_loss: 0.7555 - val_acc: 0.6749\n",
            "Epoch 5/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.5042 - acc: 0.7885 - val_loss: 0.8558 - val_acc: 0.6632\n",
            "Epoch 6/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.4768 - acc: 0.7993 - val_loss: 0.8407 - val_acc: 0.6646\n",
            "Epoch 7/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.4462 - acc: 0.8085 - val_loss: 0.8447 - val_acc: 0.6797\n",
            "Epoch 8/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.4169 - acc: 0.8225 - val_loss: 0.9646 - val_acc: 0.6680\n",
            "Epoch 9/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.4008 - acc: 0.8270 - val_loss: 1.0289 - val_acc: 0.6674\n",
            "Epoch 10/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3904 - acc: 0.8313 - val_loss: 0.9929 - val_acc: 0.7488\n",
            "Epoch 11/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3735 - acc: 0.8387 - val_loss: 1.1055 - val_acc: 0.6530\n",
            "Epoch 12/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3543 - acc: 0.8494 - val_loss: 1.1124 - val_acc: 0.6639\n",
            "Epoch 13/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3436 - acc: 0.8520 - val_loss: 1.2516 - val_acc: 0.6523\n",
            "Epoch 14/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3313 - acc: 0.8573 - val_loss: 1.2098 - val_acc: 0.6482\n",
            "Epoch 15/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3252 - acc: 0.8586 - val_loss: 1.2979 - val_acc: 0.6454\n",
            "Epoch 16/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3176 - acc: 0.8610 - val_loss: 1.3926 - val_acc: 0.6366\n",
            "Epoch 17/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.3061 - acc: 0.8658 - val_loss: 1.3123 - val_acc: 0.6694\n",
            "Epoch 18/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2947 - acc: 0.8710 - val_loss: 1.5765 - val_acc: 0.6393\n",
            "Epoch 19/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2904 - acc: 0.8730 - val_loss: 1.5425 - val_acc: 0.6372\n",
            "Epoch 20/30\n",
            "411/411 [==============================] - 6s 14ms/step - loss: 0.2805 - acc: 0.8773 - val_loss: 1.5780 - val_acc: 0.6331\n",
            "Epoch 21/30\n",
            "411/411 [==============================] - 6s 14ms/step - loss: 0.2691 - acc: 0.8824 - val_loss: 1.6811 - val_acc: 0.6352\n",
            "Epoch 22/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2633 - acc: 0.8856 - val_loss: 1.7184 - val_acc: 0.6461\n",
            "Epoch 23/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2613 - acc: 0.8865 - val_loss: 1.5853 - val_acc: 0.6502\n",
            "Epoch 24/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2519 - acc: 0.8908 - val_loss: 1.6437 - val_acc: 0.6605\n",
            "Epoch 25/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2442 - acc: 0.8946 - val_loss: 1.5970 - val_acc: 0.6509\n",
            "Epoch 26/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2443 - acc: 0.8935 - val_loss: 1.7792 - val_acc: 0.6338\n",
            "Epoch 27/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2276 - acc: 0.9015 - val_loss: 1.8550 - val_acc: 0.6331\n",
            "Epoch 28/30\n",
            "411/411 [==============================] - 5s 13ms/step - loss: 0.2211 - acc: 0.9047 - val_loss: 1.9245 - val_acc: 0.6324\n",
            "Epoch 29/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2136 - acc: 0.9078 - val_loss: 1.9414 - val_acc: 0.6256\n",
            "Epoch 30/30\n",
            "411/411 [==============================] - 5s 12ms/step - loss: 0.2089 - acc: 0.9080 - val_loss: 1.9955 - val_acc: 0.6393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiLiJVHRUgVr"
      },
      "source": [
        "cmodel.save('category_lstm_cl.h5')"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SlrE3fAMIGo",
        "outputId": "4036944f-342c-4833-cdcb-be877941ed50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(history_c.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(history_c.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(history_c.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(history_c.history['val_acc'], 'g', label='val acc')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6SLbwbHObjs",
        "outputId": "84a45230-4249-4963-b525-f0527e6bf2de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "index_to_category"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '신발', 1: '가방', 2: '의류', 3: '액세서리'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zdmR5oZHWsq"
      },
      "source": [
        "def predict_cm(question_index_for_cl, category_y, main_y): #형태소 분리된 문장들의 list가 입력으로 가야함.\n",
        "  # stc_x = convert_text_to_index_for_classification(questions, word_to_index)\n",
        "  j = 0\n",
        "  c = 0\n",
        "  m = 0\n",
        "  for i in question_index_for_cl:\n",
        "    if np.argmax(cmodel.predict(np.asarray(i).reshape(1,30))) != category_y[j]:\n",
        "      c += 1\n",
        "    if np.argmax(mmodel.predict(np.asarray(i).reshape(1,30))) != main_y[j]:\n",
        "      m += 1\n",
        "    j+=1\n",
        "  print(c, \"개의 문장의 카테고리가 맞지 않음\")\n",
        "  print(m, \"개의 문장의 의도가 맞지 않음\")"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXA9XMEZy7x4",
        "outputId": "5b39cf32-df8a-4af2-a7c0-b0fc711265d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_cm(question_index_for_cl, category_y, main_y)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1589 개의 문장의 카테고리가 맞지 않음\n",
            "1991 개의 문장의 의도가 맞지 않음\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXJLCyt0w95Y",
        "outputId": "1fd0fbcd-4593-4efc-bdce-6016c488f7eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.asarray(question_index_for_cl)[:10]"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4280, 1256, 5062, 3237, 1873, 1993, 5346, 3220,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [4629, 6058,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [3128, 1177, 6337, 5115, 4253, 3077, 2754, 3237, 5680,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [4856, 4457, 4357, 5680, 1509, 3220,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [4481, 1389, 3220,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [3336, 5680, 1602, 3261, 1329, 3220,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [3261, 1256, 3923, 5683, 3220,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [2968,  401, 5680, 1500, 5680, 1602,  551,  246, 3220,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [4457, 6274, 6300, 6158, 1389, 3220,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [5041, 2166, 5680, 3384,  246,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk46KWSNjTOl"
      },
      "source": [
        "predict_cm(question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXEMQH_jf5jl"
      },
      "source": [
        "def find_category(stc,tokenizer,model,category_list):\n",
        "    tagger = Okt()\n",
        "    stc = tagger.morphs(stc)\n",
        "    encode_stc = tokenizer.texts_to_sequences([stc])\n",
        "    pad_stc = pad_sequences(encode_stc, maxlen=15)\n",
        "    score = model.predict(pad_stc)\n",
        "    return (category_list[score.argmax()], score[0, score.argmax()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6EDnEOwI_G7"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxi2B-vjydzt"
      },
      "source": [
        "# 인덱스를 문장으로 변환\n",
        "def convert_index_to_text(indexs, vocabulary): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == END_INDEX:\n",
        "            # 종료 인덱스면 중지\n",
        "            break;\n",
        "        if vocabulary.get(index) is not None:\n",
        "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
        "            sentence += vocabulary[index]\n",
        "        else:\n",
        "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
        "            sentence.extend([vocabulary[OOV_INDEX]])\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E66RpbXydzy"
      },
      "source": [
        "# 예측을 위한 입력 생성\n",
        "def make_predict_input(sentence):\n",
        "\n",
        "    sentences = []\n",
        "    sentences.append(sentence)\n",
        "    sentences = pos_tag(sentences)\n",
        "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
        "    \n",
        "    return input_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umBNECObKCJj"
      },
      "source": [
        "def evaluate(input_seq):\n",
        "\n",
        "  input_seq = input_seq.squeeze()\n",
        "  sentence = tf.expand_dims(input_seq, axis=0)\n",
        "  output = tf.expand_dims([1], 0)\n",
        "\n",
        "  for i in range(max_sequences):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, 2):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjLQI4czaTs1"
      },
      "source": [
        "##doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAs_p0bLhlPy"
      },
      "source": [
        "import os\n",
        "from gensim.models import doc2vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import pandas as pd\n",
        "import jpype\n",
        "from konlpy.tag import Kkma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYLVCfVfaB88"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exGo1HnHR5Dg"
      },
      "source": [
        "kkma = Kkma()\n",
        "filter_kkma = ['NNG', 'NNP','OL','VA','VV','VXV']\n",
        "\n",
        "def tokenizer_kkma(doc):\n",
        "    # 꼬꼬마 형태소 분석기가 자바 기반이어서 파이썬에서 자바함수들을 실행할 수 있는 명령어 (jpype) 를 써줘야한다.\n",
        "    jpype.attachThreadToJVM()       \n",
        "    token_doc = [\"/\".join(word) for word in kkma.pos(doc)]\n",
        "    return token_doc\n",
        "\n",
        "def tokenize_kkma_noun_verb(doc):\n",
        "    jpype.attachThreadToJVM()\n",
        "    token_doc = [\"/\".join(word) for word in kkma.pos(doc) if word[1] in filter_kkma]\n",
        "    return token_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzqye7pxR8kD"
      },
      "source": [
        "token_faqs = [(tokenizer_kkma(row[1]), row[0]) for row in faqs]\n",
        "tagged_faqs = [TaggedDocument(d,[c]) for d,c in token_faqs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_DB1CbDSNQj",
        "outputId": "5360a19d-a53c-4000-e46f-4b65430a4f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 모델 만들기\n",
        "# cpu 몇 개 쓸 건지\n",
        "import multiprocessing\n",
        "# 내 컴에 있는 cpu 갯수 cores 에 저장\n",
        "cores = multiprocessing.cpu_count()\n",
        "# vector_size : 임베딩할 벡터 차원\n",
        "# negaive : negative sampling\n",
        "d2v_faqs = doc2vec.Doc2Vec(\n",
        "    vector_size = 100,\n",
        "    alpha = 0.025,\n",
        "    min_alpha = 0.025,\n",
        "    hs = 1,\n",
        "    negative = 0,\n",
        "    dm = 0,\n",
        "    dbow_words = 1,\n",
        "    min_count = 1,\n",
        "    workers = cores,\n",
        "    seed = 0\n",
        ")\n",
        "\n",
        "# 단어 사전 만들기\n",
        "d2v_faqs.build_vocab(tagged_faqs)\n",
        "for epoch in range(4):\n",
        "  # 모델 학습\n",
        "  print(epoch)\n",
        "  d2v_faqs.train(tagged_faqs,\n",
        "                 total_examples = d2v_faqs.corpus_count,\n",
        "                 epochs = d2v_faqs.epochs)\n",
        "  d2v_faqs.alpha -=0.0025\n",
        "  d2v_faqs.min_alpha = d2v_faqs.min_alpha"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPuuoO9WUwfT"
      },
      "source": [
        "# spell check and spacing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvEHNJR5X7Xh"
      },
      "source": [
        "def grammar_checker(sentence):\n",
        "\n",
        "  spacing_sentence = spacing(sentence.replace(' ',''))\n",
        "  spelled_sentence = spell_checker.check(spacing_sentence)\n",
        "  checked_sentence = spelled_sentence.checked\n",
        "\n",
        "  return checked_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjxPAkUcRXNQ"
      },
      "source": [
        "##합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "audGWlqWURLT"
      },
      "source": [
        "def give_cate(input_question): #카테고리추출하는 함수\n",
        "  big_cate=find_category(input_question,ctokenizer,cmodel,category_list)\n",
        "  samll_cate=find_category(input_question,rtokenizer,rmodel,rough_category_list)\n",
        "  return big_cate,samll_cate #리턴값으로 큰카테고리(이름,유사도),작은 카테고리(이름,유사도)\n",
        "\n",
        "def give_answer(input_question): #질문입력시 transfomer로 답변함\n",
        "  return convert_index_to_text(evaluate(make_predict_input(input_question)).numpy()[1:],index_to_word)\n",
        "\n",
        "def doc2_answer(input_question): #질문 입력시 doc2으로 답변함\n",
        "  token_test = tokenizer_kkma(input_question)\n",
        "  predict_vector = d2v_faqs.infer_vector(token_test)\n",
        "  result = d2v_faqs.docvecs.most_similar([predict_vector],topn=1)\n",
        "  return faqs[int(result[0][0])-1][2]\n",
        "\n",
        "def score_calcul(left_cate,right_cate):#카테고리를 두개를 입력하면 유사도를 계산함\n",
        "  result = 0\n",
        "  if left_cate[0]==right_cate[0]:\n",
        "    result += abs(left_cate[1]-right_cate[1])\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oOsaFW9RpBK",
        "outputId": "a2029d76-5358-4ca2-e3c3-26a87cc6c8db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_question = input()\n",
        "\n",
        "q_big_cate,q_samll_cate=give_cate(input_question)\n",
        "\n",
        "print(f\"{q_big_cate},{q_samll_cate}\")\n",
        "\n",
        "dm=doc2_answer(input_question)\n",
        "dm_big_cate,dm_small_cate=give_cate(dm)\n",
        "cm=give_answer(input_question)\n",
        "cm_big_cate,cm_small_cate=give_cate(cm)\n",
        "\n",
        "doc2_score=0\n",
        "tran_score=0\n",
        "\n",
        "doc2_score += score_calcul(q_big_cate,dm_big_cate)\n",
        "doc2_score += score_calcul(q_big_cate,dm_small_cate)\n",
        "tran_score += score_calcul(q_big_cate,cm_big_cate)\n",
        "tran_score += score_calcul(q_big_cate,dm_small_cate)\n",
        "\n",
        "if doc2_score>=tran_score:\n",
        "  print(f\"***doc2: {grammar_checker(dm)}\")\n",
        "else:\n",
        "  print(f\"***tran: {grammar_checker(cm)}\")\n",
        "\n",
        "print(\"==================================\")\n",
        "print(f\"doc2: {dm_big_cate},{dm_small_cate}\")\n",
        "print(grammar_checker(dm))\n",
        "if doc2_score!=0:\n",
        "  print(doc2_score)\n",
        "else:\n",
        "  print(\"평가불가\")\n",
        "print(\"\")\n",
        "print(f\"tran: {cm_big_cate},{cm_small_cate}\")\n",
        "print(grammar_checker(cm))\n",
        "if tran_score!=0:\n",
        "  print(tran_score)\n",
        "else:\n",
        "  print(\"평가불가\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "카운터에 있는 점원이 입고 있는 옷 맘에 드는데 어떤 제품인가요?\n",
            "('유사제품추천문의', 0.6587085),('신발', 0.9972078)\n",
            "***doc2: 네 피팅룸은 이쪽입니다\n",
            "==================================\n",
            "doc2: ('제품요청', 0.50416297),('의류', 0.999944)\n",
            "네 피팅룸은 이쪽입니다\n",
            "평가불가\n",
            "\n",
            "tran: ('제품별추천문의', 0.67691714),('의류', 0.88469416)\n",
            "고객 님 이 제품 은 어떠 신지 요 ? \n",
            "평가불가\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}